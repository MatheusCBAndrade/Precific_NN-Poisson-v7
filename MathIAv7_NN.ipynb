{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(66840, 141)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_pickle(r'C:\\Users\\mathe\\OneDrive\\Área de Trabalho\\SoccerIA\\MathIA_v7\\dataset_141cols_europeu.pkl')\n",
    "\n",
    "nan_counts = dataset.isna().sum()\n",
    "nan_tot = nan_counts.sum()\n",
    "print(nan_tot)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando os dataframes de 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe2023_ALE_B.xlsx\n",
      "(90, 19)\n",
      "team1                     0\n",
      "team2                     0\n",
      "team1_goals              54\n",
      "team2_goals              54\n",
      "season                    0\n",
      "championship              0\n",
      "team1_shots_on_target    54\n",
      "team1_shots_out          54\n",
      "team2_shots_on_target    54\n",
      "team2_shots_out          54\n",
      "team1_red_cards          54\n",
      "team2_red_cards          54\n",
      "team1_fouls              54\n",
      "team2_fouls              54\n",
      "team1_corners            54\n",
      "team2_corners            54\n",
      "team1_total_shots        54\n",
      "team2_total_shots        54\n",
      "date                      0\n",
      "dtype: int64\n",
      "dataframe2023_BEL_A.xlsx\n",
      "(77, 19)\n",
      "team1                     0\n",
      "team2                     0\n",
      "team1_goals              40\n",
      "team2_goals              40\n",
      "season                    0\n",
      "championship              0\n",
      "team1_shots_on_target    40\n",
      "team1_shots_out          40\n",
      "team2_shots_on_target    40\n",
      "team2_shots_out          40\n",
      "team1_red_cards          40\n",
      "team2_red_cards          40\n",
      "team1_fouls              40\n",
      "team2_fouls              40\n",
      "team1_corners            40\n",
      "team2_corners            40\n",
      "team1_total_shots        40\n",
      "team2_total_shots        40\n",
      "date                      0\n",
      "dtype: int64\n",
      "dataframe2023_BRA_A.xlsx\n",
      "(287, 19)\n",
      "team1                     0\n",
      "team2                     0\n",
      "team1_goals              82\n",
      "team2_goals              82\n",
      "season                    0\n",
      "championship              0\n",
      "team1_shots_on_target    82\n",
      "team1_shots_out          82\n",
      "team2_shots_on_target    82\n",
      "team2_shots_out          82\n",
      "team1_red_cards          82\n",
      "team2_red_cards          82\n",
      "team1_fouls              82\n",
      "team2_fouls              82\n",
      "team1_corners            82\n",
      "team2_corners            82\n",
      "team1_total_shots        82\n",
      "team2_total_shots        82\n",
      "date                      0\n",
      "dtype: int64\n",
      "dataframe2023_ESP_B.xlsx\n",
      "(121, 19)\n",
      "team1                     0\n",
      "team2                     0\n",
      "team1_goals              77\n",
      "team2_goals              77\n",
      "season                    0\n",
      "championship              0\n",
      "team1_shots_on_target    77\n",
      "team1_shots_out          77\n",
      "team2_shots_on_target    77\n",
      "team2_shots_out          77\n",
      "team1_red_cards          77\n",
      "team2_red_cards          77\n",
      "team1_fouls              77\n",
      "team2_fouls              77\n",
      "team1_corners            77\n",
      "team2_corners            77\n",
      "team1_total_shots        77\n",
      "team2_total_shots        77\n",
      "date                      0\n",
      "dtype: int64\n",
      "dataframe2023_ING_C.xlsx\n",
      "(145, 19)\n",
      "team1                     0\n",
      "team2                     0\n",
      "team1_goals              74\n",
      "team2_goals              74\n",
      "season                    0\n",
      "championship              0\n",
      "team1_shots_on_target    74\n",
      "team1_shots_out          74\n",
      "team2_shots_on_target    74\n",
      "team2_shots_out          74\n",
      "team1_red_cards          74\n",
      "team2_red_cards          74\n",
      "team1_fouls              74\n",
      "team2_fouls              74\n",
      "team1_corners            74\n",
      "team2_corners            74\n",
      "team1_total_shots        74\n",
      "team2_total_shots        74\n",
      "date                      0\n",
      "dtype: int64\n",
      "dataframe2023_ING_D.xlsx\n",
      "(142, 19)\n",
      "team1                     0\n",
      "team2                     0\n",
      "team1_goals              72\n",
      "team2_goals              72\n",
      "season                    0\n",
      "championship              0\n",
      "team1_shots_on_target    72\n",
      "team1_shots_out          72\n",
      "team2_shots_on_target    72\n",
      "team2_shots_out          72\n",
      "team1_red_cards          72\n",
      "team2_red_cards          72\n",
      "team1_fouls              72\n",
      "team2_fouls              72\n",
      "team1_corners            72\n",
      "team2_corners            72\n",
      "team1_total_shots        71\n",
      "team2_total_shots        71\n",
      "date                      0\n",
      "dtype: int64\n",
      "dataframe2023_SUE_A.xlsx\n",
      "(214, 19)\n",
      "team1                     0\n",
      "team2                     0\n",
      "team1_goals              46\n",
      "team2_goals              46\n",
      "season                    0\n",
      "championship              0\n",
      "team1_shots_on_target    46\n",
      "team1_shots_out          46\n",
      "team2_shots_on_target    46\n",
      "team2_shots_out          46\n",
      "team1_red_cards          46\n",
      "team2_red_cards          46\n",
      "team1_fouls              46\n",
      "team2_fouls              46\n",
      "team1_corners            46\n",
      "team2_corners            46\n",
      "team1_total_shots        46\n",
      "team2_total_shots        46\n",
      "date                      0\n",
      "dtype: int64\n",
      "Index(['team1', 'team2', 'team1_goals', 'team2_goals', 'season',\n",
      "       'championship', 'team1_shots_on_target', 'team1_shots_out',\n",
      "       'team2_shots_on_target', 'team2_shots_out', 'team1_red_cards',\n",
      "       'team2_red_cards', 'team1_fouls', 'team2_fouls', 'team1_corners',\n",
      "       'team2_corners', 'team1_total_shots', 'team2_total_shots', 'date',\n",
      "       'is_future_match'],\n",
      "      dtype='object')\n",
      "(1076, 20)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Caminho para a pasta que contém os arquivos .xlsx de 2023\n",
    "path = r'C:\\Users\\mathe\\OneDrive\\Área de Trabalho\\SoccerIA\\Planilhas2023'\n",
    "\n",
    "# Dicionário para armazenar os dataframes\n",
    "dataframes = {}\n",
    "dfss = []\n",
    "# Lista todos os arquivos na pasta\n",
    "files = os.listdir(path)\n",
    "\n",
    "# Filtra a lista de arquivos para incluir apenas os arquivos .xlsx\n",
    "xlsx_files = [f for f in files if f.endswith('.xlsx')]\n",
    "\n",
    "# Carrega cada arquivo .xlsx em um dataframe e armazena no dicionário\n",
    "for file in xlsx_files:\n",
    "    full_path = os.path.join(path, file)  # junta o caminho do diretório com o nome do arquivo\n",
    "    dataframes[file] = pd.read_excel(full_path)  # lê o arquivo .xlsx do caminho completo\n",
    "\n",
    "    if \"Unnamed: 0\" in dataframes[file].columns:\n",
    "        dataframes[file].drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\n",
    "    if \"match_report_url\" in dataframes[file].columns:\n",
    "        dataframes[file].drop(\"match_report_url\", axis=1, inplace=True)    \n",
    "\n",
    "    if \"team1_yellow_cards\" in dataframes[file].columns:\n",
    "        dataframes[file].drop(\"team1_yellow_cards\", axis=1, inplace=True)\n",
    "\n",
    "    if \"team2_yellow_cards\" in dataframes[file].columns:\n",
    "        dataframes[file].drop(\"team2_yellow_cards\", axis=1, inplace=True)  \n",
    "    dfss.append(dataframes[file])\n",
    "\n",
    "    print(file)\n",
    "    print(dataframes[file].shape)\n",
    "    nan_counts = dataframes[file].isna().sum()\n",
    "    print(nan_counts)\n",
    "\n",
    "\n",
    "# Combine all the DataFrames into a single DataFrame\n",
    "combined_df_2023 = pd.concat(dfss, ignore_index=True)\n",
    "\n",
    "\n",
    "combined_df_2023['team1'] = combined_df_2023['team1'].str.lower()\n",
    "combined_df_2023['team2'] = combined_df_2023['team2'].str.lower()\n",
    "combined_df_2023.replace('', np.nan, inplace=True)\n",
    "# Add a column to mark future matches\n",
    "combined_df_2023['is_future_match'] = combined_df_2023['team1_goals'].isna() | combined_df_2023['team2_goals'].isna()\n",
    "combined_df_2023['season'] = '2023'\n",
    "# Replace empty string with NaN\n",
    "combined_df_2023[\"team1_red_cards\"].replace('', np.nan, inplace=True)\n",
    "combined_df_2023[\"team2_red_cards\"].replace('', np.nan, inplace=True)\n",
    "\n",
    "# Replace NaN with 0\n",
    "combined_df_2023[\"team1_red_cards\"].fillna(0, inplace=True)\n",
    "combined_df_2023[\"team2_red_cards\"].fillna(0, inplace=True)\n",
    "\n",
    "combined_df_2023['date'] = pd.to_datetime(combined_df_2023['date'], format='%Y-%m-%d', errors='coerce')\n",
    "combined_df_2023.sort_values('date', inplace=True)\n",
    "\n",
    "print(combined_df_2023.columns)\n",
    "print(combined_df_2023.shape) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1076, 120)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "combined_df_2023.sort_values('date', inplace=True)\n",
    "\n",
    "\n",
    "combined_df_2023['team1_goals'] = pd.to_numeric(combined_df_2023['team1_goals'], errors='coerce')\n",
    "combined_df_2023['team2_goals'] = pd.to_numeric(combined_df_2023['team2_goals'], errors='coerce')\n",
    "\n",
    "# calculate goal differences\n",
    "combined_df_2023['goal_diff_team1'] = combined_df_2023['team1_goals'] - combined_df_2023['team2_goals']\n",
    "combined_df_2023['goal_diff_team2'] = combined_df_2023['team2_goals'] - combined_df_2023['team1_goals']\n",
    "\n",
    "# calculate corners differences\n",
    "combined_df_2023['corners_diff_team1'] = combined_df_2023['team1_corners'] - combined_df_2023['team2_corners']############# NEW\n",
    "combined_df_2023['corners_diff_team2'] = combined_df_2023['team2_corners'] - combined_df_2023['team1_corners']############# NEW\n",
    "\n",
    "# calculate big wins and losses\n",
    "combined_df_2023['team1_big_win'] = np.where(combined_df_2023['goal_diff_team1'] >= 2, 1, 0)\n",
    "combined_df_2023['team1_big_loss'] = np.where(combined_df_2023['goal_diff_team1'] <= -2, 1, 0)\n",
    "combined_df_2023['team2_big_win'] = np.where(combined_df_2023['goal_diff_team2'] >= 2, 1, 0)\n",
    "combined_df_2023['team2_big_loss'] = np.where(combined_df_2023['goal_diff_team2'] <= -2, 1, 0)\n",
    "\n",
    "# calculate AH-2.5 win and losses\n",
    "combined_df_2023['team1_ah-2.5_win'] = np.where(combined_df_2023['corners_diff_team1'] >= 3, 1, 0)############# NEW\n",
    "combined_df_2023['team1_ah-2.5_loss'] = np.where(combined_df_2023['corners_diff_team1'] <= 2, 1, 0)############# NEW\n",
    "combined_df_2023['team2_ah-2.5_win'] = np.where(combined_df_2023['corners_diff_team2'] >= 3, 1, 0)############# NEW\n",
    "combined_df_2023['team2_ah-2.5_loss'] = np.where(combined_df_2023['corners_diff_team2'] <= 2, 1, 0)############# NEW\n",
    "\n",
    "\n",
    "# calculate AH+2.5 win and losses\n",
    "combined_df_2023['team1_ah+2.5_win'] = np.where(combined_df_2023['corners_diff_team1'] >= -2, 1, 0)############# NEW\n",
    "combined_df_2023['team1_ah+2.5_loss'] = np.where(combined_df_2023['corners_diff_team1'] <= -3, 1, 0)############# NEW\n",
    "combined_df_2023['team2_ah+2.5_win'] = np.where(combined_df_2023['corners_diff_team2'] >= -2, 1, 0)############# NEW\n",
    "combined_df_2023['team2_ah+2.5_loss'] = np.where(combined_df_2023['corners_diff_team2'] <= -3, 1, 0)############# NEW\n",
    "\n",
    "\n",
    "# calculate over4.5 win and losses\n",
    "combined_df_2023['team1_over4.5'] = np.where(combined_df_2023['team1_corners'] >= 5, 1, 0)############# NEW\n",
    "combined_df_2023['team1_under4.5'] = np.where(combined_df_2023['team1_corners'] <= 4, 1, 0)############# NEW\n",
    "combined_df_2023['team2_over4.5'] = np.where(combined_df_2023['team2_corners'] >= 5, 1, 0)############# NEW\n",
    "combined_df_2023['team2_under4.5'] = np.where(combined_df_2023['team2_corners'] <= 4, 1, 0)############# NEW\n",
    "\n",
    "# calculate over3.5 win and losses\n",
    "combined_df_2023['team1_over3.5'] = np.where(combined_df_2023['team1_corners'] >= 4, 1, 0)############# NEW\n",
    "combined_df_2023['team1_under3.5'] = np.where(combined_df_2023['team1_corners'] <= 3, 1, 0)############# NEW\n",
    "combined_df_2023['team2_over3.5'] = np.where(combined_df_2023['team2_corners'] >= 4, 1, 0)############# NEW\n",
    "combined_df_2023['team2_under3.5'] = np.where(combined_df_2023['team2_corners'] <= 3, 1, 0)############# NEW\n",
    "\n",
    "# calculate over6.5 win and losses\n",
    "combined_df_2023['team1_over6.5'] = np.where(combined_df_2023['team1_corners'] >= 7, 1, 0)############# NEW\n",
    "combined_df_2023['team1_under6.5'] = np.where(combined_df_2023['team1_corners'] <= 6, 1, 0)############# NEW\n",
    "combined_df_2023['team2_over6.5'] = np.where(combined_df_2023['team2_corners'] >= 7, 1, 0)############# NEW\n",
    "combined_df_2023['team2_under6.5'] = np.where(combined_df_2023['team2_corners'] <= 6, 1, 0)############# NEW\n",
    "\n",
    "\n",
    "# Initialize these columns with 0\n",
    "combined_df_2023['team1_big_wins_last5'] = 0\n",
    "combined_df_2023['team1_big_losses_last5'] = 0\n",
    "combined_df_2023['team2_big_wins_last5'] = 0\n",
    "combined_df_2023['team2_big_losses_last5'] = 0\n",
    "\n",
    "combined_df_2023['team1_ah-2.5_wins_last5'] = 0############# NEW\n",
    "combined_df_2023['team1_ah-2.5_losses_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_ah-2.5_wins_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_ah-2.5_losses_last5'] = 0############# NEW\n",
    "\n",
    "combined_df_2023['team1_ah+2.5_wins_last5'] = 0############# NEW\n",
    "combined_df_2023['team1_ah+2.5_losses_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_ah+2.5_wins_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_ah+2.5_losses_last5'] = 0############# NEW\n",
    "\n",
    "combined_df_2023['team1_over3.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team1_under3.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_over3.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_under3.5_last5'] = 0############# NEW\n",
    "\n",
    "combined_df_2023['team1_over4.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team1_under4.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_over4.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_under4.5_last5'] = 0############# NEW\n",
    "\n",
    "combined_df_2023['team1_over6.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team1_under6.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_over6.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_under6.5_last5'] = 0############# NEW\n",
    "\n",
    "\n",
    "new_cols = ['avg_scr_lasts3_1_home', 'avg_scr_lasts5_1_home', 'avg_scr_lasts3_1_away',\n",
    "            'avg_scr_lasts5_1_away', 'avg_conc_lasts3_1_home', 'avg_conc_lasts5_1_home',\n",
    "            'avg_conc_lasts3_1_away', 'avg_conc_lasts5_1_away', 'avg_scr_lasts3_2_home',\n",
    "            'avg_scr_lasts5_2_home', 'avg_scr_lasts3_2_away', 'avg_scr_lasts5_2_away',\n",
    "            'avg_conc_lasts3_2_home', 'avg_conc_lasts5_2_home', 'avg_conc_lasts3_2_away',\n",
    "            'avg_conc_lasts5_2_away','team1_big_wins_last5', 'team1_big_losses_last5', \n",
    "            'team2_big_wins_last5', 'team2_big_losses_last5',\n",
    "            #abaixo vai ser baseado em finalizações\n",
    "            'avg_total_shots_lasts5_1_home','avg_total_shots_lasts5_1_away','avg_total_shots_lasts5_2_home',\n",
    "            'avg_total_shots_lasts5_2_away', 'avg_otarget_shots_lasts5_1_home','avg_otarget_shots_lasts5_1_away',\n",
    "            'avg_otarget_shots_lasts5_2_home','avg_otarget_shots_lasts5_2_away','avg_out_shots_lasts5_1_home',\n",
    "            'avg_out_shots_lasts5_1_away','avg_out_shots_lasts5_2_home','avg_out_shots_lasts5_2_away',\n",
    "            'avg_conc_total_shots_lasts5_1_home','avg_conc_total_shots_lasts5_1_away',\n",
    "            'avg_conc_total_shots_lasts5_2_home','avg_conc_total_shots_lasts5_2_away',\n",
    "            #abaixo vai ser baseado em corners\n",
    "            'avg_corners_lasts5_1_home','avg_corners_lasts5_1_away', \n",
    "            'avg_corners_conc_lasts5_1_home','avg_corners_conc_lasts5_1_away',\n",
    "            'avg_corners_lasts5_2_home','avg_corners_lasts5_2_away', \n",
    "            'avg_corners_conc_lasts5_2_home', 'avg_corners_conc_lasts5_2_away',\n",
    "            #abaixo vai ser baseado em fouls\n",
    "            'avg_fouls_lasts5_1_home','avg_fouls_lasts5_1_away', \n",
    "            'avg_fouls_conc_lasts5_1_home', 'avg_fouls_conc_lasts5_1_away',\n",
    "            'avg_fouls_lasts5_2_home','avg_fouls_lasts5_2_away', \n",
    "            'avg_fouls_conc_lasts5_2_home', 'avg_fouls_conc_lasts5_2_away',\n",
    "            #novas colunas da v7\n",
    "            'team1_ah-2.5_wins_last5', 'team1_ah-2.5_losses_last5','team2_ah-2.5_wins_last5','team2_ah-2.5_losses_last5',\n",
    "            'team1_ah+2.5_wins_last5','team1_ah+2.5_losses_last5','team2_ah+2.5_wins_last5','team2_ah+2.5_losses_last5',\n",
    "            'team1_over3.5_last5','team1_under3.5_last5','team2_over3.5_last5','team2_under3.5_last5',\n",
    "            'team1_over4.5_last5','team1_under4.5_last5','team2_over4.5_last5','team2_under4.5_last5',\n",
    "            'team1_over6.5_last5','team1_under6.5_last5','team2_over6.5_last5','team2_under6.5_last5'\n",
    "            ]\n",
    "\n",
    "# Create a dictionary with keys as column names and values as np.nan\n",
    "new_cols_dict = {col: np.nan for col in new_cols}\n",
    "\n",
    "# Add new columns to the DataFrame\n",
    "combined_df_2023 = combined_df_2023.assign(**new_cols_dict)\n",
    "\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for i, row in combined_df_2023.iterrows():\n",
    "    # For each team, get their past home and away matches before the current date\n",
    "    team1_matches = combined_df_2023[((combined_df_2023['team1'] == row['team1']) | (combined_df_2023['team2'] == row['team1'])) & (combined_df_2023['date'] < row['date']) & (combined_df_2023['season'] == row['season'])].sort_values(by='date')\n",
    "    team2_matches = combined_df_2023[((combined_df_2023['team1'] == row['team2']) | (combined_df_2023['team2'] == row['team2'])) & (combined_df_2023['date'] < row['date']) & (combined_df_2023['season'] == row['season'])].sort_values(by='date')\n",
    "\n",
    "    # For each team, calculate stats for last 5 matches\n",
    "    if not team1_matches.empty:\n",
    "        team1_matches['big_win'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_big_win'], team1_matches['team2_big_win'])\n",
    "        team1_matches['big_loss'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_big_loss'], team1_matches['team2_big_loss'])\n",
    "        combined_df_2023.at[i, 'team1_big_wins_last5'] = team1_matches['big_win'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team1_big_losses_last5'] = team1_matches['big_loss'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para ah-2.5 para a equipe 1\n",
    "        team1_matches['ah-2.5_win'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_ah-2.5_win'], team1_matches['team2_ah-2.5_win'])\n",
    "        team1_matches['ah-2.5_loss'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_ah-2.5_loss'], team1_matches['team2_ah-2.5_loss'])\n",
    "        combined_df_2023.at[i, 'team1_ah-2.5_wins_last5'] = team1_matches['ah-2.5_win'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team1_ah-2.5_losses_last5'] = team1_matches['ah-2.5_loss'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para ah+2.5 para a equipe 1\n",
    "        team1_matches['ah+2.5_win'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_ah+2.5_win'], team1_matches['team2_ah+2.5_win'])\n",
    "        team1_matches['ah+2.5_loss'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_ah+2.5_loss'], team1_matches['team2_ah+2.5_loss'])\n",
    "        combined_df_2023.at[i, 'team1_ah+2.5_wins_last5'] = team1_matches['ah+2.5_win'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team1_ah+2.5_losses_last5'] = team1_matches['ah+2.5_loss'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para over3.5 para a equipe 1\n",
    "        team1_matches['over3.5'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_over3.5'], team1_matches['team2_over3.5'])\n",
    "        team1_matches['under3.5'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_under3.5'], team1_matches['team2_under3.5'])\n",
    "        combined_df_2023.at[i, 'team1_over3.5_last5'] = team1_matches['over3.5'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team1_under3.5_last5'] = team1_matches['under3.5'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para over4.5 para a equipe 1\n",
    "        team1_matches['over4.5'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_over4.5'], team1_matches['team2_over4.5'])\n",
    "        team1_matches['under4.5'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_under4.5'], team1_matches['team2_under4.5'])\n",
    "        combined_df_2023.at[i, 'team1_over4.5_last5'] = team1_matches['over4.5'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team1_under4.5_last5'] = team1_matches['under4.5'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para over6.5 para a equipe 1\n",
    "        team1_matches['over6.5'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_over6.5'], team1_matches['team2_over6.5'])\n",
    "        team1_matches['under6.5'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_under6.5'], team1_matches['team2_under6.5'])\n",
    "        combined_df_2023.at[i, 'team1_over6.5_last5'] = team1_matches['over6.5'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team1_under6.5_last5'] = team1_matches['under6.5'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "\n",
    "\n",
    "\n",
    "    if not team2_matches.empty:\n",
    "        team2_matches['big_win'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_big_win'], team2_matches['team2_big_win'])\n",
    "        team2_matches['big_loss'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_big_loss'], team2_matches['team2_big_loss'])\n",
    "        combined_df_2023.at[i, 'team2_big_wins_last5'] = team2_matches['big_win'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team2_big_losses_last5'] = team2_matches['big_loss'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para ah-2.5 para a equipe 2\n",
    "        team2_matches['ah-2.5_win'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_ah-2.5_win'], team2_matches['team2_ah-2.5_win'])\n",
    "        team2_matches['ah-2.5_loss'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_ah-2.5_loss'], team2_matches['team2_ah-2.5_loss'])\n",
    "        combined_df_2023.at[i, 'team2_ah-2.5_wins_last5'] = team2_matches['ah-2.5_win'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team2_ah-2.5_losses_last5'] = team2_matches['ah-2.5_loss'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para ah+2.5 para a equipe 2\n",
    "        team2_matches['ah+2.5_win'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_ah+2.5_win'], team2_matches['team2_ah+2.5_win'])\n",
    "        team2_matches['ah+2.5_loss'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_ah+2.5_loss'], team2_matches['team2_ah+2.5_loss'])\n",
    "        combined_df_2023.at[i, 'team2_ah+2.5_wins_last5'] = team2_matches['ah+2.5_win'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team2_ah+2.5_losses_last5'] = team2_matches['ah+2.5_loss'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para over3.5  para a equipe 2\n",
    "        team2_matches['over3.5'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_over3.5'], team2_matches['team2_over3.5'])\n",
    "        team2_matches['under3.5'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_under3.5'], team2_matches['team2_under3.5'])\n",
    "        combined_df_2023.at[i, 'team2_over3.5_last5'] = team2_matches['over3.5'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team2_under3.5_last5'] = team2_matches['under3.5'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para over4.5  para a equipe 2\n",
    "        team2_matches['over4.5'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_over4.5'], team2_matches['team2_over4.5'])\n",
    "        team2_matches['under4.5'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_under4.5'], team2_matches['team2_under4.5'])\n",
    "        combined_df_2023.at[i, 'team2_over4.5_last5'] = team2_matches['over4.5'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team2_under4.5_last5'] = team2_matches['under4.5'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para over6.5  para a equipe 2\n",
    "        team2_matches['over6.5'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_over6.5'], team2_matches['team2_over6.5'])\n",
    "        team2_matches['under6.5'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_under6.5'], team2_matches['team2_under6.5'])\n",
    "        combined_df_2023.at[i, 'team2_over6.5_last5'] = team2_matches['over6.5'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team2_under6.5_last5'] = team2_matches['under6.5'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "for i, row in combined_df_2023.iterrows():\n",
    "    team1_home = combined_df_2023[(combined_df_2023['date'] < row['date']) & (combined_df_2023['team1'] == row['team1']) & (combined_df_2023['season'] == row['season'])]\n",
    "    team1_away = combined_df_2023[(combined_df_2023['date'] < row['date']) & (combined_df_2023['team2'] == row['team1']) & (combined_df_2023['season'] == row['season'])]\n",
    "    \n",
    "    team2_home = combined_df_2023[(combined_df_2023['date'] < row['date']) & (combined_df_2023['team1'] == row['team2']) & (combined_df_2023['season'] == row['season'])]\n",
    "    team2_away = combined_df_2023[(combined_df_2023['date'] < row['date']) & (combined_df_2023['team2'] == row['team2']) & (combined_df_2023['season'] == row['season'])]\n",
    "\n",
    "    if not team1_home.empty:\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts3_1_home'] = team1_home['team1_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team1_home['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts5_1_home'] = team1_home['team1_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts3_1_home'] = team1_home['team2_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team1_home['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts5_1_home'] = team1_home['team2_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team2_goals'].isna().any() else np.nan\n",
    "        ####################################### ABAIXO É SOBRE FINALIZAÇÕES ###########################################\n",
    "        combined_df_2023.at[i, 'avg_total_shots_lasts5_1_home'] = team1_home['team1_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_total_shots'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_total_shots_lasts5_1_home'] = team1_home['team2_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team2_total_shots'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_otarget_shots_lasts5_1_home'] = team1_home['team1_shots_on_target'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_shots_on_target'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_out_shots_lasts5_1_home'] = team1_home['team1_shots_out'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_shots_out'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE CORNERS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_corners_lasts5_1_home'] = team1_home['team1_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_corners'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_corners_conc_lasts5_1_home'] = team1_home['team2_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team2_corners'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE FOULS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_fouls_lasts5_1_home'] = team1_home['team1_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_fouls'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_fouls_conc_lasts5_1_home'] = team1_home['team2_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team2_fouls'].isna().any() else np.nan\n",
    "\n",
    "    if not team1_away.empty:\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts3_1_away'] = team1_away['team2_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team1_away['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts5_1_away'] = team1_away['team2_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts3_1_away'] = team1_away['team1_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team1_away['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts5_1_away'] = team1_away['team1_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team1_goals'].isna().any() else np.nan\n",
    "        ####################################### ABAIXO É SOBRE FINALIZAÇÕES ###########################################\n",
    "        combined_df_2023.at[i, 'avg_total_shots_lasts5_1_away'] = team1_away['team2_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_total_shots'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_otarget_shots_lasts5_1_away'] = team1_away['team2_shots_on_target'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_shots_on_target'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_out_shots_lasts5_1_away'] = team1_away['team2_shots_out'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_shots_out'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_total_shots_lasts5_1_away'] = team1_away['team1_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team1_total_shots'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE CORNERS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_corners_lasts5_1_away'] = team1_away['team2_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_corners'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_corners_conc_lasts5_1_away'] = team1_away['team1_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team1_corners'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE FOULS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_fouls_lasts5_1_away'] = team1_away['team2_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_fouls'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_fouls_conc_lasts5_1_away'] = team1_away['team1_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team1_fouls'].isna().any() else np.nan\n",
    "\n",
    "    if not team2_home.empty:\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts3_2_home'] = team2_home['team1_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team2_home['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts5_2_home'] = team2_home['team1_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts3_2_home'] = team2_home['team2_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team2_home['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts5_2_home'] = team2_home['team2_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team2_goals'].isna().any() else np.nan\n",
    "        ####################################### ABAIXO É SOBRE FINALIZAÇÕES ###########################################\n",
    "        combined_df_2023.at[i, 'avg_total_shots_lasts5_2_home'] = team2_home['team1_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_total_shots'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_otarget_shots_lasts5_2_home'] = team2_home['team1_shots_on_target'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_shots_on_target'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_out_shots_lasts5_2_home'] = team2_home['team1_shots_out'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_shots_out'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_total_shots_lasts5_2_home'] = team2_home['team2_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team2_total_shots'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE CORNERS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_corners_lasts5_2_home'] = team2_home['team1_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_corners'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_corners_conc_lasts5_2_home'] = team2_home['team2_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team2_corners'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE FOULS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_fouls_lasts5_2_home'] = team2_home['team1_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_fouls'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_fouls_conc_lasts5_2_home'] = team2_home['team2_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team2_fouls'].isna().any() else np.nan\n",
    "\n",
    "\n",
    "    if not team2_away.empty:\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts3_2_away'] = team2_away['team2_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team2_away['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts5_2_away'] = team2_away['team2_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts3_2_away'] = team2_away['team1_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team2_away['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts5_2_away'] = team2_away['team1_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team1_goals'].isna().any() else np.nan\n",
    "        ####################################### ABAIXO É SOBRE FINALIZAÇÕES ###########################################\n",
    "        combined_df_2023.at[i, 'avg_total_shots_lasts5_2_away'] = team2_away['team2_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_total_shots'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_otarget_shots_lasts5_2_away'] = team2_away['team2_shots_on_target'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_shots_on_target'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_out_shots_lasts5_2_away'] = team2_away['team2_shots_out'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_shots_out'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_total_shots_lasts5_2_away'] = team2_away['team1_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team1_total_shots'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE CORNERS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_corners_lasts5_2_away'] = team2_away['team2_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_corners'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_corners_conc_lasts5_2_away'] = team2_away['team1_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team1_corners'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE FOULS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_fouls_lasts5_2_away'] = team2_away['team2_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_fouls'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_fouls_conc_lasts5_2_away'] = team2_away['team1_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team1_fouls'].isna().any() else np.nan\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "combined_df_2023.shape        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1076, 140)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_result(row):\n",
    "    if row['team1_goals'] > row['team2_goals']:\n",
    "        return pd.Series([3, 0])\n",
    "    elif row['team1_goals'] < row['team2_goals']:\n",
    "        return pd.Series([0, 3])\n",
    "    else:\n",
    "        return pd.Series([1, 1])\n",
    "\n",
    "combined_df_2023[['result_team1', 'result_team2']] = combined_df_2023.apply(get_result, axis=1)\n",
    "\n",
    "def get_streak(df, result_col, results):\n",
    "    result_series = df[result_col].apply(lambda x: 1 if x in results else 0)\n",
    "    result_series = result_series * (result_series.groupby((result_series != result_series.shift()).cumsum()).cumcount() + 1)\n",
    "    return result_series\n",
    "\n",
    "# Create a dictionary to hold individual team dataframes\n",
    "team_df_dict = {}\n",
    "\n",
    "def get_individual_team_df(df, team_name): #teoricamente aqui deveria ser corners, mas o erro se apresentou menor assim:\n",
    "    if team_name in team_df_dict:\n",
    "        return team_df_dict[team_name]\n",
    "        \n",
    "    team_games = df[(df['team1'] == team_name) | (df['team2'] == team_name)].copy()\n",
    "    team_games['team_is_team1'] = team_games['team1'] == team_name\n",
    "    team_games['team_result'] = np.where(team_games['team_is_team1'], team_games['result_team1'], team_games['result_team2'])\n",
    "    team_games['team_goals'] = np.where(team_games['team_is_team1'], team_games['team1_goals'], team_games['team2_goals'])\n",
    "    team_games['team_redcards'] = np.where(team_games['team_is_team1'], team_games['team1_red_cards'], team_games['team2_red_cards'])\n",
    "\n",
    "    team_games.sort_values('date', inplace=True)\n",
    "    team_games['days_since_last_game'] = team_games['date'].diff().dt.days\n",
    "\n",
    "    team_df_dict[team_name] = team_games\n",
    "    return team_games\n",
    "\n",
    "def get_team_stats(row, df):\n",
    "    team1_games = get_individual_team_df(df, row['team1'])\n",
    "    team2_games = get_individual_team_df(df, row['team2'])\n",
    "\n",
    "    # Filter to include only games that occurred before the current game\n",
    "    team1_games = team1_games[team1_games['date'] < row['date']]\n",
    "    team2_games = team2_games[team2_games['date'] < row['date']]\n",
    "\n",
    "    stats = {}\n",
    "\n",
    "    if not team1_games.empty:\n",
    "        stats['team1_winning_streak'] = get_streak(team1_games, 'team_result', [3]).iloc[-1]\n",
    "        stats['team1_undefeated_streak'] = get_streak(team1_games, 'team_result', [1, 3]).iloc[-1]\n",
    "        stats['team1_losing_streak'] = get_streak(team1_games, 'team_result', [0]).iloc[-1]\n",
    "        stats['team1_without_winning_streak'] = get_streak(team1_games, 'team_result', [0, 1]).iloc[-1]\n",
    "        stats['avg_points_lasts5_1'] = team1_games.tail(5)['team_result'].mean()\n",
    "        stats['team1_strength'] = team1_games['team_goals'].sum() / (team1_games['team1_goals'].sum() + team1_games['team2_goals'].sum() + 0.01)\n",
    "        stats['championship_points_1'] = team1_games['team_result'].sum() / len(team1_games)\n",
    "        rested_4_or_more_days_1 = team1_games.tail(1)['days_since_last_game'].values[0] >= 4\n",
    "        stats['rested_4_days_or_more_1'] = 1 if rested_4_or_more_days_1 else -1\n",
    "\n",
    "    if not team2_games.empty:\n",
    "        stats['team2_winning_streak'] = get_streak(team2_games, 'team_result', [3]).iloc[-1]\n",
    "        stats['team2_undefeated_streak'] = get_streak(team2_games, 'team_result', [1, 3]).iloc[-1]\n",
    "        stats['team2_losing_streak'] = get_streak(team2_games, 'team_result', [0]).iloc[-1]\n",
    "        stats['team2_without_winning_streak'] = get_streak(team2_games, 'team_result', [0, 1]).iloc[-1]\n",
    "        stats['avg_points_lasts5_2'] = team2_games.tail(5)['team_result'].mean()\n",
    "        stats['team2_strength'] = team2_games['team_goals'].sum() / (team2_games['team1_goals'].sum() + team2_games['team2_goals'].sum() + 0.01)\n",
    "        stats['championship_points_2'] = team2_games['team_result'].sum() / len(team2_games)\n",
    "        rested_4_or_more_days_2 = team2_games.tail(1)['days_since_last_game'].values[0] >= 4\n",
    "        stats['rested_4_days_or_more_2'] = 1 if rested_4_or_more_days_2 else -1\n",
    "\n",
    "    return pd.Series(stats)\n",
    "\n",
    "combined_df_2023 = pd.concat([combined_df_2023, combined_df_2023.apply(lambda row: get_team_stats(row, combined_df_2023), axis=1)], axis=1)\n",
    "\n",
    "# Now, calculate the number of suspended players for the next match for each team.\n",
    "for team_name in team_df_dict.keys():\n",
    "    team_df = team_df_dict[team_name].copy()\n",
    "    team_df['next_match_suspended_players'] = team_df['team_redcards'].shift()\n",
    "\n",
    "    # Assign the suspended players back to the combined_df_2023.\n",
    "    team1_mask = combined_df_2023['team1'] == team_name\n",
    "    team2_mask = combined_df_2023['team2'] == team_name\n",
    "    combined_df_2023.loc[team1_mask, 'team1_suspended_players'] = team_df.loc[team1_mask, 'next_match_suspended_players']\n",
    "    combined_df_2023.loc[team2_mask, 'team2_suspended_players'] = team_df.loc[team2_mask, 'next_match_suspended_players']\n",
    "\n",
    "combined_df_2023.shape    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['team1',\n",
       " 'team2',\n",
       " 'team1_goals',\n",
       " 'team2_goals',\n",
       " 'season',\n",
       " 'championship',\n",
       " 'team1_shots_on_target',\n",
       " 'team1_shots_out',\n",
       " 'team2_shots_on_target',\n",
       " 'team2_shots_out',\n",
       " 'team1_red_cards',\n",
       " 'team2_red_cards',\n",
       " 'team1_fouls',\n",
       " 'team2_fouls',\n",
       " 'team1_corners',\n",
       " 'team2_corners',\n",
       " 'team1_total_shots',\n",
       " 'team2_total_shots',\n",
       " 'date',\n",
       " 'is_future_match',\n",
       " 'goal_diff_team1',\n",
       " 'goal_diff_team2',\n",
       " 'corners_diff_team1',\n",
       " 'corners_diff_team2',\n",
       " 'team1_big_win',\n",
       " 'team1_big_loss',\n",
       " 'team2_big_win',\n",
       " 'team2_big_loss',\n",
       " 'team1_ah-2.5_win',\n",
       " 'team1_ah-2.5_loss',\n",
       " 'team2_ah-2.5_win',\n",
       " 'team2_ah-2.5_loss',\n",
       " 'team1_ah+2.5_win',\n",
       " 'team1_ah+2.5_loss',\n",
       " 'team2_ah+2.5_win',\n",
       " 'team2_ah+2.5_loss',\n",
       " 'team1_over4.5',\n",
       " 'team1_under4.5',\n",
       " 'team2_over4.5',\n",
       " 'team2_under4.5',\n",
       " 'team1_over3.5',\n",
       " 'team1_under3.5',\n",
       " 'team2_over3.5',\n",
       " 'team2_under3.5',\n",
       " 'team1_over6.5',\n",
       " 'team1_under6.5',\n",
       " 'team2_over6.5',\n",
       " 'team2_under6.5',\n",
       " 'team1_big_wins_last5',\n",
       " 'team1_big_losses_last5',\n",
       " 'team2_big_wins_last5',\n",
       " 'team2_big_losses_last5',\n",
       " 'team1_ah-2.5_wins_last5',\n",
       " 'team1_ah-2.5_losses_last5',\n",
       " 'team2_ah-2.5_wins_last5',\n",
       " 'team2_ah-2.5_losses_last5',\n",
       " 'team1_ah+2.5_wins_last5',\n",
       " 'team1_ah+2.5_losses_last5',\n",
       " 'team2_ah+2.5_wins_last5',\n",
       " 'team2_ah+2.5_losses_last5',\n",
       " 'team1_over3.5_last5',\n",
       " 'team1_under3.5_last5',\n",
       " 'team2_over3.5_last5',\n",
       " 'team2_under3.5_last5',\n",
       " 'team1_over4.5_last5',\n",
       " 'team1_under4.5_last5',\n",
       " 'team2_over4.5_last5',\n",
       " 'team2_under4.5_last5',\n",
       " 'team1_over6.5_last5',\n",
       " 'team1_under6.5_last5',\n",
       " 'team2_over6.5_last5',\n",
       " 'team2_under6.5_last5',\n",
       " 'avg_scr_lasts3_1_home',\n",
       " 'avg_scr_lasts5_1_home',\n",
       " 'avg_scr_lasts3_1_away',\n",
       " 'avg_scr_lasts5_1_away',\n",
       " 'avg_conc_lasts3_1_home',\n",
       " 'avg_conc_lasts5_1_home',\n",
       " 'avg_conc_lasts3_1_away',\n",
       " 'avg_conc_lasts5_1_away',\n",
       " 'avg_scr_lasts3_2_home',\n",
       " 'avg_scr_lasts5_2_home',\n",
       " 'avg_scr_lasts3_2_away',\n",
       " 'avg_scr_lasts5_2_away',\n",
       " 'avg_conc_lasts3_2_home',\n",
       " 'avg_conc_lasts5_2_home',\n",
       " 'avg_conc_lasts3_2_away',\n",
       " 'avg_conc_lasts5_2_away',\n",
       " 'avg_total_shots_lasts5_1_home',\n",
       " 'avg_total_shots_lasts5_1_away',\n",
       " 'avg_total_shots_lasts5_2_home',\n",
       " 'avg_total_shots_lasts5_2_away',\n",
       " 'avg_otarget_shots_lasts5_1_home',\n",
       " 'avg_otarget_shots_lasts5_1_away',\n",
       " 'avg_otarget_shots_lasts5_2_home',\n",
       " 'avg_otarget_shots_lasts5_2_away',\n",
       " 'avg_out_shots_lasts5_1_home',\n",
       " 'avg_out_shots_lasts5_1_away',\n",
       " 'avg_out_shots_lasts5_2_home',\n",
       " 'avg_out_shots_lasts5_2_away',\n",
       " 'avg_conc_total_shots_lasts5_1_home',\n",
       " 'avg_conc_total_shots_lasts5_1_away',\n",
       " 'avg_conc_total_shots_lasts5_2_home',\n",
       " 'avg_conc_total_shots_lasts5_2_away',\n",
       " 'avg_corners_lasts5_1_home',\n",
       " 'avg_corners_lasts5_1_away',\n",
       " 'avg_corners_conc_lasts5_1_home',\n",
       " 'avg_corners_conc_lasts5_1_away',\n",
       " 'avg_corners_lasts5_2_home',\n",
       " 'avg_corners_lasts5_2_away',\n",
       " 'avg_corners_conc_lasts5_2_home',\n",
       " 'avg_corners_conc_lasts5_2_away',\n",
       " 'avg_fouls_lasts5_1_home',\n",
       " 'avg_fouls_lasts5_1_away',\n",
       " 'avg_fouls_conc_lasts5_1_home',\n",
       " 'avg_fouls_conc_lasts5_1_away',\n",
       " 'avg_fouls_lasts5_2_home',\n",
       " 'avg_fouls_lasts5_2_away',\n",
       " 'avg_fouls_conc_lasts5_2_home',\n",
       " 'avg_fouls_conc_lasts5_2_away',\n",
       " 'result_team1',\n",
       " 'result_team2',\n",
       " 'team1_winning_streak',\n",
       " 'team1_undefeated_streak',\n",
       " 'team1_losing_streak',\n",
       " 'team1_without_winning_streak',\n",
       " 'avg_points_lasts5_1',\n",
       " 'team1_strength',\n",
       " 'championship_points_1',\n",
       " 'rested_4_days_or_more_1',\n",
       " 'team2_winning_streak',\n",
       " 'team2_undefeated_streak',\n",
       " 'team2_losing_streak',\n",
       " 'team2_without_winning_streak',\n",
       " 'avg_points_lasts5_2',\n",
       " 'team2_strength',\n",
       " 'championship_points_2',\n",
       " 'rested_4_days_or_more_2',\n",
       " 'team1_suspended_players',\n",
       " 'team2_suspended_players']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combined_df_2023.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    " 'team1_goals',\n",
    " 'team2_goals',\n",
    " 'team1_shots_on_target',\n",
    " 'team1_shots_out',\n",
    " 'team2_shots_on_target',\n",
    " 'team2_shots_out',\n",
    " 'team1_red_cards',\n",
    " 'team2_red_cards',\n",
    " 'team1_fouls',\n",
    " 'team2_fouls',\n",
    " 'team1_corners',\n",
    " 'team2_corners',\n",
    " 'team1_total_shots',\n",
    " 'team2_total_shots',\n",
    " 'date',\n",
    " 'is_future_match',\n",
    " 'goal_diff_team1',\n",
    " 'goal_diff_team2',\n",
    " 'corners_diff_team1',\n",
    " 'corners_diff_team2',\n",
    " 'team1_big_win',\n",
    " 'team1_big_loss',\n",
    " 'team2_big_win',\n",
    " 'team2_big_loss',\n",
    " 'team1_ah-2.5_win',\n",
    " 'team1_ah-2.5_loss',\n",
    " 'team2_ah-2.5_win',\n",
    " 'team2_ah-2.5_loss',\n",
    " 'team1_ah+2.5_win',\n",
    " 'team1_ah+2.5_loss',\n",
    " 'team2_ah+2.5_win',\n",
    " 'team2_ah+2.5_loss',\n",
    " 'team1_over4.5',\n",
    " 'team1_under4.5',\n",
    " 'team2_over4.5',\n",
    " 'team2_under4.5',\n",
    " 'team1_over3.5',\n",
    " 'team1_under3.5',\n",
    " 'team2_over3.5',\n",
    " 'team2_under3.5',\n",
    " 'team1_over6.5',\n",
    " 'team1_under6.5',\n",
    " 'team2_over6.5',\n",
    " 'team2_under6.5',\n",
    " 'result_team1',\n",
    " 'result_team2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando future Match baseado na data de hoje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(445, 140)\n",
      "(43, 93)\n"
     ]
    }
   ],
   "source": [
    "dataset2 = combined_df_2023.copy()\n",
    "\n",
    "# filter the DataFrame\n",
    "future_matches = dataset2[dataset2['is_future_match'] == True]\n",
    "future_matches.sort_values(by='date')\n",
    "print(future_matches.shape)\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Get yesterday's date\n",
    "yesterday = datetime.now() - timedelta(days=1)\n",
    "\n",
    "# Filter the DataFrame to include only rows with dates greater than yesterday\n",
    "#future_matches = future_matches[future_matches['date'] > yesterday]\n",
    "\n",
    "# Liste todas as colunas que você deseja verificar\n",
    "columns_to_check= [col for col in future_matches.columns if col not in columns_to_drop]\n",
    "\n",
    "# Drop as linhas com 'np.nan' nas colunas especificadas\n",
    "future_matches = future_matches.dropna(subset=columns_to_check)\n",
    "future_matches_calculado = future_matches.drop(columns_to_drop,axis=1)\n",
    "future_matches_calculado = future_matches_calculado.drop('season',axis=1)\n",
    "\"\"\"# Contando os valores NaN em cada coluna\n",
    "nan_counts = future_matches.isna().sum()\n",
    "\n",
    "# Transformando em uma lista de pares (nome da coluna, contagem de np.nan)\n",
    "nan_list = list(nan_counts.items())\n",
    "\n",
    "# Percorrendo a lista e imprimindo cada valor individualmente com o nome da coluna\n",
    "for col_name, nan_count in nan_list:\n",
    "    print(f'{col_name}: {nan_count}')\"\"\"\n",
    "    \n",
    "print(future_matches_calculado.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1076, 140)\n",
      "A quantidade de np.nan em linhas eram 44744\n",
      "Total number of rows with 'NaN' or an empty value: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(302, 140)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CORTAR AS LINHAS COM MATCHES FUTUROS AQUI\n",
    "\n",
    "# Replace empty strings with NaN\n",
    "print(dataset2.shape)\n",
    "dataset2.replace('', np.nan, inplace=True)\n",
    "print(f\"A quantidade de np.nan em linhas eram {dataset2.isna().sum().sum()}\")\n",
    "# Remove rows that contain any missing values\n",
    "dataset2.dropna(inplace=True)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "counter = 0  # Initialize counter\n",
    "for index, row in dataset2.iterrows():\n",
    "    if row.isnull().any() or row.eq('').any():\n",
    "        print(f\"Row {index} contains 'NaN' or an empty value.\")\n",
    "        counter += 1  # Increase counter if condition is met\n",
    "\n",
    "print(f\"Total number of rows with 'NaN' or an empty value: {counter}\")\n",
    "dataset2.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenando os 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>championship</th>\n",
       "      <th>date</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>team1_goals</th>\n",
       "      <th>team2_goals</th>\n",
       "      <th>team1_total_shots</th>\n",
       "      <th>team2_total_shots</th>\n",
       "      <th>team1_shots_on_target</th>\n",
       "      <th>team2_shots_on_target</th>\n",
       "      <th>...</th>\n",
       "      <th>team1_winning_streak</th>\n",
       "      <th>team1_without_winning_streak</th>\n",
       "      <th>team2_losing_streak</th>\n",
       "      <th>team2_strength</th>\n",
       "      <th>team2_undefeated_streak</th>\n",
       "      <th>team2_winning_streak</th>\n",
       "      <th>team2_without_winning_streak</th>\n",
       "      <th>team1_suspended_players</th>\n",
       "      <th>team2_suspended_players</th>\n",
       "      <th>is_future_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E0</td>\n",
       "      <td>2002-09-14</td>\n",
       "      <td>Charlton</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666297</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E0</td>\n",
       "      <td>2002-09-14</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.665927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E0</td>\n",
       "      <td>2002-09-14</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Man United</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.554939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E0</td>\n",
       "      <td>2002-09-14</td>\n",
       "      <td>West Brom</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332963</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E0</td>\n",
       "      <td>2002-09-15</td>\n",
       "      <td>Man City</td>\n",
       "      <td>Blackburn</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.454133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67124</th>\n",
       "      <td>ING D</td>\n",
       "      <td>2023-09-02</td>\n",
       "      <td>harrogate town fc</td>\n",
       "      <td>barrow</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67123</th>\n",
       "      <td>ING D</td>\n",
       "      <td>2023-09-02</td>\n",
       "      <td>morecambe</td>\n",
       "      <td>salford city</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.499688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67140</th>\n",
       "      <td>ING C</td>\n",
       "      <td>2023-09-02</td>\n",
       "      <td>bolton wanderers fc</td>\n",
       "      <td>derby county</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624610</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67131</th>\n",
       "      <td>ING D</td>\n",
       "      <td>2023-09-02</td>\n",
       "      <td>newport county afc</td>\n",
       "      <td>afc wimbledon</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.776915</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67141</th>\n",
       "      <td>ING C</td>\n",
       "      <td>2023-09-02</td>\n",
       "      <td>carlisle utd</td>\n",
       "      <td>shrewsbury town</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499376</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67142 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      championship       date                team1            team2  \\\n",
       "0               E0 2002-09-14             Charlton          Arsenal   \n",
       "1               E0 2002-09-14              Everton    Middlesbrough   \n",
       "2               E0 2002-09-14                Leeds       Man United   \n",
       "3               E0 2002-09-14            West Brom      Southampton   \n",
       "4               E0 2002-09-15             Man City        Blackburn   \n",
       "...            ...        ...                  ...              ...   \n",
       "67124        ING D 2023-09-02    harrogate town fc           barrow   \n",
       "67123        ING D 2023-09-02            morecambe     salford city   \n",
       "67140        ING C 2023-09-02  bolton wanderers fc     derby county   \n",
       "67131        ING D 2023-09-02   newport county afc    afc wimbledon   \n",
       "67141        ING C 2023-09-02         carlisle utd  shrewsbury town   \n",
       "\n",
       "       team1_goals  team2_goals  team1_total_shots  team2_total_shots  \\\n",
       "0              0.0          3.0                9.0               10.0   \n",
       "1              2.0          1.0               13.0               10.0   \n",
       "2              1.0          0.0                8.0                6.0   \n",
       "3              1.0          0.0               11.0               10.0   \n",
       "4              2.0          2.0               15.0               12.0   \n",
       "...            ...          ...                ...                ...   \n",
       "67124          0.0          1.0               10.0                8.0   \n",
       "67123          1.0          0.0                9.0                4.0   \n",
       "67140          2.0          1.0               10.0                5.0   \n",
       "67131          2.0          2.0                8.0               11.0   \n",
       "67141          2.0          0.0                9.0                8.0   \n",
       "\n",
       "       team1_shots_on_target  team2_shots_on_target  ...  \\\n",
       "0                        3.0                    8.0  ...   \n",
       "1                        8.0                    5.0  ...   \n",
       "2                        2.0                    5.0  ...   \n",
       "3                        7.0                    5.0  ...   \n",
       "4                        7.0                    8.0  ...   \n",
       "...                      ...                    ...  ...   \n",
       "67124                    6.0                    3.0  ...   \n",
       "67123                    5.0                    2.0  ...   \n",
       "67140                    6.0                    1.0  ...   \n",
       "67131                    4.0                    4.0  ...   \n",
       "67141                    2.0                    2.0  ...   \n",
       "\n",
       "       team1_winning_streak  team1_without_winning_streak  \\\n",
       "0                       0.0                           1.0   \n",
       "1                       0.0                           3.0   \n",
       "2                       1.0                           0.0   \n",
       "3                       2.0                           0.0   \n",
       "4                       0.0                           1.0   \n",
       "...                     ...                           ...   \n",
       "67124                   1.0                           0.0   \n",
       "67123                   0.0                           1.0   \n",
       "67140                   0.0                           2.0   \n",
       "67131                   2.0                           0.0   \n",
       "67141                   0.0                           5.0   \n",
       "\n",
       "       team2_losing_streak  team2_strength  team2_undefeated_streak  \\\n",
       "0                      0.0        0.666297                      5.0   \n",
       "1                      0.0        0.665927                      1.0   \n",
       "2                      1.0        0.554939                      0.0   \n",
       "3                      0.0        0.332963                      1.0   \n",
       "4                      2.0        0.454133                      0.0   \n",
       "...                    ...             ...                      ...   \n",
       "67124                  0.0        0.544959                      1.0   \n",
       "67123                  1.0        0.499688                      0.0   \n",
       "67140                  0.0        0.624610                      2.0   \n",
       "67131                  0.0        0.776915                      5.0   \n",
       "67141                  0.0        0.499376                      1.0   \n",
       "\n",
       "       team2_winning_streak  team2_without_winning_streak  \\\n",
       "0                       1.0                           0.0   \n",
       "1                       1.0                           0.0   \n",
       "2                       0.0                           1.0   \n",
       "3                       1.0                           0.0   \n",
       "4                       0.0                           3.0   \n",
       "...                     ...                           ...   \n",
       "67124                   0.0                           3.0   \n",
       "67123                   0.0                           1.0   \n",
       "67140                   2.0                           0.0   \n",
       "67131                   0.0                           1.0   \n",
       "67141                   1.0                           0.0   \n",
       "\n",
       "       team1_suspended_players team2_suspended_players  is_future_match  \n",
       "0                          0.0                     0.0              NaN  \n",
       "1                          0.0                     0.0              NaN  \n",
       "2                          0.0                     0.0              NaN  \n",
       "3                          0.0                     0.0              NaN  \n",
       "4                          1.0                     0.0              NaN  \n",
       "...                        ...                     ...              ...  \n",
       "67124                      0.0                     0.0            False  \n",
       "67123                      1.0                     0.0            False  \n",
       "67140                      0.0                     0.0            False  \n",
       "67131                      0.0                     0.0            False  \n",
       "67141                      0.0                     0.0            False  \n",
       "\n",
       "[67142 rows x 140 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatotal = pd.concat([dataset, dataset2], ignore_index=True)#mudei o 'dataset' por combined_df_13c_new\n",
    "\n",
    "datatotal.sort_values(by='date', inplace=True)\n",
    "\n",
    "if 'team1_yellow_cards' in datatotal.columns:\n",
    "    datatotal = datatotal.drop(['team1_yellow_cards'], axis=1)\n",
    "\n",
    "if 'team2_yellow_cards' in datatotal.columns:\n",
    "    datatotal = datatotal.drop(['team2_yellow_cards'], axis=1)\n",
    "\n",
    "# Substituir valores maiores que 15 por 15 na coluna 'team1_corners'\n",
    "datatotal.loc[datatotal['team1_corners'] > 15, 'team1_corners'] = 15\n",
    "\n",
    "# Substituir valores maiores que 15 por 15 na coluna 'team2_corners'\n",
    "datatotal.loc[datatotal['team2_corners'] > 15, 'team2_corners'] = 15    \n",
    "\n",
    "datatotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E0' 'SC0' 'E3' 'E2' 'E1' 'I1' 'SP1' 'D1' 'F1' 'D2' 'P1' 'SP2' 'T1' 'I2'\n",
      " 'N1' 'F2' 'B1' 'G1' 'SUE A' 'BRA A' 'ING C' 'ING D']\n"
     ]
    }
   ],
   "source": [
    "champ_uniques = datatotal['championship'].unique()\n",
    "print(champ_uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converta Categorias em IDs Numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Suponho que 'datatotal' e 'future_matches' já estejam definidos e tenham as mesmas colunas relevantes\n",
    "\n",
    "# Treinar o LabelEncoder com 'datatotal' e 'future_matches'\n",
    "le_teams = LabelEncoder().fit(pd.concat([datatotal['team1'], datatotal['team2'], future_matches_calculado['team1'], future_matches_calculado['team2']]).astype(str))\n",
    "le_champ = LabelEncoder().fit(pd.concat([datatotal['championship'], future_matches_calculado['championship']]).astype(str))\n",
    "\n",
    "# Aplicar o LabelEncoder a 'datatotal'\n",
    "datatotal['team1'] = le_teams.transform(datatotal['team1'].astype(str))\n",
    "datatotal['team2'] = le_teams.transform(datatotal['team2'].astype(str))\n",
    "datatotal['championship'] = le_champ.transform(datatotal['championship'].astype(str))\n",
    "\n",
    "# Agora, aplicar o mesmo LabelEncoder a 'future_matches'\n",
    "future_matches_calculado['team1'] = le_teams.transform(future_matches_calculado['team1'].astype(str))\n",
    "future_matches_calculado['team2'] = le_teams.transform(future_matches_calculado['team2'].astype(str))\n",
    "future_matches_calculado['championship'] = le_champ.transform(future_matches_calculado['championship'].astype(str))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>championship</th>\n",
       "      <th>team1_big_wins_last5</th>\n",
       "      <th>team1_big_losses_last5</th>\n",
       "      <th>team2_big_wins_last5</th>\n",
       "      <th>team2_big_losses_last5</th>\n",
       "      <th>team1_ah-2.5_wins_last5</th>\n",
       "      <th>team1_ah-2.5_losses_last5</th>\n",
       "      <th>team2_ah-2.5_wins_last5</th>\n",
       "      <th>...</th>\n",
       "      <th>team2_winning_streak</th>\n",
       "      <th>team2_undefeated_streak</th>\n",
       "      <th>team2_losing_streak</th>\n",
       "      <th>team2_without_winning_streak</th>\n",
       "      <th>avg_points_lasts5_2</th>\n",
       "      <th>team2_strength</th>\n",
       "      <th>championship_points_2</th>\n",
       "      <th>rested_4_days_or_more_2</th>\n",
       "      <th>team1_suspended_players</th>\n",
       "      <th>team2_suspended_players</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>533</td>\n",
       "      <td>519</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.222099</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>515</td>\n",
       "      <td>499</td>\n",
       "      <td>21</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.730043</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>471</td>\n",
       "      <td>472</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.571293</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>508</td>\n",
       "      <td>517</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.414533</td>\n",
       "      <td>1.190476</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>479</td>\n",
       "      <td>502</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.566572</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      team1  team2  championship  team1_big_wins_last5  \\\n",
       "127     533    519             1                   0.0   \n",
       "1031    515    499            21                   2.0   \n",
       "372     471    472             2                   1.0   \n",
       "373     508    517             2                   0.0   \n",
       "374     479    502             2                   3.0   \n",
       "\n",
       "      team1_big_losses_last5  team2_big_wins_last5  team2_big_losses_last5  \\\n",
       "127                      2.0                   0.0                     2.0   \n",
       "1031                     1.0                   1.0                     1.0   \n",
       "372                      0.0                   2.0                     0.0   \n",
       "373                      0.0                   0.0                     1.0   \n",
       "374                      0.0                   0.0                     1.0   \n",
       "\n",
       "      team1_ah-2.5_wins_last5  team1_ah-2.5_losses_last5  \\\n",
       "127                       3.0                        2.0   \n",
       "1031                      1.0                        4.0   \n",
       "372                       1.0                        4.0   \n",
       "373                       1.0                        4.0   \n",
       "374                       2.0                        3.0   \n",
       "\n",
       "      team2_ah-2.5_wins_last5  ...  team2_winning_streak  \\\n",
       "127                       0.0  ...                   0.0   \n",
       "1031                      2.0  ...                   2.0   \n",
       "372                       3.0  ...                   1.0   \n",
       "373                       1.0  ...                   0.0   \n",
       "374                       2.0  ...                   0.0   \n",
       "\n",
       "      team2_undefeated_streak  team2_losing_streak  \\\n",
       "127                       1.0                  0.0   \n",
       "1031                      2.0                  0.0   \n",
       "372                       1.0                  0.0   \n",
       "373                       1.0                  0.0   \n",
       "374                       3.0                  0.0   \n",
       "\n",
       "      team2_without_winning_streak  avg_points_lasts5_2  team2_strength  \\\n",
       "127                            5.0                  0.2        0.222099   \n",
       "1031                           0.0                  1.8        0.730043   \n",
       "372                            0.0                  1.8        0.571293   \n",
       "373                            9.0                  0.4        0.414533   \n",
       "374                            1.0                  1.6        0.566572   \n",
       "\n",
       "      championship_points_2  rested_4_days_or_more_2  team1_suspended_players  \\\n",
       "127                0.200000                      1.0                      0.0   \n",
       "1031               2.285714                      1.0                      0.0   \n",
       "372                1.428571                      1.0                      1.0   \n",
       "373                1.190476                      1.0                      0.0   \n",
       "374                1.714286                      1.0                      0.0   \n",
       "\n",
       "      team2_suspended_players  \n",
       "127                       0.0  \n",
       "1031                      0.0  \n",
       "372                       0.0  \n",
       "373                       0.0  \n",
       "374                       0.0  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_matches_calculado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "n_teams = len(le_teams.classes_)\n",
    "n_champ = len(le_champ.classes_)\n",
    "print(n_teams)\n",
    "print(n_champ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatotal['season'] = datatotal['season'].astype('float64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando X e Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67142, 94)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = datatotal.drop(columns_to_drop, axis=1)\n",
    "y1 = datatotal['team1_corners']\n",
    "y2 = datatotal['team2_corners']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dtype('int32'),\n",
       " dtype('int32'),\n",
       " dtype('int32'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['championship',\n",
       " 'team1',\n",
       " 'team2',\n",
       " 'season',\n",
       " 'team1_big_wins_last5',\n",
       " 'team1_big_losses_last5',\n",
       " 'team2_big_wins_last5',\n",
       " 'team2_big_losses_last5',\n",
       " 'team1_ah-2.5_wins_last5',\n",
       " 'team1_ah-2.5_losses_last5',\n",
       " 'team2_ah-2.5_wins_last5',\n",
       " 'team2_ah-2.5_losses_last5',\n",
       " 'team1_ah+2.5_wins_last5',\n",
       " 'team1_ah+2.5_losses_last5',\n",
       " 'team2_ah+2.5_wins_last5',\n",
       " 'team2_ah+2.5_losses_last5',\n",
       " 'team1_over3.5_last5',\n",
       " 'team1_under3.5_last5',\n",
       " 'team2_over3.5_last5',\n",
       " 'team2_under3.5_last5',\n",
       " 'team1_over4.5_last5',\n",
       " 'team1_under4.5_last5',\n",
       " 'team2_over4.5_last5',\n",
       " 'team2_under4.5_last5',\n",
       " 'team1_over6.5_last5',\n",
       " 'team1_under6.5_last5',\n",
       " 'team2_over6.5_last5',\n",
       " 'team2_under6.5_last5',\n",
       " 'avg_scr_lasts3_1_home',\n",
       " 'avg_scr_lasts5_1_home',\n",
       " 'avg_scr_lasts3_1_away',\n",
       " 'avg_scr_lasts5_1_away',\n",
       " 'avg_conc_lasts3_1_home',\n",
       " 'avg_conc_lasts5_1_home',\n",
       " 'avg_conc_lasts3_1_away',\n",
       " 'avg_conc_lasts5_1_away',\n",
       " 'avg_scr_lasts3_2_home',\n",
       " 'avg_scr_lasts5_2_home',\n",
       " 'avg_scr_lasts3_2_away',\n",
       " 'avg_scr_lasts5_2_away',\n",
       " 'avg_conc_lasts3_2_home',\n",
       " 'avg_conc_lasts5_2_home',\n",
       " 'avg_conc_lasts3_2_away',\n",
       " 'avg_conc_lasts5_2_away',\n",
       " 'avg_total_shots_lasts5_1_home',\n",
       " 'avg_total_shots_lasts5_1_away',\n",
       " 'avg_total_shots_lasts5_2_home',\n",
       " 'avg_total_shots_lasts5_2_away',\n",
       " 'avg_otarget_shots_lasts5_1_home',\n",
       " 'avg_otarget_shots_lasts5_1_away',\n",
       " 'avg_otarget_shots_lasts5_2_home',\n",
       " 'avg_otarget_shots_lasts5_2_away',\n",
       " 'avg_out_shots_lasts5_1_home',\n",
       " 'avg_out_shots_lasts5_1_away',\n",
       " 'avg_out_shots_lasts5_2_home',\n",
       " 'avg_out_shots_lasts5_2_away',\n",
       " 'avg_conc_total_shots_lasts5_1_home',\n",
       " 'avg_conc_total_shots_lasts5_1_away',\n",
       " 'avg_conc_total_shots_lasts5_2_home',\n",
       " 'avg_conc_total_shots_lasts5_2_away',\n",
       " 'avg_corners_lasts5_1_home',\n",
       " 'avg_corners_lasts5_1_away',\n",
       " 'avg_corners_conc_lasts5_1_home',\n",
       " 'avg_corners_conc_lasts5_1_away',\n",
       " 'avg_corners_lasts5_2_home',\n",
       " 'avg_corners_lasts5_2_away',\n",
       " 'avg_corners_conc_lasts5_2_home',\n",
       " 'avg_corners_conc_lasts5_2_away',\n",
       " 'avg_fouls_lasts5_1_home',\n",
       " 'avg_fouls_lasts5_1_away',\n",
       " 'avg_fouls_conc_lasts5_1_home',\n",
       " 'avg_fouls_conc_lasts5_1_away',\n",
       " 'avg_fouls_lasts5_2_home',\n",
       " 'avg_fouls_lasts5_2_away',\n",
       " 'avg_fouls_conc_lasts5_2_home',\n",
       " 'avg_fouls_conc_lasts5_2_away',\n",
       " 'avg_points_lasts5_1',\n",
       " 'avg_points_lasts5_2',\n",
       " 'championship_points_1',\n",
       " 'championship_points_2',\n",
       " 'rested_4_days_or_more_1',\n",
       " 'rested_4_days_or_more_2',\n",
       " 'team1_losing_streak',\n",
       " 'team1_strength',\n",
       " 'team1_undefeated_streak',\n",
       " 'team1_winning_streak',\n",
       " 'team1_without_winning_streak',\n",
       " 'team2_losing_streak',\n",
       " 'team2_strength',\n",
       " 'team2_undefeated_streak',\n",
       " 'team2_winning_streak',\n",
       " 'team2_without_winning_streak',\n",
       " 'team1_suspended_players',\n",
       " 'team2_suspended_players']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. 10.  4.  0. 15.  9.  8.  5.  6.  7.  3. 12. 11. 14.  2. 13.]\n"
     ]
    }
   ],
   "source": [
    "y1_uniques = datatotal['team1_corners'].unique()\n",
    "print(y1_uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem de ocorrências para y1:\n",
      "team1_corners\n",
      "0      695\n",
      "1     2435\n",
      "2     5027\n",
      "3     7578\n",
      "4     9210\n",
      "5     9504\n",
      "6     8627\n",
      "7     7240\n",
      "8     5578\n",
      "9     3952\n",
      "10    2777\n",
      "11    1818\n",
      "12    1112\n",
      "13     711\n",
      "14     416\n",
      "15     462\n",
      "16       0\n",
      "17       0\n",
      "18       0\n",
      "19       0\n",
      "20       0\n",
      "21       0\n",
      "22       0\n",
      "23       0\n",
      "24       0\n",
      "25       0\n",
      "26       0\n",
      "27       0\n",
      "28       0\n",
      "29       0\n",
      "30       0\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Contagem de ocorrências para y2:\n",
      "team2_corners\n",
      "0      1556\n",
      "1      4940\n",
      "2      8154\n",
      "3     10281\n",
      "4     10644\n",
      "5      9473\n",
      "6      7390\n",
      "7      5630\n",
      "8      3583\n",
      "9      2336\n",
      "10     1369\n",
      "11      847\n",
      "12      415\n",
      "13      283\n",
      "14      137\n",
      "15      104\n",
      "16        0\n",
      "17        0\n",
      "18        0\n",
      "19        0\n",
      "20        0\n",
      "21        0\n",
      "22        0\n",
      "23        0\n",
      "24        0\n",
      "25        0\n",
      "26        0\n",
      "27        0\n",
      "28        0\n",
      "29        0\n",
      "30        0\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contar ocorrências para 'y1'\n",
    "y1_counts = y1.value_counts().sort_index().reindex(range(0, 31), fill_value=0)\n",
    "print(\"Contagem de ocorrências para y1:\")\n",
    "print(y1_counts)\n",
    "\n",
    "# Contar ocorrências para 'y2'\n",
    "y2_counts = y2.value_counts().sort_index().reindex(range(0, 31), fill_value=0)\n",
    "print(\"\\nContagem de ocorrências para y2:\")\n",
    "print(y2_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando o treino e o teste e a normalização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas variáveis abaixo estão sendo criadas de forma idêntica, apenas para ter significado semântico em relação "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Dividindo os dados com base na coluna 'season'\n",
    "X_train = X[X['season'] < 2022].drop(['team1', 'team2', 'championship', 'season'], axis=1)\n",
    "X_test = X[X['season'] >= 2022].drop(['team1', 'team2', 'championship', 'season'], axis=1)\n",
    "y_train1 = y1[X['season'] < 2022]\n",
    "y_test1 = y1[X['season'] >= 2022]\n",
    "y_train2 = y2[X['season'] < 2022]\n",
    "y_test2 = y2[X['season'] >= 2022]\n",
    "\n",
    "# Escalando apenas as colunas que você quer (ajuste isso conforme suas necessidades)\n",
    "cols_to_scale = [col for col in future_matches_calculado.columns if col not in ['team1', 'team2', 'championship']]\n",
    "\n",
    "# Ajustar o escalonador com base no conjunto de treinamento\n",
    "scaler = StandardScaler().fit(X_train[cols_to_scale])\n",
    "\n",
    "# Reordenar as colunas para corresponder à ordem usada para ajustar o escalonador\n",
    "X_train = X_train[cols_to_scale]\n",
    "X_test = X_test[cols_to_scale]\n",
    "\n",
    "# Aplicar o escalonamento\n",
    "future_matches_calculado_scaled = future_matches_calculado.copy()\n",
    "future_matches_calculado_scaled[cols_to_scale] = scaler.transform(future_matches_calculado[cols_to_scale])\n",
    "\n",
    "# Transformar os conjuntos de treinamento e teste\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Preparar as colunas para o embedding\n",
    "X_train_embed = X[X['season'] < 2022][['team1', 'team2', 'championship']]\n",
    "X_test_embed = X[X['season'] >= 2022][['team1', 'team2', 'championship']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['team1_big_wins_last5',\n",
       " 'team1_big_losses_last5',\n",
       " 'team2_big_wins_last5',\n",
       " 'team2_big_losses_last5',\n",
       " 'team1_ah-2.5_wins_last5',\n",
       " 'team1_ah-2.5_losses_last5',\n",
       " 'team2_ah-2.5_wins_last5',\n",
       " 'team2_ah-2.5_losses_last5',\n",
       " 'team1_ah+2.5_wins_last5',\n",
       " 'team1_ah+2.5_losses_last5',\n",
       " 'team2_ah+2.5_wins_last5',\n",
       " 'team2_ah+2.5_losses_last5',\n",
       " 'team1_over3.5_last5',\n",
       " 'team1_under3.5_last5',\n",
       " 'team2_over3.5_last5',\n",
       " 'team2_under3.5_last5',\n",
       " 'team1_over4.5_last5',\n",
       " 'team1_under4.5_last5',\n",
       " 'team2_over4.5_last5',\n",
       " 'team2_under4.5_last5',\n",
       " 'team1_over6.5_last5',\n",
       " 'team1_under6.5_last5',\n",
       " 'team2_over6.5_last5',\n",
       " 'team2_under6.5_last5',\n",
       " 'avg_scr_lasts3_1_home',\n",
       " 'avg_scr_lasts5_1_home',\n",
       " 'avg_scr_lasts3_1_away',\n",
       " 'avg_scr_lasts5_1_away',\n",
       " 'avg_conc_lasts3_1_home',\n",
       " 'avg_conc_lasts5_1_home',\n",
       " 'avg_conc_lasts3_1_away',\n",
       " 'avg_conc_lasts5_1_away',\n",
       " 'avg_scr_lasts3_2_home',\n",
       " 'avg_scr_lasts5_2_home',\n",
       " 'avg_scr_lasts3_2_away',\n",
       " 'avg_scr_lasts5_2_away',\n",
       " 'avg_conc_lasts3_2_home',\n",
       " 'avg_conc_lasts5_2_home',\n",
       " 'avg_conc_lasts3_2_away',\n",
       " 'avg_conc_lasts5_2_away',\n",
       " 'avg_total_shots_lasts5_1_home',\n",
       " 'avg_total_shots_lasts5_1_away',\n",
       " 'avg_total_shots_lasts5_2_home',\n",
       " 'avg_total_shots_lasts5_2_away',\n",
       " 'avg_otarget_shots_lasts5_1_home',\n",
       " 'avg_otarget_shots_lasts5_1_away',\n",
       " 'avg_otarget_shots_lasts5_2_home',\n",
       " 'avg_otarget_shots_lasts5_2_away',\n",
       " 'avg_out_shots_lasts5_1_home',\n",
       " 'avg_out_shots_lasts5_1_away',\n",
       " 'avg_out_shots_lasts5_2_home',\n",
       " 'avg_out_shots_lasts5_2_away',\n",
       " 'avg_conc_total_shots_lasts5_1_home',\n",
       " 'avg_conc_total_shots_lasts5_1_away',\n",
       " 'avg_conc_total_shots_lasts5_2_home',\n",
       " 'avg_conc_total_shots_lasts5_2_away',\n",
       " 'avg_corners_lasts5_1_home',\n",
       " 'avg_corners_lasts5_1_away',\n",
       " 'avg_corners_conc_lasts5_1_home',\n",
       " 'avg_corners_conc_lasts5_1_away',\n",
       " 'avg_corners_lasts5_2_home',\n",
       " 'avg_corners_lasts5_2_away',\n",
       " 'avg_corners_conc_lasts5_2_home',\n",
       " 'avg_corners_conc_lasts5_2_away',\n",
       " 'avg_fouls_lasts5_1_home',\n",
       " 'avg_fouls_lasts5_1_away',\n",
       " 'avg_fouls_conc_lasts5_1_home',\n",
       " 'avg_fouls_conc_lasts5_1_away',\n",
       " 'avg_fouls_lasts5_2_home',\n",
       " 'avg_fouls_lasts5_2_away',\n",
       " 'avg_fouls_conc_lasts5_2_home',\n",
       " 'avg_fouls_conc_lasts5_2_away',\n",
       " 'team1_winning_streak',\n",
       " 'team1_undefeated_streak',\n",
       " 'team1_losing_streak',\n",
       " 'team1_without_winning_streak',\n",
       " 'avg_points_lasts5_1',\n",
       " 'team1_strength',\n",
       " 'championship_points_1',\n",
       " 'rested_4_days_or_more_1',\n",
       " 'team2_winning_streak',\n",
       " 'team2_undefeated_streak',\n",
       " 'team2_losing_streak',\n",
       " 'team2_without_winning_streak',\n",
       " 'avg_points_lasts5_2',\n",
       " 'team2_strength',\n",
       " 'championship_points_2',\n",
       " 'rested_4_days_or_more_2',\n",
       " 'team1_suspended_players',\n",
       " 'team2_suspended_players']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61353, 90)\n",
      "(5789, 90)\n",
      "(61353,)\n",
      "(5789,)\n",
      "(61353,)\n",
      "(5789,)\n",
      "(61353, 3)\n",
      "(5789, 3)\n",
      "(43, 93)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape)\n",
    "print(X_test_scaled.shape)\n",
    "print(y_train1.shape)\n",
    "print(y_test1.shape)\n",
    "print(y_train2.shape)\n",
    "print(y_test2.shape)\n",
    "print(X_train_embed.shape)\n",
    "print(X_test_embed.shape)\n",
    "print(future_matches_calculado_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função de perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import tensorflow as tf\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, [-1])\n",
    "    y_pred = tf.reshape(y_pred, [-1])\n",
    "\n",
    "    avg = tf.reduce_mean(y_true)\n",
    "    abs_error = tf.abs(y_true - y_pred)\n",
    "    distance_to_avg = tf.abs(y_pred - avg)\n",
    "    reward = tf.math.log(distance_to_avg + 3)\n",
    "    penalty = 2 * abs_error / (distance_to_avg + 3)\n",
    "    \n",
    "    # Aplicando a função tanh ao resultado de (penalty - reward)\n",
    "    normalized_diff = tf.math.tanh(penalty - reward)\n",
    "    \n",
    "    # Somando com abs_error\n",
    "    custom_loss_value = abs_error + normalized_diff\n",
    "    \n",
    "    # Garantindo que o valor mínimo da perda seja 0.0001\n",
    "    custom_loss_value = tf.maximum(custom_loss_value, 0.0001)\n",
    "    \n",
    "    return tf.reduce_mean(custom_loss_value)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def custom_unified_loss(y_true, y_pred):\n",
    "    # Separar y_true e y_pred para cada time\n",
    "    y_true_team1, y_true_team2 = y_true[:, 0], y_true[:, 1]\n",
    "    y_pred_team1, y_pred_team2 = y_pred[:, 0], y_pred[:, 1]\n",
    "    \n",
    "    # Calcular a média para cada time\n",
    "    avg1 = tf.reduce_mean(y_true_team1)\n",
    "    avg2 = tf.reduce_mean(y_true_team2)\n",
    "\n",
    "    # Calcular o erro absoluto relativo para cada time\n",
    "    normalized_error_team1 = tf.abs(y_true[:, 0] - y_pred[:, 0]) \n",
    "    normalized_error_team2 = tf.abs(y_true[:, 1] - y_pred[:, 1]) *(avg1/avg2)\n",
    "    abs_error = (normalized_error_team1 + normalized_error_team2) / 2\n",
    "\n",
    "    #_val_mae_diff = np.mean(np.abs((val_predict[:, 0] - val_predict[:, 1]) - (val_targ[:, 0] - val_targ[:, 1])))\n",
    "       # ...\n",
    "    dif_prev = (y_pred_team1 - y_pred_team2)\n",
    "    dif_true = (y_true_team1 - y_true_team2)\n",
    "    \n",
    "    # Calcula a diferença absoluta entre as diferenças previstas e verdadeiras\n",
    "    abs_diff = tf.abs(dif_prev - dif_true)\n",
    "    \n",
    "    # Calcula um termo de bônus usando a função sigmoidal\n",
    "    bonus_term = tf.math.tanh(10 * (1 - abs_diff))\n",
    "    \n",
    "    # Se a diferença é maior ou igual a 4 (ou menor ou igual a -4), aplica um fator negativo\n",
    "    condition1 = tf.logical_and(dif_true >= 4, dif_prev >= 4)\n",
    "    condition2 = tf.logical_and(dif_true <= -4, dif_prev <= -4)\n",
    "    condition3 = abs_diff <= 1.5\n",
    "\n",
    "    final_condition = tf.logical_or(tf.logical_or(condition1, condition2), condition3)\n",
    "\n",
    "    abs_diff_acc = tf.where(final_condition, -1 * (abs_diff + bonus_term), abs_diff + bonus_term)\n",
    "\n",
    "\n",
    "    # Calcular a diferença entre as previsões para as médias\n",
    "    distance_to_avg1 = tf.abs(y_pred_team1 - avg1)\n",
    "    distance_to_avg2 = tf.abs(y_pred_team2 - avg2)\n",
    "    \n",
    "    # Calcular os rewards\n",
    "    reward1 = tf.math.log(distance_to_avg1 + 1)\n",
    "    reward2 = tf.math.log(distance_to_avg2 + 1)\n",
    "\n",
    "    # Calcular as penalties\n",
    "    penalty1 = 1 * normalized_error_team1 / (distance_to_avg1 + 1)\n",
    "    penalty2 = 1 * normalized_error_team2 / (distance_to_avg2 + 1)    \n",
    "\n",
    "    # Aplicando a função tanh ao resultado de (penalty - reward)\n",
    "    normalized_diff1 = tf.math.tanh(penalty1 - reward1)\n",
    "    normalized_diff2 = tf.math.tanh(penalty2 - reward2)\n",
    "    normalized_diff = tf.math.tanh((normalized_diff1 + normalized_diff2)/2)\n",
    "\n",
    "    # combined_error\n",
    "    combined_error = abs_error + abs_diff_acc + normalized_diff\n",
    "    \n",
    "    # Garantindo que o valor mínimo da perda seja 0.0001\n",
    "    combined_error_value = tf.maximum(combined_error, 0.0001)\n",
    "\n",
    "    return tf.reduce_mean(combined_error_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testes de funções de perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward1: [2.1282318], penalty1: [1.0714287], normalized_diff1: [-0.7844373]\n",
      "reward2: [2.3418057], penalty2: [0.], normalized_diff2: [-0.9816783]\n",
      "bonus_term [-1.]--> abs_diff_acc: [8.], abs_error: [4.5], normalized_diff: [-0.70794797]\n",
      "y_true_team1: 5, y_pred_team1: 14, y_true_team2: 14, y_pred_team2: 14, Loss: 11.7921\n",
      "\n",
      "reward1: [1.8870696], penalty1: [0.15151516], normalized_diff1: [-0.93970895]\n",
      "reward2: [0.3364723], penalty2: [9.223602], normalized_diff2: [1.]\n",
      "bonus_term [-1.]--> abs_diff_acc: [-9.], abs_error: [6.956522], normalized_diff: [0.0301364]\n",
      "y_true_team1: 0, y_pred_team1: 1, y_true_team2: 14, y_pred_team2: 5, Loss: 0.0001\n",
      "\n",
      "reward1: [2.1282318], penalty1: [0.71428573], normalized_diff1: [-0.88832915]\n",
      "reward2: [1.2809339], penalty2: [0.39855075], normalized_diff2: [-0.7076112]\n",
      "bonus_term [-1.]--> abs_diff_acc: [-6.], abs_error: [3.7173913], normalized_diff: [-0.66290045]\n",
      "y_true_team1: 8, y_pred_team1: 14, y_true_team2: 3, y_pred_team2: 2, Loss: 0.0001\n",
      "\n",
      "reward1: [0.9555114], penalty1: [3.4615386], normalized_diff1: [0.9867736]\n",
      "reward2: [1.5260563], penalty2: [0.31190926], normalized_diff2: [-0.8379192]\n",
      "bonus_term [-1.]--> abs_diff_acc: [-9.], abs_error: [5.2173915], normalized_diff: [0.07429009]\n",
      "y_true_team1: 14, y_pred_team1: 5, y_true_team2: 0, y_pred_team2: 1, Loss: 0.0001\n",
      "\n",
      "reward1: [2.00148], penalty1: [0.8108108], normalized_diff1: [-0.83078647]\n",
      "reward2: [2.00148], penalty2: [0.5816686], normalized_diff2: [-0.8895596]\n",
      "bonus_term [-1.]--> abs_diff_acc: [2.], abs_error: [5.152174], normalized_diff: [-0.6963468]\n",
      "y_true_team1: 7, y_pred_team1: 13, y_true_team2: 8, y_pred_team2: 11, Loss: 6.4558\n",
      "\n",
      "reward1: [1.5260563], penalty1: [0.65217394], normalized_diff1: [-0.70334125]\n",
      "reward2: [1.7227666], penalty2: [2.5621119], normalized_diff2: [0.6854621]\n",
      "bonus_term [-1.]--> abs_diff_acc: [12.], abs_error: [8.673913], normalized_diff: [-0.00893932]\n",
      "y_true_team1: 0, y_pred_team1: 3, y_true_team2: 10, y_pred_team2: 0, Loss: 20.6650\n",
      "\n",
      "reward1: [0.9555114], penalty1: [3.0769231], normalized_diff1: [0.971673]\n",
      "reward2: [2.2407095], penalty2: [0.7631823], normalized_diff2: [-0.9010036]\n",
      "bonus_term [-1.]--> abs_diff_acc: [12.], abs_error: [7.5869565], normalized_diff: [0.03532]\n",
      "y_true_team1: 13, y_pred_team1: 5, y_true_team2: 8, y_pred_team2: 13, Loss: 19.6223\n",
      "\n",
      "reward1: [2.1282318], penalty1: [0.59523815], normalized_diff1: [-0.91093546]\n",
      "reward2: [0.47000358], penalty2: [3.5869567], normalized_diff2: [0.99608403]\n",
      "bonus_term [0.]--> abs_diff_acc: [-1.], abs_error: [5.369565], normalized_diff: [0.04254858]\n",
      "y_true_team1: 9, y_pred_team1: 14, y_true_team2: 0, y_pred_team2: 4, Loss: 4.4121\n",
      "\n",
      "reward1: [2.2407095], penalty1: [0.7446809], normalized_diff1: [-0.90442806]\n",
      "reward2: [1.5260563], penalty2: [0.31190926], normalized_diff2: [-0.8379192]\n",
      "bonus_term [-1.]--> abs_diff_acc: [-7.], abs_error: [4.2173915], normalized_diff: [-0.7019699]\n",
      "y_true_team1: 8, y_pred_team1: 15, y_true_team2: 2, y_pred_team2: 1, Loss: 0.0001\n",
      "\n",
      "reward1: [2.00148], penalty1: [1.7567568], normalized_diff1: [-0.23995212]\n",
      "reward2: [1.4816046], penalty2: [0.6521739], normalized_diff2: [-0.68017024]\n",
      "bonus_term [-1.]--> abs_diff_acc: [14.], abs_error: [7.9347825], normalized_diff: [-0.4301341]\n",
      "y_true_team1: 0, y_pred_team1: 13, y_true_team2: 10, y_pred_team2: 8, Loss: 21.5046\n",
      "\n",
      "reward1: [1.8870696], penalty1: [0.15151516], normalized_diff1: [-0.93970895]\n",
      "reward2: [2.4336133], penalty2: [0.12585813], normalized_diff2: [-0.9803998]\n",
      "bonus_term [-1.]--> abs_diff_acc: [-1.], abs_error: [1.2173913], normalized_diff: [-0.74430114]\n",
      "y_true_team1: 2, y_pred_team1: 1, y_true_team2: 14, y_pred_team2: 15, Loss: 0.0001\n",
      "\n",
      "reward1: [1.8870696], penalty1: [1.8181819], normalized_diff1: [-0.06877894]\n",
      "reward2: [1.686399], penalty2: [0.2657005], normalized_diff2: [-0.8897446]\n",
      "bonus_term [-1.]--> abs_diff_acc: [10.], abs_error: [6.7173915], normalized_diff: [-0.44565216]\n",
      "y_true_team1: 13, y_pred_team1: 1, y_true_team2: 10, y_pred_team2: 9, Loss: 16.2717\n",
      "\n",
      "reward1: [1.5260563], penalty1: [2.173913], normalized_diff1: [0.5702253]\n",
      "reward2: [0.9555114], penalty2: [3.8628764], normalized_diff2: [0.9940513]\n",
      "bonus_term [-1.]--> abs_diff_acc: [2.], abs_error: [10.021739], normalized_diff: [0.65393233]\n",
      "y_true_team1: 13, y_pred_team1: 3, y_true_team2: 10, y_pred_team2: 3, Loss: 12.6757\n",
      "\n",
      "reward1: [2.1282318], penalty1: [1.1904763], normalized_diff1: [-0.7341893]\n",
      "reward2: [1.2809339], penalty2: [0.39855075], normalized_diff2: [-0.7076112]\n",
      "bonus_term [-1.]--> abs_diff_acc: [10.], abs_error: [5.7173915], normalized_diff: [-0.6174666]\n",
      "y_true_team1: 4, y_pred_team1: 14, y_true_team2: 3, y_pred_team2: 2, Loss: 15.0999\n",
      "\n",
      "reward1: [2.0281482], penalty1: [1.7105263], normalized_diff1: [-0.30735496]\n",
      "reward2: [2.00148], penalty2: [0.19388954], normalized_diff2: [-0.94758636]\n",
      "bonus_term [-1.]--> abs_diff_acc: [13.], abs_error: [7.2173915], normalized_diff: [-0.55630815]\n",
      "y_true_team1: 13, y_pred_team1: 0, y_true_team2: 10, y_pred_team2: 11, Loss: 19.6611\n",
      "\n",
      "reward1: [1.4816046], penalty1: [0.45454544], normalized_diff1: [-0.7727262]\n",
      "reward2: [1.2809339], penalty2: [1.9927536], normalized_diff2: [0.61181664]\n",
      "bonus_term [-1.]--> abs_diff_acc: [-2.], abs_error: [4.5869565], normalized_diff: [-0.08028162]\n",
      "y_true_team1: 12, y_pred_team1: 10, y_true_team2: 7, y_pred_team2: 2, Loss: 2.5067\n",
      "\n",
      "reward1: [1.2809339], penalty1: [1.9444445], normalized_diff1: [0.58069503]\n",
      "reward2: [0.47000358], penalty2: [8.967392], normalized_diff2: [1.]\n",
      "bonus_term [-1.]--> abs_diff_acc: [2.], abs_error: [10.673913], normalized_diff: [0.6586058]\n",
      "y_true_team1: 11, y_pred_team1: 4, y_true_team2: 14, y_pred_team2: 4, Loss: 13.3325\n",
      "\n",
      "reward1: [0.8754688], penalty1: [3.3333333], normalized_diff1: [0.985446]\n",
      "reward2: [1.2237755], penalty2: [0.], normalized_diff2: [-0.8407644]\n",
      "bonus_term [-1.]--> abs_diff_acc: [7.], abs_error: [4.], normalized_diff: [0.07221486]\n",
      "y_true_team1: 0, y_pred_team1: 8, y_true_team2: 7, y_pred_team2: 7, Loss: 11.0722\n",
      "\n",
      "reward1: [2.1282318], penalty1: [1.3095238], normalized_diff1: [-0.67436606]\n",
      "reward2: [2.00148], penalty2: [0.7755582], normalized_diff2: [-0.8413924]\n",
      "bonus_term [-1.]--> abs_diff_acc: [6.], abs_error: [8.369565], normalized_diff: [-0.6398261]\n",
      "y_true_team1: 3, y_pred_team1: 14, y_true_team2: 7, y_pred_team2: 11, Loss: 13.7297\n",
      "\n",
      "reward1: [0.9555114], penalty1: [0.7692308], normalized_diff1: [-0.18415542]\n",
      "reward2: [0.3364723], penalty2: [10.248446], normalized_diff2: [1.]\n",
      "bonus_term [-1.]--> abs_diff_acc: [11.], abs_error: [8.173913], normalized_diff: [0.3867071]\n",
      "y_true_team1: 3, y_pred_team1: 5, y_true_team2: 15, y_pred_team2: 5, Loss: 19.5606\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def custom_unified_loss2(y_true, y_pred):\n",
    "    # Separar y_true e y_pred para cada time\n",
    "    y_true_team1, y_true_team2 = y_true[:, 0], y_true[:, 1]\n",
    "    y_pred_team1, y_pred_team2 = y_pred[:, 0], y_pred[:, 1]\n",
    "    \n",
    "    # Calcular a média para cada time\n",
    "    avg1 = 6.6\n",
    "    avg2 = 4.6\n",
    "\n",
    "    # Calcular o erro absoluto relativo para cada time\n",
    "    normalized_error_team1 = tf.abs(y_true[:, 0] - y_pred[:, 0]) \n",
    "    normalized_error_team2 = tf.abs(y_true[:, 1] - y_pred[:, 1]) *(avg1/avg2)\n",
    "    abs_error = (normalized_error_team1 + normalized_error_team2) / 2\n",
    "\n",
    "    #_val_mae_diff = np.mean(np.abs((val_predict[:, 0] - val_predict[:, 1]) - (val_targ[:, 0] - val_targ[:, 1])))\n",
    "       # ...\n",
    "    dif_prev = (y_pred_team1 - y_pred_team2)\n",
    "    dif_true = (y_true_team1 - y_true_team2)\n",
    "    \n",
    "    # Calcula a diferença absoluta entre as diferenças previstas e verdadeiras\n",
    "    abs_diff = tf.abs(dif_prev - dif_true)\n",
    "    \n",
    "    # Calcula um termo de bônus usando a função sigmoidal\n",
    "    bonus_term = tf.math.tanh(10 * (1 - abs_diff))\n",
    "    \n",
    "    # Se a diferença é maior ou igual a 4 (ou menor ou igual a -4), aplica um fator negativo\n",
    "    if (dif_true >= 4 and dif_prev >= 4) or (dif_true <= -4 and dif_prev <= -4) or (abs_diff <= 1.5):\n",
    "        abs_diff_acc = -1 * (abs_diff + bonus_term)\n",
    "    else:\n",
    "        abs_diff_acc = abs_diff + bonus_term\n",
    "\n",
    "\n",
    "    # Calcular a diferença entre as previsões para as médias\n",
    "    distance_to_avg1 = tf.abs(y_pred_team1 - avg1)\n",
    "    distance_to_avg2 = tf.abs(y_pred_team2 - avg2)\n",
    "    \n",
    "    # Calcular os rewards\n",
    "    reward1 = tf.math.log(distance_to_avg1 + 1)\n",
    "    reward2 = tf.math.log(distance_to_avg2 + 1)\n",
    "\n",
    "    # Calcular as penalties\n",
    "    penalty1 = 1 * normalized_error_team1 / (distance_to_avg1 + 1)\n",
    "    penalty2 = 1 * normalized_error_team2 / (distance_to_avg2 + 1)    \n",
    "\n",
    "    # Aplicando a função tanh ao resultado de (penalty - reward)\n",
    "    normalized_diff1 = tf.math.tanh(penalty1 - reward1)\n",
    "    normalized_diff2 = tf.math.tanh(penalty2 - reward2)\n",
    "    normalized_diff = tf.math.tanh((normalized_diff1 + normalized_diff2)/2)\n",
    "\n",
    "    # Print rewards, penalties, and normalized_diff\n",
    "    print(f\"reward1: {reward1.numpy()}, penalty1: {penalty1.numpy()}, normalized_diff1: {normalized_diff1.numpy()}\")\n",
    "    print(f\"reward2: {reward2.numpy()}, penalty2: {penalty2.numpy()}, normalized_diff2: {normalized_diff2.numpy()}\")\n",
    "    print(f\"bonus_term {bonus_term.numpy()}--> abs_diff_acc: {abs_diff_acc.numpy()}, abs_error: {abs_error.numpy()}, normalized_diff: {normalized_diff.numpy()}\")  # Novo valor impresso\n",
    "\n",
    "\n",
    "    # combined_error\n",
    "    combined_error = abs_error + abs_diff_acc + normalized_diff\n",
    "    \n",
    "    # Garantindo que o valor mínimo da perda seja 0.0001\n",
    "    combined_error_value = tf.maximum(combined_error, 0.0001)\n",
    "\n",
    "    return tf.reduce_mean(combined_error_value)\n",
    "\n",
    "# Loop para gerar valores aleatórios e calcular a perda\n",
    "for _ in range(20):\n",
    "    # Gerando valores aleatórios para y_true e y_pred\n",
    "    y_true_sample = np.random.randint(0, 16, size=(1, 2))\n",
    "    y_pred_sample = np.random.randint(0, 16, size=(1, 2))\n",
    "    \n",
    "    # Convertendo para tensores do TensorFlow\n",
    "    y_true_tensor = tf.convert_to_tensor(y_true_sample, dtype=tf.float32)\n",
    "    y_pred_tensor = tf.convert_to_tensor(y_pred_sample, dtype=tf.float32)\n",
    "    \n",
    "    # Calculando a perda\n",
    "    loss_value = custom_unified_loss2(y_true_tensor, y_pred_tensor).numpy()\n",
    "    \n",
    "    # Imprimindo os resultados\n",
    "    print(f\"y_true_team1: {y_true_sample[0][0]}, y_pred_team1: {y_pred_sample[0][0]}, y_true_team2: {y_true_sample[0][1]}, y_pred_team2: {y_pred_sample[0][1]}, Loss: {loss_value:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenando ambos Ys em um único tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61353, 3)\n",
      "(5789, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Suponha que y_train1 e y_train2 são seus vetores de saída originais\n",
    "# Eles têm o shape (comprimento,)\n",
    "\n",
    "# Calcular a diferença entre y_train1 e y_train2\n",
    "y_train_diff = y_train1 - y_train2\n",
    "y_test_diff = y_test1 - y_test2\n",
    "# Concatenar ao longo de uma nova dimensão para criar um tensor de saída com shape (comprimento, 3)\n",
    "y_train_combined = np.stack((y_train1, y_train2, y_train_diff), axis=-1)\n",
    "y_test_combined = np.stack((y_test1, y_test2, y_test_diff), axis=-1)\n",
    "\n",
    "\n",
    "print(y_train_combined.shape)\n",
    "print(y_test_combined.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arquitetura da NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ==== Parte 1: Definindo os Inputs para o Embedding ====\n",
    "# Estes são os inputs que vão alimentar os embeddings. \n",
    "# Cada input tem a dimensão de (1,) porque cada jogo tem exatamente um 'team1', um 'team2', e um 'championship'.\n",
    "team1_input = Input(shape=(1,), name='Team1-Input')\n",
    "team2_input = Input(shape=(1,), name='Team2-Input')\n",
    "champ_input = Input(shape=(1,), name='Championship-Input')\n",
    "\n",
    "# ==== Parte 2: Criando os Embeddings ====\n",
    "# n_teams e n_champ são o número de times e campeonatos únicos, respectivamente.\n",
    "# O output_dim é um hiperparâmetro para você ajustar. Ele define o tamanho do espaço de embedding.\n",
    "\n",
    "# Embedding para o time 1\n",
    "team1_embedding = Embedding(input_dim=n_teams, output_dim=50, name='Team1-Embedding')(team1_input)  # output_dim ajustável\n",
    "\n",
    "# Embedding para o time 2\n",
    "team2_embedding = Embedding(input_dim=n_teams, output_dim=50, name='Team2-Embedding')(team2_input)  # output_dim ajustável\n",
    "\n",
    "# Embedding para o campeonato\n",
    "champ_embedding = Embedding(input_dim=n_champ, output_dim=5, name='Championship-Embedding')(champ_input)  # output_dim ajustável\n",
    "\n",
    "# ==== Parte 3: Achatando os Embeddings ====\n",
    "# Cada embedding precisa ser achatado para ser concatenado posteriormente\n",
    "team1_embedding = Flatten()(team1_embedding)\n",
    "team2_embedding = Flatten()(team2_embedding)\n",
    "champ_embedding = Flatten()(champ_embedding)\n",
    "\n",
    "# ==== Parte 4: Outras Características ====\n",
    "# Este é o input para as outras características (já escaladas) do seu conjunto de dados.\n",
    "other_features_input = Input(shape=(X_train_scaled.shape[1],), name='Other-Features-Input')\n",
    "\n",
    "# ==== Parte 5: Concatenando Tudo ====\n",
    "# Aqui, todos os embeddings e as outras características são concatenados em um único vetor\n",
    "merged = Concatenate()([team1_embedding, team2_embedding, champ_embedding, other_features_input])\n",
    "\n",
    "# ==== Parte 6: Camadas Ocultas ====\n",
    "# Estes são os neurônios e camadas totalmente conectadas (Dense) onde a \"aprendizagem\" real acontece.\n",
    "# Você pode ajustar o número de neurônios, a função de ativação, e outros hiperparâmetros aqui.\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "hidden_layer = Dense(1024, activation='relu', kernel_regularizer=l2(0.0001))(merged)\n",
    "hidden_layer = Dropout(0.2)(hidden_layer)\n",
    "\n",
    "hidden_layer = Dense(512, activation='tanh')(hidden_layer)\n",
    "hidden_layer = Dropout(0.2)(hidden_layer)\n",
    "\n",
    "hidden_layer = Dense(256, activation='tanh')(hidden_layer)\n",
    "hidden_layer = Dropout(0.2)(hidden_layer)\n",
    "\n",
    "hidden_layer = Dense(128, activation='tanh')(hidden_layer)\n",
    "hidden_layer = Dropout(0.2)(hidden_layer)\n",
    "\n",
    "hidden_layer = Dense(64, activation='tanh')(hidden_layer)\n",
    "hidden_layer = Dropout(0.2)(hidden_layer)\n",
    "\n",
    "hidden_layer = Dense(32, activation='tanh')(hidden_layer)\n",
    "hidden_layer = Dropout(0.2)(hidden_layer)\n",
    "\n",
    "#hidden_layer = Dense(8, activation='tanh')(hidden_layer)\n",
    "#hidden_layer = Dropout(0.2)(hidden_layer)\n",
    "\n",
    "# ==== Parte 7: Camada de Saída ====\n",
    "# Esta é a camada de saída. A função de ativação 'linear' é usada para regressão.\n",
    "output = Dense(3, activation='linear', name='Output-Layer')(hidden_layer)\n",
    "\n",
    "# ==== Parte 8: Compilando o Modelo ====\n",
    "# Finalmente, o modelo é compilado. O otimizador Adam é usado, com uma taxa de aprendizagem de 0.001.\n",
    "# A perda é definida como 'mean_squared_error', que é comum para problemas de regressão.\n",
    "model = Model(\n",
    "    inputs=[team1_input, team2_input, champ_input, other_features_input], \n",
    "    outputs=[output]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "480/480 [==============================] - 11s 17ms/step - loss: 4.9169 - mean_absolute_error: 2.6931 - val_loss: 4.7444 - val_mean_absolute_error: 2.5372\n",
      "181/181 [==============================] - 1s 2ms/step\n",
      " - val_mae_team1: 2.2408 - val_mae_team2: 2.0015 - val_mae_diff: 3.2469 - val_mae_diff_output: 3.3692\n",
      "Epoch 2/100\n",
      "480/480 [==============================] - 8s 17ms/step - loss: 4.8209 - mean_absolute_error: 2.6534 - val_loss: 4.6672 - val_mean_absolute_error: 2.5403\n",
      "181/181 [==============================] - 0s 2ms/step\n",
      " - val_mae_team1: 2.2379 - val_mae_team2: 1.9893 - val_mae_diff: 3.2382 - val_mae_diff_output: 3.3938\n",
      "Epoch 3/100\n",
      "480/480 [==============================] - 8s 17ms/step - loss: 4.7720 - mean_absolute_error: 2.6134 - val_loss: 4.6737 - val_mean_absolute_error: 2.5408\n",
      "181/181 [==============================] - 0s 2ms/step\n",
      " - val_mae_team1: 2.2656 - val_mae_team2: 2.0046 - val_mae_diff: 3.2505 - val_mae_diff_output: 3.3523\n",
      "Epoch 4/100\n",
      "480/480 [==============================] - 8s 17ms/step - loss: 4.7403 - mean_absolute_error: 2.6051 - val_loss: 4.6586 - val_mean_absolute_error: 2.5264\n",
      "181/181 [==============================] - 0s 2ms/step\n",
      " - val_mae_team1: 2.2550 - val_mae_team2: 1.9997 - val_mae_diff: 3.2438 - val_mae_diff_output: 3.3246\n",
      "Epoch 5/100\n",
      "480/480 [==============================] - 8s 17ms/step - loss: 4.7179 - mean_absolute_error: 2.5981 - val_loss: 4.7278 - val_mean_absolute_error: 2.5327\n",
      "181/181 [==============================] - 0s 2ms/step\n",
      " - val_mae_team1: 2.2560 - val_mae_team2: 2.0057 - val_mae_diff: 3.3018 - val_mae_diff_output: 3.3364\n",
      "Epoch 6/100\n",
      "480/480 [==============================] - 8s 17ms/step - loss: 4.7118 - mean_absolute_error: 2.6057 - val_loss: 4.6808 - val_mean_absolute_error: 2.5470\n",
      "181/181 [==============================] - 0s 2ms/step\n",
      " - val_mae_team1: 2.2588 - val_mae_team2: 2.0201 - val_mae_diff: 3.2599 - val_mae_diff_output: 3.3622\n",
      "Epoch 7/100\n",
      "480/480 [==============================] - 8s 17ms/step - loss: 4.6952 - mean_absolute_error: 2.5971 - val_loss: 4.6924 - val_mean_absolute_error: 2.5669\n",
      "181/181 [==============================] - 0s 2ms/step\n",
      " - val_mae_team1: 2.2843 - val_mae_team2: 2.0091 - val_mae_diff: 3.2501 - val_mae_diff_output: 3.4072\n",
      "Epoch 8/100\n",
      "480/480 [==============================] - 8s 17ms/step - loss: 4.6952 - mean_absolute_error: 2.5937 - val_loss: 4.6937 - val_mean_absolute_error: 2.5540\n",
      "181/181 [==============================] - 0s 2ms/step\n",
      " - val_mae_team1: 2.2660 - val_mae_team2: 2.0374 - val_mae_diff: 3.2649 - val_mae_diff_output: 3.3585\n",
      "Epoch 9/100\n",
      "480/480 [==============================] - 8s 17ms/step - loss: 4.6784 - mean_absolute_error: 2.5917 - val_loss: 4.6983 - val_mean_absolute_error: 2.5566\n",
      "181/181 [==============================] - 0s 2ms/step\n",
      " - val_mae_team1: 2.2942 - val_mae_team2: 1.9953 - val_mae_diff: 3.2647 - val_mae_diff_output: 3.3801\n",
      "Epoch 10/100\n",
      "480/480 [==============================] - 8s 18ms/step - loss: 4.6675 - mean_absolute_error: 2.5913 - val_loss: 4.7137 - val_mean_absolute_error: 2.5422\n",
      "181/181 [==============================] - 0s 3ms/step\n",
      " - val_mae_team1: 2.2598 - val_mae_team2: 2.0130 - val_mae_diff: 3.2738 - val_mae_diff_output: 3.3539\n",
      "Epoch 11/100\n",
      "480/480 [==============================] - 8s 17ms/step - loss: 4.6660 - mean_absolute_error: 2.5917 - val_loss: 4.7219 - val_mean_absolute_error: 2.5545\n",
      "181/181 [==============================] - 0s 2ms/step\n",
      " - val_mae_team1: 2.2674 - val_mae_team2: 2.0106 - val_mae_diff: 3.2847 - val_mae_diff_output: 3.3855\n",
      "Epoch 12/100\n",
      "480/480 [==============================] - 8s 17ms/step - loss: 4.6398 - mean_absolute_error: 2.5956 - val_loss: 4.7498 - val_mean_absolute_error: 2.5648\n",
      "181/181 [==============================] - 0s 2ms/step\n",
      " - val_mae_team1: 2.2823 - val_mae_team2: 2.0339 - val_mae_diff: 3.2891 - val_mae_diff_output: 3.3782\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "# Parâmetros para Early Stopping\n",
    "patience = 10\n",
    "best_val_mae_diff = np.inf\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "# Número de épocas\n",
    "n_epochs = 100\n",
    "\n",
    "# Compilando o modelo unificado\n",
    "model.compile(optimizer=Adam(0.001), loss=custom_unified_loss, metrics=['mean_absolute_error'])\n",
    "\n",
    "# Loop de treinamento\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "    \n",
    "    # Treinamento para uma época\n",
    "    history = model.fit(\n",
    "        [X_train_embed['team1'], X_train_embed['team2'], X_train_embed['championship'], X_train_scaled], \n",
    "        y_train_combined, \n",
    "        epochs=1,\n",
    "        batch_size=128,\n",
    "        verbose=1,\n",
    "        validation_data=([X_test_embed['team1'], X_test_embed['team2'], X_test_embed['championship'], X_test_scaled], y_test_combined)\n",
    "    )\n",
    "    \n",
    "    # Calculando métricas adicionais\n",
    "    val_predict = model.predict([X_test_embed['team1'], X_test_embed['team2'], X_test_embed['championship'], X_test_scaled])\n",
    "    val_targ = y_test_combined\n",
    "\n",
    "    _val_mae_team1 = np.mean(np.abs(val_predict[:, 0] - val_targ[:, 0]))\n",
    "    _val_mae_team2 = np.mean(np.abs(val_predict[:, 1] - val_targ[:, 1]))\n",
    "    _val_mae_diff = np.mean(np.abs((val_predict[:, 0] - val_predict[:, 1]) - (val_targ[:, 0] - val_targ[:, 1])))\n",
    "    _val_mae_diff_output = np.mean(np.abs(val_predict[:, 2] - val_targ[:, 2]))  # Nova métrica para a terceira saída\n",
    "\n",
    "    print(f\" - val_mae_team1: {_val_mae_team1:.4f} - val_mae_team2: {_val_mae_team2:.4f} - val_mae_diff: {_val_mae_diff:.4f} - val_mae_diff_output: {_val_mae_diff_output:.4f}\")\n",
    "\n",
    "    # Lógica de Early Stopping\n",
    "    if _val_mae_diff < best_val_mae_diff:\n",
    "        best_val_mae_diff = _val_mae_diff\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1901447772979736\n",
    "#1.996545672416687"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 93)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_matches_calculado_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>championship</th>\n",
       "      <th>team1_big_wins_last5</th>\n",
       "      <th>team1_big_losses_last5</th>\n",
       "      <th>team2_big_wins_last5</th>\n",
       "      <th>team2_big_losses_last5</th>\n",
       "      <th>team1_ah-2.5_wins_last5</th>\n",
       "      <th>team1_ah-2.5_losses_last5</th>\n",
       "      <th>team2_ah-2.5_wins_last5</th>\n",
       "      <th>...</th>\n",
       "      <th>team2_winning_streak</th>\n",
       "      <th>team2_undefeated_streak</th>\n",
       "      <th>team2_losing_streak</th>\n",
       "      <th>team2_without_winning_streak</th>\n",
       "      <th>avg_points_lasts5_2</th>\n",
       "      <th>team2_strength</th>\n",
       "      <th>championship_points_2</th>\n",
       "      <th>rested_4_days_or_more_2</th>\n",
       "      <th>team1_suspended_players</th>\n",
       "      <th>team2_suspended_players</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>533</td>\n",
       "      <td>519</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.907378</td>\n",
       "      <td>1.233839</td>\n",
       "      <td>-0.939662</td>\n",
       "      <td>1.319616</td>\n",
       "      <td>1.526092</td>\n",
       "      <td>-1.526092</td>\n",
       "      <td>-1.315635</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.569612</td>\n",
       "      <td>-0.360440</td>\n",
       "      <td>-0.525751</td>\n",
       "      <td>1.187144</td>\n",
       "      <td>-1.825696</td>\n",
       "      <td>-3.420264</td>\n",
       "      <td>-3.846691</td>\n",
       "      <td>0.443706</td>\n",
       "      <td>-0.334677</td>\n",
       "      <td>-0.305174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>515</td>\n",
       "      <td>499</td>\n",
       "      <td>21</td>\n",
       "      <td>1.257310</td>\n",
       "      <td>0.123596</td>\n",
       "      <td>0.117516</td>\n",
       "      <td>0.184672</td>\n",
       "      <td>-0.333442</td>\n",
       "      <td>0.333442</td>\n",
       "      <td>0.504801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986754</td>\n",
       "      <td>-0.059744</td>\n",
       "      <td>-0.525751</td>\n",
       "      <td>-0.690139</td>\n",
       "      <td>0.629454</td>\n",
       "      <td>2.914147</td>\n",
       "      <td>3.052626</td>\n",
       "      <td>0.443706</td>\n",
       "      <td>-0.334677</td>\n",
       "      <td>-0.305174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>471</td>\n",
       "      <td>472</td>\n",
       "      <td>2</td>\n",
       "      <td>0.174966</td>\n",
       "      <td>-0.986648</td>\n",
       "      <td>1.174694</td>\n",
       "      <td>-0.950273</td>\n",
       "      <td>-0.333442</td>\n",
       "      <td>0.333442</td>\n",
       "      <td>1.415019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208571</td>\n",
       "      <td>-0.360440</td>\n",
       "      <td>-0.525751</td>\n",
       "      <td>-0.690139</td>\n",
       "      <td>0.629454</td>\n",
       "      <td>0.934421</td>\n",
       "      <td>0.217290</td>\n",
       "      <td>0.443706</td>\n",
       "      <td>2.587813</td>\n",
       "      <td>-0.305174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>508</td>\n",
       "      <td>517</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.907378</td>\n",
       "      <td>-0.986648</td>\n",
       "      <td>-0.939662</td>\n",
       "      <td>0.184672</td>\n",
       "      <td>-0.333442</td>\n",
       "      <td>0.333442</td>\n",
       "      <td>-0.405417</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.569612</td>\n",
       "      <td>-0.360440</td>\n",
       "      <td>-0.525751</td>\n",
       "      <td>2.688970</td>\n",
       "      <td>-1.518802</td>\n",
       "      <td>-1.020477</td>\n",
       "      <td>-0.570303</td>\n",
       "      <td>0.443706</td>\n",
       "      <td>-0.334677</td>\n",
       "      <td>-0.305174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>479</td>\n",
       "      <td>502</td>\n",
       "      <td>2</td>\n",
       "      <td>2.339654</td>\n",
       "      <td>-0.986648</td>\n",
       "      <td>-0.939662</td>\n",
       "      <td>0.184672</td>\n",
       "      <td>0.596325</td>\n",
       "      <td>-0.596325</td>\n",
       "      <td>0.504801</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.569612</td>\n",
       "      <td>0.240951</td>\n",
       "      <td>-0.525751</td>\n",
       "      <td>-0.314683</td>\n",
       "      <td>0.322560</td>\n",
       "      <td>0.875556</td>\n",
       "      <td>1.162402</td>\n",
       "      <td>0.443706</td>\n",
       "      <td>-0.334677</td>\n",
       "      <td>-0.305174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      team1  team2  championship  team1_big_wins_last5  \\\n",
       "127     533    519             1             -0.907378   \n",
       "1031    515    499            21              1.257310   \n",
       "372     471    472             2              0.174966   \n",
       "373     508    517             2             -0.907378   \n",
       "374     479    502             2              2.339654   \n",
       "\n",
       "      team1_big_losses_last5  team2_big_wins_last5  team2_big_losses_last5  \\\n",
       "127                 1.233839             -0.939662                1.319616   \n",
       "1031                0.123596              0.117516                0.184672   \n",
       "372                -0.986648              1.174694               -0.950273   \n",
       "373                -0.986648             -0.939662                0.184672   \n",
       "374                -0.986648             -0.939662                0.184672   \n",
       "\n",
       "      team1_ah-2.5_wins_last5  team1_ah-2.5_losses_last5  \\\n",
       "127                  1.526092                  -1.526092   \n",
       "1031                -0.333442                   0.333442   \n",
       "372                 -0.333442                   0.333442   \n",
       "373                 -0.333442                   0.333442   \n",
       "374                  0.596325                  -0.596325   \n",
       "\n",
       "      team2_ah-2.5_wins_last5  ...  team2_winning_streak  \\\n",
       "127                 -1.315635  ...             -0.569612   \n",
       "1031                 0.504801  ...              0.986754   \n",
       "372                  1.415019  ...              0.208571   \n",
       "373                 -0.405417  ...             -0.569612   \n",
       "374                  0.504801  ...             -0.569612   \n",
       "\n",
       "      team2_undefeated_streak  team2_losing_streak  \\\n",
       "127                 -0.360440            -0.525751   \n",
       "1031                -0.059744            -0.525751   \n",
       "372                 -0.360440            -0.525751   \n",
       "373                 -0.360440            -0.525751   \n",
       "374                  0.240951            -0.525751   \n",
       "\n",
       "      team2_without_winning_streak  avg_points_lasts5_2  team2_strength  \\\n",
       "127                       1.187144            -1.825696       -3.420264   \n",
       "1031                     -0.690139             0.629454        2.914147   \n",
       "372                      -0.690139             0.629454        0.934421   \n",
       "373                       2.688970            -1.518802       -1.020477   \n",
       "374                      -0.314683             0.322560        0.875556   \n",
       "\n",
       "      championship_points_2  rested_4_days_or_more_2  team1_suspended_players  \\\n",
       "127               -3.846691                 0.443706                -0.334677   \n",
       "1031               3.052626                 0.443706                -0.334677   \n",
       "372                0.217290                 0.443706                 2.587813   \n",
       "373               -0.570303                 0.443706                -0.334677   \n",
       "374                1.162402                 0.443706                -0.334677   \n",
       "\n",
       "      team2_suspended_players  \n",
       "127                 -0.305174  \n",
       "1031                -0.305174  \n",
       "372                 -0.305174  \n",
       "373                 -0.305174  \n",
       "374                 -0.305174  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_matches_calculado_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 104ms/step\n",
      "Prediction for oud-heverlee leuven: 6.855722427368164 corners\n",
      "Prediction for kv kortrijk: 3.2748918533325195 corners\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prediction for ifk varnamo: 4.022220134735107 corners\n",
      "Prediction for elfsborg: 5.817602157592773 corners\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prediction for athletico-pr: 4.20367956161499 corners\n",
      "Prediction for atlético mineiro: 3.12150502204895 corners\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prediction for goiás: 4.142315864562988 corners\n",
      "Prediction for internacional: 3.116544246673584 corners\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prediction for botafogo: 5.75384521484375 corners\n",
      "Prediction for flamengo: 3.4216904640197754 corners\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prediction for halmstad: 4.136152267456055 corners\n",
      "Prediction for ik sirius: 3.1183035373687744 corners\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Prediction for kv mechelen: 4.36046028137207 corners\n",
      "Prediction for eupen: 3.084480047225952 corners\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Prediction for cercle brugge: 6.854557991027832 corners\n",
      "Prediction for kvc westerlo: 3.2629125118255615 corners\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Prediction for américa-mg: 4.715497016906738 corners\n",
      "Prediction for santos: 2.9107701778411865 corners\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Prediction for cruzeiro: 4.254647731781006 corners\n",
      "Prediction for red bull bragantino: 5.622119903564453 corners\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Prediction for norrkoping: 4.145750999450684 corners\n",
      "Prediction for djurgardens if: 3.129359006881714 corners\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Prediction for são paulo: 5.744995594024658 corners\n",
      "Prediction for coritiba: 3.1073031425476074 corners\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Prediction for degerfors if: 4.0643815994262695 corners\n",
      "Prediction for bk hacken: 5.807313919067383 corners\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Prediction for kalmar: 3.8752520084381104 corners\n",
      "Prediction for mjallby: 3.6333680152893066 corners\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Prediction for royal charleroi sc: 3.8877480030059814 corners\n",
      "Prediction for sint truiden: 4.156093597412109 corners\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Prediction for grêmio: 4.13936185836792 corners\n",
      "Prediction for cuiabá: 3.16922664642334 corners\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Prediction for fluminense: 5.957523345947266 corners\n",
      "Prediction for fortaleza: 3.464064598083496 corners\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Prediction for hammarby if: 6.632425785064697 corners\n",
      "Prediction for aik: 3.4970738887786865 corners\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Prediction for varbergs bois fc: 4.141430377960205 corners\n",
      "Prediction for brommapojkarna: 3.1168406009674072 corners\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Prediction for malmo: 6.867342472076416 corners\n",
      "Prediction for ifk gotemburgo: 3.2723710536956787 corners\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prediction for bahia: 5.628143310546875 corners\n",
      "Prediction for vasco da gama: 3.4672963619232178 corners\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Prediction for corinthians: 3.847259998321533 corners\n",
      "Prediction for palmeiras: 3.6683907508850098 corners\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Prediction for cambridge utd fc: 6.4740705490112305 corners\n",
      "Prediction for reading: 3.7497692108154297 corners\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Prediction for exeter city: 6.1954216957092285 corners\n",
      "Prediction for leyton orient: 3.4180777072906494 corners\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Prediction for port vale fc: 6.4927568435668945 corners\n",
      "Prediction for burton albion: 3.3038015365600586 corners\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Prediction for shrewsbury town: 4.06827449798584 corners\n",
      "Prediction for bolton wanderers fc: 5.789523124694824 corners\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Prediction for stevenage f.c.: 6.476538181304932 corners\n",
      "Prediction for carlisle utd: 3.46928334236145 corners\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Prediction for wigan fc: 4.367432594299316 corners\n",
      "Prediction for charlton athletic: 2.9961962699890137 corners\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prediction for derby county: 4.450508117675781 corners\n",
      "Prediction for northampton: 3.168283462524414 corners\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Prediction for barnsley fc: 3.902327299118042 corners\n",
      "Prediction for portsmouth: 3.976555585861206 corners\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prediction for peterborough united: 6.864875793457031 corners\n",
      "Prediction for cheltenham town: 3.2731385231018066 corners\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prediction for fleetwood town: 3.8176352977752686 corners\n",
      "Prediction for blackpool fc: 3.88488507270813 corners\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prediction for crawley town: 3.9153246879577637 corners\n",
      "Prediction for newport county afc: 3.558530807495117 corners\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Prediction for afc wimbledon: 6.302399158477783 corners\n",
      "Prediction for stockport county fc: 3.664860486984253 corners\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prediction for wrexham: 6.865370750427246 corners\n",
      "Prediction for doncaster rovers: 3.271407127380371 corners\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Prediction for forest green rovers: 3.8726236820220947 corners\n",
      "Prediction for crewe alexandra fc: 3.6891446113586426 corners\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prediction for barrow: 4.133371353149414 corners\n",
      "Prediction for morecambe: 3.1976935863494873 corners\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prediction for mk dons: 3.9217541217803955 corners\n",
      "Prediction for notts county: 4.787694931030273 corners\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prediction for salford city: 4.140255928039551 corners\n",
      "Prediction for walsall: 3.246094226837158 corners\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prediction for accrington stanley: 4.163273334503174 corners\n",
      "Prediction for mansfield town: 5.329154014587402 corners\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Prediction for bradford city: 4.054924011230469 corners\n",
      "Prediction for grimsby town: 5.003532886505127 corners\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prediction for gillingham: 4.653353214263916 corners\n",
      "Prediction for harrogate town fc: 2.9913198947906494 corners\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Prediction for lincoln city: 4.134929656982422 corners\n",
      "Prediction for oxford united: 3.1383016109466553 corners\n",
      "Corner Predictions: {'oud-heverlee leuven': 6.8557224, 'kv kortrijk': 3.2748919, 'ifk varnamo': 4.02222, 'elfsborg': 5.817602, 'athletico-pr': 4.2036796, 'atlético mineiro': 3.121505, 'goiás': 4.142316, 'internacional': 3.1165442, 'botafogo': 5.753845, 'flamengo': 3.4216905, 'halmstad': 4.1361523, 'ik sirius': 3.1183035, 'kv mechelen': 4.3604603, 'eupen': 3.08448, 'cercle brugge': 6.854558, 'kvc westerlo': 3.2629125, 'américa-mg': 4.715497, 'santos': 2.9107702, 'cruzeiro': 4.2546477, 'red bull bragantino': 5.62212, 'norrkoping': 4.145751, 'djurgardens if': 3.129359, 'são paulo': 5.7449956, 'coritiba': 3.1073031, 'degerfors if': 4.0643816, 'bk hacken': 5.807314, 'kalmar': 3.875252, 'mjallby': 3.633368, 'royal charleroi sc': 3.887748, 'sint truiden': 4.1560936, 'grêmio': 4.139362, 'cuiabá': 3.1692266, 'fluminense': 5.9575233, 'fortaleza': 3.4640646, 'hammarby if': 6.632426, 'aik': 3.497074, 'varbergs bois fc': 4.1414304, 'brommapojkarna': 3.1168406, 'malmo': 6.8673425, 'ifk gotemburgo': 3.272371, 'bahia': 5.6281433, 'vasco da gama': 3.4672964, 'corinthians': 3.84726, 'palmeiras': 3.6683908, 'cambridge utd fc': 6.4740705, 'reading': 3.7497692, 'exeter city': 6.1954217, 'leyton orient': 3.4180777, 'port vale fc': 6.492757, 'burton albion': 3.3038015, 'shrewsbury town': 4.0682745, 'bolton wanderers fc': 5.789523, 'stevenage f.c.': 6.476538, 'carlisle utd': 3.4692833, 'wigan fc': 4.3674326, 'charlton athletic': 2.9961963, 'derby county': 4.450508, 'northampton': 3.1682835, 'barnsley fc': 3.9023273, 'portsmouth': 3.9765556, 'peterborough united': 6.864876, 'cheltenham town': 3.2731385, 'fleetwood town': 3.8176353, 'blackpool fc': 3.884885, 'crawley town': 3.9153247, 'newport county afc': 3.5585308, 'afc wimbledon': 6.302399, 'stockport county fc': 3.6648605, 'wrexham': 6.8653708, 'doncaster rovers': 3.2714071, 'forest green rovers': 3.8726237, 'crewe alexandra fc': 3.6891446, 'barrow': 4.1333714, 'morecambe': 3.1976936, 'mk dons': 3.9217541, 'notts county': 4.787695, 'salford city': 4.140256, 'walsall': 3.2460942, 'accrington stanley': 4.1632733, 'mansfield town': 5.329154, 'bradford city': 4.054924, 'grimsby town': 5.003533, 'gillingham': 4.653353, 'harrogate town fc': 2.99132, 'lincoln city': 4.1349297, 'oxford united': 3.1383016}\n"
     ]
    }
   ],
   "source": [
    "# Inicializando um dicionário vazio para armazenar as previsões\n",
    "corner_predictions = {}\n",
    "\n",
    "# Iterar sobre cada linha em 'future_matches' e 'future_matches_calculado_scaled'\n",
    "for (index1, row1), (index2, row2) in zip(future_matches.iterrows(), future_matches_calculado_scaled.iterrows()):\n",
    "    # Prepare os dados de entrada para a previsão\n",
    "    team1_input_data = np.array([[row2['team1']]], dtype=np.float32)\n",
    "    team2_input_data = np.array([[row2['team2']]], dtype=np.float32)\n",
    "    champ_input_data = np.array([[row2['championship']]], dtype=np.float32)\n",
    "    \n",
    "    # Certifique-se de que 'other_features_data' contém todas as outras características na mesma ordem que foram usadas para treinar o modelo\n",
    "    other_features_data = np.array([row2.drop(['team1', 'team2', 'championship']).astype(np.float32)])\n",
    "    \n",
    "    # Faça a previsão usando o modelo unificado\n",
    "    pred = model.predict([team1_input_data, team2_input_data, champ_input_data, other_features_data])\n",
    "    \n",
    "    # As previsões para ambos os times estão na mesma saída, então vamos separá-las\n",
    "    pred_team1, pred_team2 = pred[0][0], pred[0][1]\n",
    "    \n",
    "    # Armazenar as previsões no dicionário\n",
    "    corner_predictions[row1['team1']] = pred_team1\n",
    "    corner_predictions[row1['team2']] = pred_team2\n",
    "    \n",
    "    # Imprimir as previsões\n",
    "    print(f\"Prediction for {row1['team1']}: {pred_team1} corners\")\n",
    "    print(f\"Prediction for {row1['team2']}: {pred_team2} corners\")\n",
    "\n",
    "# Exibindo o dicionário de previsões\n",
    "print(\"Corner Predictions:\", corner_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team1_name</th>\n",
       "      <th>Team1_prediction</th>\n",
       "      <th>Team2_name</th>\n",
       "      <th>Team2_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oud-heverlee leuven</td>\n",
       "      <td>6.855722</td>\n",
       "      <td>kv kortrijk</td>\n",
       "      <td>3.274892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ifk varnamo</td>\n",
       "      <td>4.022220</td>\n",
       "      <td>elfsborg</td>\n",
       "      <td>5.817602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>athletico-pr</td>\n",
       "      <td>4.203680</td>\n",
       "      <td>atlético mineiro</td>\n",
       "      <td>3.121505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>goiás</td>\n",
       "      <td>4.142316</td>\n",
       "      <td>internacional</td>\n",
       "      <td>3.116544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>botafogo</td>\n",
       "      <td>5.753845</td>\n",
       "      <td>flamengo</td>\n",
       "      <td>3.421690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>halmstad</td>\n",
       "      <td>4.136152</td>\n",
       "      <td>ik sirius</td>\n",
       "      <td>3.118304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kv mechelen</td>\n",
       "      <td>4.360460</td>\n",
       "      <td>eupen</td>\n",
       "      <td>3.084480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cercle brugge</td>\n",
       "      <td>6.854558</td>\n",
       "      <td>kvc westerlo</td>\n",
       "      <td>3.262913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>américa-mg</td>\n",
       "      <td>4.715497</td>\n",
       "      <td>santos</td>\n",
       "      <td>2.910770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cruzeiro</td>\n",
       "      <td>4.254648</td>\n",
       "      <td>red bull bragantino</td>\n",
       "      <td>5.622120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>norrkoping</td>\n",
       "      <td>4.145751</td>\n",
       "      <td>djurgardens if</td>\n",
       "      <td>3.129359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>são paulo</td>\n",
       "      <td>5.744996</td>\n",
       "      <td>coritiba</td>\n",
       "      <td>3.107303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>degerfors if</td>\n",
       "      <td>4.064382</td>\n",
       "      <td>bk hacken</td>\n",
       "      <td>5.807314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>kalmar</td>\n",
       "      <td>3.875252</td>\n",
       "      <td>mjallby</td>\n",
       "      <td>3.633368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>royal charleroi sc</td>\n",
       "      <td>3.887748</td>\n",
       "      <td>sint truiden</td>\n",
       "      <td>4.156094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>grêmio</td>\n",
       "      <td>4.139362</td>\n",
       "      <td>cuiabá</td>\n",
       "      <td>3.169227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fluminense</td>\n",
       "      <td>5.957523</td>\n",
       "      <td>fortaleza</td>\n",
       "      <td>3.464065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hammarby if</td>\n",
       "      <td>6.632426</td>\n",
       "      <td>aik</td>\n",
       "      <td>3.497074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>varbergs bois fc</td>\n",
       "      <td>4.141430</td>\n",
       "      <td>brommapojkarna</td>\n",
       "      <td>3.116841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>malmo</td>\n",
       "      <td>6.867342</td>\n",
       "      <td>ifk gotemburgo</td>\n",
       "      <td>3.272371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bahia</td>\n",
       "      <td>5.628143</td>\n",
       "      <td>vasco da gama</td>\n",
       "      <td>3.467296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>corinthians</td>\n",
       "      <td>3.847260</td>\n",
       "      <td>palmeiras</td>\n",
       "      <td>3.668391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cambridge utd fc</td>\n",
       "      <td>6.474071</td>\n",
       "      <td>reading</td>\n",
       "      <td>3.749769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>exeter city</td>\n",
       "      <td>6.195422</td>\n",
       "      <td>leyton orient</td>\n",
       "      <td>3.418078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>port vale fc</td>\n",
       "      <td>6.492757</td>\n",
       "      <td>burton albion</td>\n",
       "      <td>3.303802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>shrewsbury town</td>\n",
       "      <td>4.068274</td>\n",
       "      <td>bolton wanderers fc</td>\n",
       "      <td>5.789523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>stevenage f.c.</td>\n",
       "      <td>6.476538</td>\n",
       "      <td>carlisle utd</td>\n",
       "      <td>3.469283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>wigan fc</td>\n",
       "      <td>4.367433</td>\n",
       "      <td>charlton athletic</td>\n",
       "      <td>2.996196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>derby county</td>\n",
       "      <td>4.450508</td>\n",
       "      <td>northampton</td>\n",
       "      <td>3.168283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>barnsley fc</td>\n",
       "      <td>3.902327</td>\n",
       "      <td>portsmouth</td>\n",
       "      <td>3.976556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>peterborough united</td>\n",
       "      <td>6.864876</td>\n",
       "      <td>cheltenham town</td>\n",
       "      <td>3.273139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>fleetwood town</td>\n",
       "      <td>3.817635</td>\n",
       "      <td>blackpool fc</td>\n",
       "      <td>3.884885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>crawley town</td>\n",
       "      <td>3.915325</td>\n",
       "      <td>newport county afc</td>\n",
       "      <td>3.558531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>afc wimbledon</td>\n",
       "      <td>6.302399</td>\n",
       "      <td>stockport county fc</td>\n",
       "      <td>3.664860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>wrexham</td>\n",
       "      <td>6.865371</td>\n",
       "      <td>doncaster rovers</td>\n",
       "      <td>3.271407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>forest green rovers</td>\n",
       "      <td>3.872624</td>\n",
       "      <td>crewe alexandra fc</td>\n",
       "      <td>3.689145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>barrow</td>\n",
       "      <td>4.133371</td>\n",
       "      <td>morecambe</td>\n",
       "      <td>3.197694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>mk dons</td>\n",
       "      <td>3.921754</td>\n",
       "      <td>notts county</td>\n",
       "      <td>4.787695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>salford city</td>\n",
       "      <td>4.140256</td>\n",
       "      <td>walsall</td>\n",
       "      <td>3.246094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>accrington stanley</td>\n",
       "      <td>4.163273</td>\n",
       "      <td>mansfield town</td>\n",
       "      <td>5.329154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>bradford city</td>\n",
       "      <td>4.054924</td>\n",
       "      <td>grimsby town</td>\n",
       "      <td>5.003533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>gillingham</td>\n",
       "      <td>4.653353</td>\n",
       "      <td>harrogate town fc</td>\n",
       "      <td>2.991320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>lincoln city</td>\n",
       "      <td>4.134930</td>\n",
       "      <td>oxford united</td>\n",
       "      <td>3.138302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Team1_name  Team1_prediction           Team2_name  \\\n",
       "0   oud-heverlee leuven          6.855722          kv kortrijk   \n",
       "1           ifk varnamo          4.022220             elfsborg   \n",
       "2          athletico-pr          4.203680     atlético mineiro   \n",
       "3                 goiás          4.142316        internacional   \n",
       "4              botafogo          5.753845             flamengo   \n",
       "5              halmstad          4.136152            ik sirius   \n",
       "6           kv mechelen          4.360460                eupen   \n",
       "7         cercle brugge          6.854558         kvc westerlo   \n",
       "8            américa-mg          4.715497               santos   \n",
       "9              cruzeiro          4.254648  red bull bragantino   \n",
       "10           norrkoping          4.145751       djurgardens if   \n",
       "11            são paulo          5.744996             coritiba   \n",
       "12         degerfors if          4.064382            bk hacken   \n",
       "13               kalmar          3.875252              mjallby   \n",
       "14   royal charleroi sc          3.887748         sint truiden   \n",
       "15               grêmio          4.139362               cuiabá   \n",
       "16           fluminense          5.957523            fortaleza   \n",
       "17          hammarby if          6.632426                  aik   \n",
       "18     varbergs bois fc          4.141430       brommapojkarna   \n",
       "19                malmo          6.867342       ifk gotemburgo   \n",
       "20                bahia          5.628143        vasco da gama   \n",
       "21          corinthians          3.847260            palmeiras   \n",
       "22     cambridge utd fc          6.474071              reading   \n",
       "23          exeter city          6.195422        leyton orient   \n",
       "24         port vale fc          6.492757        burton albion   \n",
       "25      shrewsbury town          4.068274  bolton wanderers fc   \n",
       "26       stevenage f.c.          6.476538         carlisle utd   \n",
       "27             wigan fc          4.367433    charlton athletic   \n",
       "28         derby county          4.450508          northampton   \n",
       "29          barnsley fc          3.902327           portsmouth   \n",
       "30  peterborough united          6.864876      cheltenham town   \n",
       "31       fleetwood town          3.817635         blackpool fc   \n",
       "32         crawley town          3.915325   newport county afc   \n",
       "33        afc wimbledon          6.302399  stockport county fc   \n",
       "34              wrexham          6.865371     doncaster rovers   \n",
       "35  forest green rovers          3.872624   crewe alexandra fc   \n",
       "36               barrow          4.133371            morecambe   \n",
       "37              mk dons          3.921754         notts county   \n",
       "38         salford city          4.140256              walsall   \n",
       "39   accrington stanley          4.163273       mansfield town   \n",
       "40        bradford city          4.054924         grimsby town   \n",
       "41           gillingham          4.653353    harrogate town fc   \n",
       "42         lincoln city          4.134930        oxford united   \n",
       "\n",
       "    Team2_prediction  \n",
       "0           3.274892  \n",
       "1           5.817602  \n",
       "2           3.121505  \n",
       "3           3.116544  \n",
       "4           3.421690  \n",
       "5           3.118304  \n",
       "6           3.084480  \n",
       "7           3.262913  \n",
       "8           2.910770  \n",
       "9           5.622120  \n",
       "10          3.129359  \n",
       "11          3.107303  \n",
       "12          5.807314  \n",
       "13          3.633368  \n",
       "14          4.156094  \n",
       "15          3.169227  \n",
       "16          3.464065  \n",
       "17          3.497074  \n",
       "18          3.116841  \n",
       "19          3.272371  \n",
       "20          3.467296  \n",
       "21          3.668391  \n",
       "22          3.749769  \n",
       "23          3.418078  \n",
       "24          3.303802  \n",
       "25          5.789523  \n",
       "26          3.469283  \n",
       "27          2.996196  \n",
       "28          3.168283  \n",
       "29          3.976556  \n",
       "30          3.273139  \n",
       "31          3.884885  \n",
       "32          3.558531  \n",
       "33          3.664860  \n",
       "34          3.271407  \n",
       "35          3.689145  \n",
       "36          3.197694  \n",
       "37          4.787695  \n",
       "38          3.246094  \n",
       "39          5.329154  \n",
       "40          5.003533  \n",
       "41          2.991320  \n",
       "42          3.138302  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformar o dicionário em uma lista de listas, quebrando a cada 2 itens\n",
    "items = list(corner_predictions.items())\n",
    "rows = [items[i:i + 2] for i in range(0, len(items), 2)]\n",
    "\n",
    "# Criar um DataFrame a partir da lista de listas\n",
    "df = pd.DataFrame(rows, columns=['Team1', 'Team2'])\n",
    "\n",
    "# Separar as tuplas em duas colunas separadas para os nomes das equipes e as previsões\n",
    "df[['Team1_name', 'Team1_prediction']] = pd.DataFrame(df['Team1'].tolist(), index=df.index)\n",
    "df[['Team2_name', 'Team2_prediction']] = pd.DataFrame(df['Team2'].tolist(), index=df.index)\n",
    "\n",
    "# Descartar as colunas originais e reordenar\n",
    "df = df[['Team1_name', 'Team1_prediction', 'Team2_name', 'Team2_prediction']]\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 4)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 2\n",
    "\n",
    "from scipy.stats import poisson\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def poisson_probabilities(lam, max_corners=15):\n",
    "    probs = [poisson.pmf(k, lam) for k in range(max_corners + 1)]\n",
    "    probs.append(1 - sum(probs))\n",
    "    return probs\n",
    "\n",
    "def calculate_probabilities(team1_corners_prediction, team2_corners_prediction):\n",
    "    team1_corners_probabilities = poisson_probabilities(team1_corners_prediction)\n",
    "    team2_corners_probabilities = poisson_probabilities(team2_corners_prediction)\n",
    "\n",
    "    joint_prob_matrix = np.outer(team1_corners_probabilities, team2_corners_probabilities)\n",
    "\n",
    "    team1_win_prob = np.sum(np.tril(joint_prob_matrix, -1))\n",
    "    draw_prob = np.sum(np.diag(joint_prob_matrix))\n",
    "    team2_win_prob = np.sum(np.triu(joint_prob_matrix, 1))\n",
    "\n",
    "    team1_minus35_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if i-j>=4])\n",
    "    team1_plus35_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if i-j>=-3])\n",
    "    team2_minus35_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if j-i>=4])\n",
    "    team2_plus35_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if j-i>=-3])\n",
    "\n",
    "    team1_minus25_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if i-j>=3])\n",
    "    team1_plus25_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if i-j>=-2])\n",
    "    team2_minus25_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if j-i>=3])\n",
    "    team2_plus25_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if j-i>=-2])\n",
    "\n",
    "    team1_minus15_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if i-j>=2])\n",
    "    team1_plus15_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if i-j>=-1])\n",
    "    team2_minus15_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if j-i>=2])\n",
    "    team2_plus15_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if j-i>=-1])\n",
    "\n",
    "    team1_over45_prob = 1 - sum(team1_corners_probabilities[:5])\n",
    "    team1_under45_prob = sum(team1_corners_probabilities[:5])\n",
    "    team2_over45_prob = 1 - sum(team2_corners_probabilities[:5])\n",
    "    team2_under45_prob = sum(team2_corners_probabilities[:5])\n",
    "\n",
    "    team1_over55_prob = 1 - sum(team1_corners_probabilities[:6])\n",
    "    team1_under55_prob = sum(team1_corners_probabilities[:6])\n",
    "    team2_over55_prob = 1 - sum(team2_corners_probabilities[:6])\n",
    "    team2_under55_prob = sum(team2_corners_probabilities[:6])\n",
    "\n",
    "    team1_over65_prob = 1 - sum(team1_corners_probabilities[:7])\n",
    "    team1_under65_prob = sum(team1_corners_probabilities[:7])\n",
    "    team2_over65_prob = 1 - sum(team2_corners_probabilities[:7])\n",
    "    team2_under65_prob = sum(team2_corners_probabilities[:7])\n",
    "    \n",
    "    return (team1_win_prob, draw_prob, team2_win_prob,\n",
    "        team1_minus15_prob, team1_plus15_prob, team2_minus15_prob, team2_plus15_prob,\n",
    "        team1_minus25_prob, team1_plus25_prob, team2_minus25_prob, team2_plus25_prob,\n",
    "        team1_minus35_prob, team1_plus35_prob, team2_minus35_prob, team2_plus35_prob,\n",
    "        team1_over45_prob, team1_under45_prob, team2_over45_prob, team2_under45_prob,\n",
    "        team1_over55_prob, team1_under55_prob, team2_over55_prob, team2_under55_prob,\n",
    "        team1_over65_prob, team1_under65_prob, team2_over65_prob, team2_under65_prob)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 31)\n"
     ]
    }
   ],
   "source": [
    "# Inicializando o DataFrame para armazenar as odds\n",
    "odds_df = pd.DataFrame(columns=['Team 1', 'Team 2', 'Team 1 Win Odd', 'Draw Odd', 'Team 2 Win Odd',\n",
    "                                'Team 1 -1.5 Odd', 'Team 1 +1.5 Odd', 'Team 2 -1.5 Odd', 'Team 2 +1.5 Odd',\n",
    "                                'Team 1 -2.5 Odd', 'Team 1 +2.5 Odd', 'Team 2 -2.5 Odd', 'Team 2 +2.5 Odd',\n",
    "                                'Team 1 -3.5 Odd', 'Team 1 +3.5 Odd', 'Team 2 -3.5 Odd', 'Team 2 +3.5 Odd',\n",
    "                                'Team 1 Over 4.5', 'Team 1 Under 4.5', 'Team 2 Over 4.5', 'Team 2 Under 4.5',\n",
    "                                'Team 1 Over 5.5', 'Team 1 Under 5.5', 'Team 2 Over 5.5', 'Team 2 Under 5.5',\n",
    "                                'Team 1 Over 6.5', 'Team 1 Under 6.5', 'Team 2 Over 6.5', 'Team 2 Under 6.5'])\n",
    "\n",
    "# Iterar sobre cada linha no DataFrame 'df'\n",
    "for index, row in df.iterrows():\n",
    "    team1_name = row['Team1_name']\n",
    "    team1_prediction = row['Team1_prediction']\n",
    "    team2_name = row['Team2_name']\n",
    "    team2_prediction = row['Team2_prediction']\n",
    "    \n",
    "    # Calculando as probabilidades usando a função do STEP 2\n",
    "    probabilities = calculate_probabilities(team1_prediction, team2_prediction)\n",
    "    \n",
    "    # Calculando as odds\n",
    "    odds = [1 / prob for prob in probabilities]\n",
    "    \n",
    "    # Adicionando as odds ao DataFrame\n",
    "    odds_df.loc[len(odds_df)] = [team1_name, team2_name] + odds\n",
    "\n",
    "    # Inicializando as novas colunas\n",
    "odds_df['date'] = None\n",
    "odds_df['championship'] = None\n",
    "\n",
    "# Preenchendo as novas colunas\n",
    "for index, row in odds_df.iterrows():\n",
    "    team1 = row['Team 1']\n",
    "    team2 = row['Team 2']\n",
    "    \n",
    "    # Encontrando a linha correspondente em 'future_matches'\n",
    "    match_row = future_matches[(future_matches['team1'] == team1) & (future_matches['team2'] == team2)]\n",
    "    \n",
    "    if not match_row.empty:\n",
    "        # Se encontrarmos uma linha correspondente, atualizamos 'odds_df'\n",
    "        odds_df.at[index, 'date'] = match_row.iloc[0]['date']\n",
    "        odds_df.at[index, 'championship'] = match_row.iloc[0]['championship']\n",
    "\n",
    "# Converte a coluna 'date' para o tipo de data do pandas\n",
    "odds_df['date'] = pd.to_datetime(odds_df['date'])\n",
    "\n",
    "# Formata a coluna 'date' para o formato de data brasileiro (dd/mm/yyyy)\n",
    "odds_df['date'] = odds_df['date'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "odds_df = odds_df.sort_values(['championship', 'date'])\n",
    "\n",
    "# Lista das colunas atuais\n",
    "cols = odds_df.columns.tolist()\n",
    "\n",
    "# Removendo 'date' e 'championship' da lista\n",
    "cols.remove('date')\n",
    "cols.remove('championship')\n",
    "\n",
    "# Reordenando as colunas\n",
    "new_cols = ['date', 'championship'] + cols\n",
    "\n",
    "# Atualizando o DataFrame com a nova ordem de colunas\n",
    "odds_df = odds_df[new_cols]\n",
    "\n",
    "odds_df.to_excel(\"output_corners_NNNN_AH(withoutG).xlsx\", index=False)\n",
    "\n",
    "# Exibindo o DataFrame de odds\n",
    "print(odds_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
