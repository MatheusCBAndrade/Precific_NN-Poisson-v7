{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(66840, 141)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_pickle(r'C:\\Users\\mathe\\OneDrive\\Área de Trabalho\\SoccerIA\\MathIA_v7\\dataset_141cols_europeu.pkl')\n",
    "\n",
    "nan_counts = dataset.isna().sum()\n",
    "nan_tot = nan_counts.sum()\n",
    "print(nan_tot)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando os dataframes de 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe2023_BRA_A.xlsx\n",
      "(370, 19)\n",
      "team1                      0\n",
      "team2                      0\n",
      "team1_goals              181\n",
      "team2_goals              181\n",
      "season                     0\n",
      "championship               0\n",
      "team1_shots_on_target    181\n",
      "team1_shots_out          181\n",
      "team2_shots_on_target    181\n",
      "team2_shots_out          181\n",
      "team1_red_cards          181\n",
      "team2_red_cards          181\n",
      "team1_fouls              181\n",
      "team2_fouls              181\n",
      "team1_corners            181\n",
      "team2_corners            181\n",
      "team1_total_shots        181\n",
      "team2_total_shots        181\n",
      "date                       0\n",
      "dtype: int64\n",
      "dataframe2023_SUE_A.xlsx\n",
      "(230, 19)\n",
      "team1                     0\n",
      "team2                     0\n",
      "team1_goals              80\n",
      "team2_goals              80\n",
      "season                    0\n",
      "championship              0\n",
      "team1_shots_on_target    80\n",
      "team1_shots_out          80\n",
      "team2_shots_on_target    80\n",
      "team2_shots_out          80\n",
      "team1_red_cards          80\n",
      "team2_red_cards          80\n",
      "team1_fouls              80\n",
      "team2_fouls              80\n",
      "team1_corners            80\n",
      "team2_corners            80\n",
      "team1_total_shots        80\n",
      "team2_total_shots        80\n",
      "date                      0\n",
      "dtype: int64\n",
      "Index(['team1', 'team2', 'team1_goals', 'team2_goals', 'season',\n",
      "       'championship', 'team1_shots_on_target', 'team1_shots_out',\n",
      "       'team2_shots_on_target', 'team2_shots_out', 'team1_red_cards',\n",
      "       'team2_red_cards', 'team1_fouls', 'team2_fouls', 'team1_corners',\n",
      "       'team2_corners', 'team1_total_shots', 'team2_total_shots', 'date',\n",
      "       'is_future_match'],\n",
      "      dtype='object')\n",
      "(600, 20)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Caminho para a pasta que contém os arquivos .xlsx de 2023\n",
    "path = r'C:\\Users\\mathe\\OneDrive\\Área de Trabalho\\SoccerIA\\webScrappingOddspedia'\n",
    "\n",
    "# Dicionário para armazenar os dataframes\n",
    "dataframes = {}\n",
    "dfss = []\n",
    "# Lista todos os arquivos na pasta\n",
    "files = os.listdir(path)\n",
    "\n",
    "# Filtra a lista de arquivos para incluir apenas os arquivos .xlsx\n",
    "xlsx_files = [f for f in files if f.endswith('.xlsx')]\n",
    "\n",
    "# Carrega cada arquivo .xlsx em um dataframe e armazena no dicionário\n",
    "for file in xlsx_files:\n",
    "    full_path = os.path.join(path, file)  # junta o caminho do diretório com o nome do arquivo\n",
    "    dataframes[file] = pd.read_excel(full_path)  # lê o arquivo .xlsx do caminho completo\n",
    "\n",
    "    if \"Unnamed: 0\" in dataframes[file].columns:\n",
    "        dataframes[file].drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\n",
    "    if \"match_report_url\" in dataframes[file].columns:\n",
    "        dataframes[file].drop(\"match_report_url\", axis=1, inplace=True)    \n",
    "\n",
    "    if \"team1_yellow_cards\" in dataframes[file].columns:\n",
    "        dataframes[file].drop(\"team1_yellow_cards\", axis=1, inplace=True)\n",
    "\n",
    "    if \"team2_yellow_cards\" in dataframes[file].columns:\n",
    "        dataframes[file].drop(\"team2_yellow_cards\", axis=1, inplace=True)  \n",
    "    dfss.append(dataframes[file])\n",
    "\n",
    "    print(file)\n",
    "    print(dataframes[file].shape)\n",
    "    nan_counts = dataframes[file].isna().sum()\n",
    "    print(nan_counts)\n",
    "\n",
    "\n",
    "# Combine all the DataFrames into a single DataFrame\n",
    "combined_df_2023 = pd.concat(dfss, ignore_index=True)\n",
    "\n",
    "\n",
    "combined_df_2023['team1'] = combined_df_2023['team1'].str.lower()\n",
    "combined_df_2023['team2'] = combined_df_2023['team2'].str.lower()\n",
    "combined_df_2023.replace('', np.nan, inplace=True)\n",
    "# Add a column to mark future matches\n",
    "combined_df_2023['is_future_match'] = combined_df_2023['team1_goals'].isna() | combined_df_2023['team2_goals'].isna()\n",
    "combined_df_2023['season'] = '2023'\n",
    "# Replace empty string with NaN\n",
    "combined_df_2023[\"team1_red_cards\"].replace('', np.nan, inplace=True)\n",
    "combined_df_2023[\"team2_red_cards\"].replace('', np.nan, inplace=True)\n",
    "\n",
    "# Replace NaN with 0\n",
    "combined_df_2023[\"team1_red_cards\"].fillna(0, inplace=True)\n",
    "combined_df_2023[\"team2_red_cards\"].fillna(0, inplace=True)\n",
    "\n",
    "combined_df_2023['date'] = pd.to_datetime(combined_df_2023['date'], format='%Y-%m-%d', errors='coerce')\n",
    "combined_df_2023.sort_values('date', inplace=True)\n",
    "\n",
    "print(combined_df_2023.columns)\n",
    "print(combined_df_2023.shape) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 120)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "combined_df_2023.sort_values('date', inplace=True)\n",
    "\n",
    "\n",
    "combined_df_2023['team1_goals'] = pd.to_numeric(combined_df_2023['team1_goals'], errors='coerce')\n",
    "combined_df_2023['team2_goals'] = pd.to_numeric(combined_df_2023['team2_goals'], errors='coerce')\n",
    "\n",
    "# calculate goal differences\n",
    "combined_df_2023['goal_diff_team1'] = combined_df_2023['team1_goals'] - combined_df_2023['team2_goals']\n",
    "combined_df_2023['goal_diff_team2'] = combined_df_2023['team2_goals'] - combined_df_2023['team1_goals']\n",
    "\n",
    "# calculate corners differences\n",
    "combined_df_2023['corners_diff_team1'] = combined_df_2023['team1_corners'] - combined_df_2023['team2_corners']############# NEW\n",
    "combined_df_2023['corners_diff_team2'] = combined_df_2023['team2_corners'] - combined_df_2023['team1_corners']############# NEW\n",
    "\n",
    "# calculate big wins and losses\n",
    "combined_df_2023['team1_big_win'] = np.where(combined_df_2023['goal_diff_team1'] >= 2, 1, 0)\n",
    "combined_df_2023['team1_big_loss'] = np.where(combined_df_2023['goal_diff_team1'] <= -2, 1, 0)\n",
    "combined_df_2023['team2_big_win'] = np.where(combined_df_2023['goal_diff_team2'] >= 2, 1, 0)\n",
    "combined_df_2023['team2_big_loss'] = np.where(combined_df_2023['goal_diff_team2'] <= -2, 1, 0)\n",
    "\n",
    "# calculate AH-2.5 win and losses\n",
    "combined_df_2023['team1_ah-2.5_win'] = np.where(combined_df_2023['corners_diff_team1'] >= 3, 1, 0)############# NEW\n",
    "combined_df_2023['team1_ah-2.5_loss'] = np.where(combined_df_2023['corners_diff_team1'] <= 2, 1, 0)############# NEW\n",
    "combined_df_2023['team2_ah-2.5_win'] = np.where(combined_df_2023['corners_diff_team2'] >= 3, 1, 0)############# NEW\n",
    "combined_df_2023['team2_ah-2.5_loss'] = np.where(combined_df_2023['corners_diff_team2'] <= 2, 1, 0)############# NEW\n",
    "\n",
    "\n",
    "# calculate AH+2.5 win and losses\n",
    "combined_df_2023['team1_ah+2.5_win'] = np.where(combined_df_2023['corners_diff_team1'] >= -2, 1, 0)############# NEW\n",
    "combined_df_2023['team1_ah+2.5_loss'] = np.where(combined_df_2023['corners_diff_team1'] <= -3, 1, 0)############# NEW\n",
    "combined_df_2023['team2_ah+2.5_win'] = np.where(combined_df_2023['corners_diff_team2'] >= -2, 1, 0)############# NEW\n",
    "combined_df_2023['team2_ah+2.5_loss'] = np.where(combined_df_2023['corners_diff_team2'] <= -3, 1, 0)############# NEW\n",
    "\n",
    "\n",
    "# calculate over4.5 win and losses\n",
    "combined_df_2023['team1_over4.5'] = np.where(combined_df_2023['team1_corners'] >= 5, 1, 0)############# NEW\n",
    "combined_df_2023['team1_under4.5'] = np.where(combined_df_2023['team1_corners'] <= 4, 1, 0)############# NEW\n",
    "combined_df_2023['team2_over4.5'] = np.where(combined_df_2023['team2_corners'] >= 5, 1, 0)############# NEW\n",
    "combined_df_2023['team2_under4.5'] = np.where(combined_df_2023['team2_corners'] <= 4, 1, 0)############# NEW\n",
    "\n",
    "# calculate over3.5 win and losses\n",
    "combined_df_2023['team1_over3.5'] = np.where(combined_df_2023['team1_corners'] >= 4, 1, 0)############# NEW\n",
    "combined_df_2023['team1_under3.5'] = np.where(combined_df_2023['team1_corners'] <= 3, 1, 0)############# NEW\n",
    "combined_df_2023['team2_over3.5'] = np.where(combined_df_2023['team2_corners'] >= 4, 1, 0)############# NEW\n",
    "combined_df_2023['team2_under3.5'] = np.where(combined_df_2023['team2_corners'] <= 3, 1, 0)############# NEW\n",
    "\n",
    "# calculate over6.5 win and losses\n",
    "combined_df_2023['team1_over6.5'] = np.where(combined_df_2023['team1_corners'] >= 7, 1, 0)############# NEW\n",
    "combined_df_2023['team1_under6.5'] = np.where(combined_df_2023['team1_corners'] <= 6, 1, 0)############# NEW\n",
    "combined_df_2023['team2_over6.5'] = np.where(combined_df_2023['team2_corners'] >= 7, 1, 0)############# NEW\n",
    "combined_df_2023['team2_under6.5'] = np.where(combined_df_2023['team2_corners'] <= 6, 1, 0)############# NEW\n",
    "\n",
    "\n",
    "# Initialize these columns with 0\n",
    "combined_df_2023['team1_big_wins_last5'] = 0\n",
    "combined_df_2023['team1_big_losses_last5'] = 0\n",
    "combined_df_2023['team2_big_wins_last5'] = 0\n",
    "combined_df_2023['team2_big_losses_last5'] = 0\n",
    "\n",
    "combined_df_2023['team1_ah-2.5_wins_last5'] = 0############# NEW\n",
    "combined_df_2023['team1_ah-2.5_losses_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_ah-2.5_wins_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_ah-2.5_losses_last5'] = 0############# NEW\n",
    "\n",
    "combined_df_2023['team1_ah+2.5_wins_last5'] = 0############# NEW\n",
    "combined_df_2023['team1_ah+2.5_losses_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_ah+2.5_wins_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_ah+2.5_losses_last5'] = 0############# NEW\n",
    "\n",
    "combined_df_2023['team1_over3.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team1_under3.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_over3.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_under3.5_last5'] = 0############# NEW\n",
    "\n",
    "combined_df_2023['team1_over4.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team1_under4.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_over4.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_under4.5_last5'] = 0############# NEW\n",
    "\n",
    "combined_df_2023['team1_over6.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team1_under6.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_over6.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_under6.5_last5'] = 0############# NEW\n",
    "\n",
    "\n",
    "new_cols = ['avg_scr_lasts3_1_home', 'avg_scr_lasts5_1_home', 'avg_scr_lasts3_1_away',\n",
    "            'avg_scr_lasts5_1_away', 'avg_conc_lasts3_1_home', 'avg_conc_lasts5_1_home',\n",
    "            'avg_conc_lasts3_1_away', 'avg_conc_lasts5_1_away', 'avg_scr_lasts3_2_home',\n",
    "            'avg_scr_lasts5_2_home', 'avg_scr_lasts3_2_away', 'avg_scr_lasts5_2_away',\n",
    "            'avg_conc_lasts3_2_home', 'avg_conc_lasts5_2_home', 'avg_conc_lasts3_2_away',\n",
    "            'avg_conc_lasts5_2_away','team1_big_wins_last5', 'team1_big_losses_last5', \n",
    "            'team2_big_wins_last5', 'team2_big_losses_last5',\n",
    "            #abaixo vai ser baseado em finalizações\n",
    "            'avg_total_shots_lasts5_1_home','avg_total_shots_lasts5_1_away','avg_total_shots_lasts5_2_home',\n",
    "            'avg_total_shots_lasts5_2_away', 'avg_otarget_shots_lasts5_1_home','avg_otarget_shots_lasts5_1_away',\n",
    "            'avg_otarget_shots_lasts5_2_home','avg_otarget_shots_lasts5_2_away','avg_out_shots_lasts5_1_home',\n",
    "            'avg_out_shots_lasts5_1_away','avg_out_shots_lasts5_2_home','avg_out_shots_lasts5_2_away',\n",
    "            'avg_conc_total_shots_lasts5_1_home','avg_conc_total_shots_lasts5_1_away',\n",
    "            'avg_conc_total_shots_lasts5_2_home','avg_conc_total_shots_lasts5_2_away',\n",
    "            #abaixo vai ser baseado em corners\n",
    "            'avg_corners_lasts5_1_home','avg_corners_lasts5_1_away', \n",
    "            'avg_corners_conc_lasts5_1_home','avg_corners_conc_lasts5_1_away',\n",
    "            'avg_corners_lasts5_2_home','avg_corners_lasts5_2_away', \n",
    "            'avg_corners_conc_lasts5_2_home', 'avg_corners_conc_lasts5_2_away',\n",
    "            #abaixo vai ser baseado em fouls\n",
    "            'avg_fouls_lasts5_1_home','avg_fouls_lasts5_1_away', \n",
    "            'avg_fouls_conc_lasts5_1_home', 'avg_fouls_conc_lasts5_1_away',\n",
    "            'avg_fouls_lasts5_2_home','avg_fouls_lasts5_2_away', \n",
    "            'avg_fouls_conc_lasts5_2_home', 'avg_fouls_conc_lasts5_2_away',\n",
    "            #novas colunas da v7\n",
    "            'team1_ah-2.5_wins_last5', 'team1_ah-2.5_losses_last5','team2_ah-2.5_wins_last5','team2_ah-2.5_losses_last5',\n",
    "            'team1_ah+2.5_wins_last5','team1_ah+2.5_losses_last5','team2_ah+2.5_wins_last5','team2_ah+2.5_losses_last5',\n",
    "            'team1_over3.5_last5','team1_under3.5_last5','team2_over3.5_last5','team2_under3.5_last5',\n",
    "            'team1_over4.5_last5','team1_under4.5_last5','team2_over4.5_last5','team2_under4.5_last5',\n",
    "            'team1_over6.5_last5','team1_under6.5_last5','team2_over6.5_last5','team2_under6.5_last5'\n",
    "            ]\n",
    "\n",
    "# Create a dictionary with keys as column names and values as np.nan\n",
    "new_cols_dict = {col: np.nan for col in new_cols}\n",
    "\n",
    "# Add new columns to the DataFrame\n",
    "combined_df_2023 = combined_df_2023.assign(**new_cols_dict)\n",
    "\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for i, row in combined_df_2023.iterrows():\n",
    "    # For each team, get their past home and away matches before the current date\n",
    "    team1_matches = combined_df_2023[((combined_df_2023['team1'] == row['team1']) | (combined_df_2023['team2'] == row['team1'])) & (combined_df_2023['date'] < row['date']) & (combined_df_2023['season'] == row['season'])].sort_values(by='date')\n",
    "    team2_matches = combined_df_2023[((combined_df_2023['team1'] == row['team2']) | (combined_df_2023['team2'] == row['team2'])) & (combined_df_2023['date'] < row['date']) & (combined_df_2023['season'] == row['season'])].sort_values(by='date')\n",
    "\n",
    "    # For each team, calculate stats for last 5 matches\n",
    "    if not team1_matches.empty:\n",
    "        team1_matches['big_win'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_big_win'], team1_matches['team2_big_win'])\n",
    "        team1_matches['big_loss'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_big_loss'], team1_matches['team2_big_loss'])\n",
    "        combined_df_2023.at[i, 'team1_big_wins_last5'] = team1_matches['big_win'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team1_big_losses_last5'] = team1_matches['big_loss'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para ah-2.5 para a equipe 1\n",
    "        team1_matches['ah-2.5_win'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_ah-2.5_win'], team1_matches['team2_ah-2.5_win'])\n",
    "        team1_matches['ah-2.5_loss'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_ah-2.5_loss'], team1_matches['team2_ah-2.5_loss'])\n",
    "        combined_df_2023.at[i, 'team1_ah-2.5_wins_last5'] = team1_matches['ah-2.5_win'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team1_ah-2.5_losses_last5'] = team1_matches['ah-2.5_loss'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para ah+2.5 para a equipe 1\n",
    "        team1_matches['ah+2.5_win'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_ah+2.5_win'], team1_matches['team2_ah+2.5_win'])\n",
    "        team1_matches['ah+2.5_loss'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_ah+2.5_loss'], team1_matches['team2_ah+2.5_loss'])\n",
    "        combined_df_2023.at[i, 'team1_ah+2.5_wins_last5'] = team1_matches['ah+2.5_win'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team1_ah+2.5_losses_last5'] = team1_matches['ah+2.5_loss'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para over3.5 para a equipe 1\n",
    "        team1_matches['over3.5'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_over3.5'], team1_matches['team2_over3.5'])\n",
    "        team1_matches['under3.5'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_under3.5'], team1_matches['team2_under3.5'])\n",
    "        combined_df_2023.at[i, 'team1_over3.5_last5'] = team1_matches['over3.5'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team1_under3.5_last5'] = team1_matches['under3.5'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para over4.5 para a equipe 1\n",
    "        team1_matches['over4.5'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_over4.5'], team1_matches['team2_over4.5'])\n",
    "        team1_matches['under4.5'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_under4.5'], team1_matches['team2_under4.5'])\n",
    "        combined_df_2023.at[i, 'team1_over4.5_last5'] = team1_matches['over4.5'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team1_under4.5_last5'] = team1_matches['under4.5'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para over6.5 para a equipe 1\n",
    "        team1_matches['over6.5'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_over6.5'], team1_matches['team2_over6.5'])\n",
    "        team1_matches['under6.5'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_under6.5'], team1_matches['team2_under6.5'])\n",
    "        combined_df_2023.at[i, 'team1_over6.5_last5'] = team1_matches['over6.5'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team1_under6.5_last5'] = team1_matches['under6.5'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "\n",
    "\n",
    "\n",
    "    if not team2_matches.empty:\n",
    "        team2_matches['big_win'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_big_win'], team2_matches['team2_big_win'])\n",
    "        team2_matches['big_loss'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_big_loss'], team2_matches['team2_big_loss'])\n",
    "        combined_df_2023.at[i, 'team2_big_wins_last5'] = team2_matches['big_win'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team2_big_losses_last5'] = team2_matches['big_loss'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para ah-2.5 para a equipe 2\n",
    "        team2_matches['ah-2.5_win'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_ah-2.5_win'], team2_matches['team2_ah-2.5_win'])\n",
    "        team2_matches['ah-2.5_loss'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_ah-2.5_loss'], team2_matches['team2_ah-2.5_loss'])\n",
    "        combined_df_2023.at[i, 'team2_ah-2.5_wins_last5'] = team2_matches['ah-2.5_win'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team2_ah-2.5_losses_last5'] = team2_matches['ah-2.5_loss'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para ah+2.5 para a equipe 2\n",
    "        team2_matches['ah+2.5_win'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_ah+2.5_win'], team2_matches['team2_ah+2.5_win'])\n",
    "        team2_matches['ah+2.5_loss'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_ah+2.5_loss'], team2_matches['team2_ah+2.5_loss'])\n",
    "        combined_df_2023.at[i, 'team2_ah+2.5_wins_last5'] = team2_matches['ah+2.5_win'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team2_ah+2.5_losses_last5'] = team2_matches['ah+2.5_loss'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para over3.5  para a equipe 2\n",
    "        team2_matches['over3.5'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_over3.5'], team2_matches['team2_over3.5'])\n",
    "        team2_matches['under3.5'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_under3.5'], team2_matches['team2_under3.5'])\n",
    "        combined_df_2023.at[i, 'team2_over3.5_last5'] = team2_matches['over3.5'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team2_under3.5_last5'] = team2_matches['under3.5'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para over4.5  para a equipe 2\n",
    "        team2_matches['over4.5'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_over4.5'], team2_matches['team2_over4.5'])\n",
    "        team2_matches['under4.5'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_under4.5'], team2_matches['team2_under4.5'])\n",
    "        combined_df_2023.at[i, 'team2_over4.5_last5'] = team2_matches['over4.5'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team2_under4.5_last5'] = team2_matches['under4.5'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para over6.5  para a equipe 2\n",
    "        team2_matches['over6.5'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_over6.5'], team2_matches['team2_over6.5'])\n",
    "        team2_matches['under6.5'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_under6.5'], team2_matches['team2_under6.5'])\n",
    "        combined_df_2023.at[i, 'team2_over6.5_last5'] = team2_matches['over6.5'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team2_under6.5_last5'] = team2_matches['under6.5'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "for i, row in combined_df_2023.iterrows():\n",
    "    team1_home = combined_df_2023[(combined_df_2023['date'] < row['date']) & (combined_df_2023['team1'] == row['team1']) & (combined_df_2023['season'] == row['season'])]\n",
    "    team1_away = combined_df_2023[(combined_df_2023['date'] < row['date']) & (combined_df_2023['team2'] == row['team1']) & (combined_df_2023['season'] == row['season'])]\n",
    "    \n",
    "    team2_home = combined_df_2023[(combined_df_2023['date'] < row['date']) & (combined_df_2023['team1'] == row['team2']) & (combined_df_2023['season'] == row['season'])]\n",
    "    team2_away = combined_df_2023[(combined_df_2023['date'] < row['date']) & (combined_df_2023['team2'] == row['team2']) & (combined_df_2023['season'] == row['season'])]\n",
    "\n",
    "    if not team1_home.empty:\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts3_1_home'] = team1_home['team1_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team1_home['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts5_1_home'] = team1_home['team1_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts3_1_home'] = team1_home['team2_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team1_home['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts5_1_home'] = team1_home['team2_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team2_goals'].isna().any() else np.nan\n",
    "        ####################################### ABAIXO É SOBRE FINALIZAÇÕES ###########################################\n",
    "        combined_df_2023.at[i, 'avg_total_shots_lasts5_1_home'] = team1_home['team1_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_total_shots'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_total_shots_lasts5_1_home'] = team1_home['team2_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team2_total_shots'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_otarget_shots_lasts5_1_home'] = team1_home['team1_shots_on_target'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_shots_on_target'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_out_shots_lasts5_1_home'] = team1_home['team1_shots_out'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_shots_out'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE CORNERS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_corners_lasts5_1_home'] = team1_home['team1_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_corners'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_corners_conc_lasts5_1_home'] = team1_home['team2_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team2_corners'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE FOULS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_fouls_lasts5_1_home'] = team1_home['team1_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_fouls'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_fouls_conc_lasts5_1_home'] = team1_home['team2_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team2_fouls'].isna().any() else np.nan\n",
    "\n",
    "    if not team1_away.empty:\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts3_1_away'] = team1_away['team2_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team1_away['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts5_1_away'] = team1_away['team2_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts3_1_away'] = team1_away['team1_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team1_away['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts5_1_away'] = team1_away['team1_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team1_goals'].isna().any() else np.nan\n",
    "        ####################################### ABAIXO É SOBRE FINALIZAÇÕES ###########################################\n",
    "        combined_df_2023.at[i, 'avg_total_shots_lasts5_1_away'] = team1_away['team2_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_total_shots'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_otarget_shots_lasts5_1_away'] = team1_away['team2_shots_on_target'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_shots_on_target'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_out_shots_lasts5_1_away'] = team1_away['team2_shots_out'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_shots_out'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_total_shots_lasts5_1_away'] = team1_away['team1_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team1_total_shots'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE CORNERS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_corners_lasts5_1_away'] = team1_away['team2_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_corners'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_corners_conc_lasts5_1_away'] = team1_away['team1_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team1_corners'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE FOULS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_fouls_lasts5_1_away'] = team1_away['team2_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_fouls'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_fouls_conc_lasts5_1_away'] = team1_away['team1_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team1_fouls'].isna().any() else np.nan\n",
    "\n",
    "    if not team2_home.empty:\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts3_2_home'] = team2_home['team1_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team2_home['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts5_2_home'] = team2_home['team1_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts3_2_home'] = team2_home['team2_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team2_home['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts5_2_home'] = team2_home['team2_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team2_goals'].isna().any() else np.nan\n",
    "        ####################################### ABAIXO É SOBRE FINALIZAÇÕES ###########################################\n",
    "        combined_df_2023.at[i, 'avg_total_shots_lasts5_2_home'] = team2_home['team1_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_total_shots'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_otarget_shots_lasts5_2_home'] = team2_home['team1_shots_on_target'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_shots_on_target'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_out_shots_lasts5_2_home'] = team2_home['team1_shots_out'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_shots_out'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_total_shots_lasts5_2_home'] = team2_home['team2_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team2_total_shots'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE CORNERS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_corners_lasts5_2_home'] = team2_home['team1_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_corners'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_corners_conc_lasts5_2_home'] = team2_home['team2_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team2_corners'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE FOULS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_fouls_lasts5_2_home'] = team2_home['team1_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_fouls'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_fouls_conc_lasts5_2_home'] = team2_home['team2_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team2_fouls'].isna().any() else np.nan\n",
    "\n",
    "\n",
    "    if not team2_away.empty:\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts3_2_away'] = team2_away['team2_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team2_away['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts5_2_away'] = team2_away['team2_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts3_2_away'] = team2_away['team1_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team2_away['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts5_2_away'] = team2_away['team1_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team1_goals'].isna().any() else np.nan\n",
    "        ####################################### ABAIXO É SOBRE FINALIZAÇÕES ###########################################\n",
    "        combined_df_2023.at[i, 'avg_total_shots_lasts5_2_away'] = team2_away['team2_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_total_shots'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_otarget_shots_lasts5_2_away'] = team2_away['team2_shots_on_target'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_shots_on_target'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_out_shots_lasts5_2_away'] = team2_away['team2_shots_out'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_shots_out'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_total_shots_lasts5_2_away'] = team2_away['team1_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team1_total_shots'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE CORNERS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_corners_lasts5_2_away'] = team2_away['team2_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_corners'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_corners_conc_lasts5_2_away'] = team2_away['team1_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team1_corners'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE FOULS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_fouls_lasts5_2_away'] = team2_away['team2_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_fouls'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_fouls_conc_lasts5_2_away'] = team2_away['team1_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team1_fouls'].isna().any() else np.nan\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "combined_df_2023.shape        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 140)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_result(row):\n",
    "    if row['team1_goals'] > row['team2_goals']:\n",
    "        return pd.Series([3, 0])\n",
    "    elif row['team1_goals'] < row['team2_goals']:\n",
    "        return pd.Series([0, 3])\n",
    "    else:\n",
    "        return pd.Series([1, 1])\n",
    "\n",
    "combined_df_2023[['result_team1', 'result_team2']] = combined_df_2023.apply(get_result, axis=1)\n",
    "\n",
    "def get_streak(df, result_col, results):\n",
    "    result_series = df[result_col].apply(lambda x: 1 if x in results else 0)\n",
    "    result_series = result_series * (result_series.groupby((result_series != result_series.shift()).cumsum()).cumcount() + 1)\n",
    "    return result_series\n",
    "\n",
    "# Create a dictionary to hold individual team dataframes\n",
    "team_df_dict = {}\n",
    "\n",
    "def get_individual_team_df(df, team_name): #teoricamente aqui deveria ser corners, mas o erro se apresentou menor assim:\n",
    "    if team_name in team_df_dict:\n",
    "        return team_df_dict[team_name]\n",
    "        \n",
    "    team_games = df[(df['team1'] == team_name) | (df['team2'] == team_name)].copy()\n",
    "    team_games['team_is_team1'] = team_games['team1'] == team_name\n",
    "    team_games['team_result'] = np.where(team_games['team_is_team1'], team_games['result_team1'], team_games['result_team2'])\n",
    "    team_games['team_goals'] = np.where(team_games['team_is_team1'], team_games['team1_goals'], team_games['team2_goals'])\n",
    "    team_games['team_redcards'] = np.where(team_games['team_is_team1'], team_games['team1_red_cards'], team_games['team2_red_cards'])\n",
    "\n",
    "    team_games.sort_values('date', inplace=True)\n",
    "    team_games['days_since_last_game'] = team_games['date'].diff().dt.days\n",
    "\n",
    "    team_df_dict[team_name] = team_games\n",
    "    return team_games\n",
    "\n",
    "def get_team_stats(row, df):\n",
    "    team1_games = get_individual_team_df(df, row['team1'])\n",
    "    team2_games = get_individual_team_df(df, row['team2'])\n",
    "\n",
    "    # Filter to include only games that occurred before the current game\n",
    "    team1_games = team1_games[team1_games['date'] < row['date']]\n",
    "    team2_games = team2_games[team2_games['date'] < row['date']]\n",
    "\n",
    "    stats = {}\n",
    "\n",
    "    if not team1_games.empty:\n",
    "        stats['team1_winning_streak'] = get_streak(team1_games, 'team_result', [3]).iloc[-1]\n",
    "        stats['team1_undefeated_streak'] = get_streak(team1_games, 'team_result', [1, 3]).iloc[-1]\n",
    "        stats['team1_losing_streak'] = get_streak(team1_games, 'team_result', [0]).iloc[-1]\n",
    "        stats['team1_without_winning_streak'] = get_streak(team1_games, 'team_result', [0, 1]).iloc[-1]\n",
    "        stats['avg_points_lasts5_1'] = team1_games.tail(5)['team_result'].mean()\n",
    "        stats['team1_strength'] = team1_games['team_goals'].sum() / (team1_games['team1_goals'].sum() + team1_games['team2_goals'].sum() + 0.01)\n",
    "        stats['championship_points_1'] = team1_games['team_result'].sum() / len(team1_games)\n",
    "        rested_4_or_more_days_1 = team1_games.tail(1)['days_since_last_game'].values[0] >= 4\n",
    "        stats['rested_4_days_or_more_1'] = 1 if rested_4_or_more_days_1 else -1\n",
    "\n",
    "    if not team2_games.empty:\n",
    "        stats['team2_winning_streak'] = get_streak(team2_games, 'team_result', [3]).iloc[-1]\n",
    "        stats['team2_undefeated_streak'] = get_streak(team2_games, 'team_result', [1, 3]).iloc[-1]\n",
    "        stats['team2_losing_streak'] = get_streak(team2_games, 'team_result', [0]).iloc[-1]\n",
    "        stats['team2_without_winning_streak'] = get_streak(team2_games, 'team_result', [0, 1]).iloc[-1]\n",
    "        stats['avg_points_lasts5_2'] = team2_games.tail(5)['team_result'].mean()\n",
    "        stats['team2_strength'] = team2_games['team_goals'].sum() / (team2_games['team1_goals'].sum() + team2_games['team2_goals'].sum() + 0.01)\n",
    "        stats['championship_points_2'] = team2_games['team_result'].sum() / len(team2_games)\n",
    "        rested_4_or_more_days_2 = team2_games.tail(1)['days_since_last_game'].values[0] >= 4\n",
    "        stats['rested_4_days_or_more_2'] = 1 if rested_4_or_more_days_2 else -1\n",
    "\n",
    "    return pd.Series(stats)\n",
    "\n",
    "combined_df_2023 = pd.concat([combined_df_2023, combined_df_2023.apply(lambda row: get_team_stats(row, combined_df_2023), axis=1)], axis=1)\n",
    "\n",
    "# Now, calculate the number of suspended players for the next match for each team.\n",
    "for team_name in team_df_dict.keys():\n",
    "    team_df = team_df_dict[team_name].copy()\n",
    "    team_df['next_match_suspended_players'] = team_df['team_redcards'].shift()\n",
    "\n",
    "    # Assign the suspended players back to the combined_df_2023.\n",
    "    team1_mask = combined_df_2023['team1'] == team_name\n",
    "    team2_mask = combined_df_2023['team2'] == team_name\n",
    "    combined_df_2023.loc[team1_mask, 'team1_suspended_players'] = team_df.loc[team1_mask, 'next_match_suspended_players']\n",
    "    combined_df_2023.loc[team2_mask, 'team2_suspended_players'] = team_df.loc[team2_mask, 'next_match_suspended_players']\n",
    "\n",
    "combined_df_2023.shape    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['team1',\n",
       " 'team2',\n",
       " 'team1_goals',\n",
       " 'team2_goals',\n",
       " 'season',\n",
       " 'championship',\n",
       " 'team1_shots_on_target',\n",
       " 'team1_shots_out',\n",
       " 'team2_shots_on_target',\n",
       " 'team2_shots_out',\n",
       " 'team1_red_cards',\n",
       " 'team2_red_cards',\n",
       " 'team1_fouls',\n",
       " 'team2_fouls',\n",
       " 'team1_corners',\n",
       " 'team2_corners',\n",
       " 'team1_total_shots',\n",
       " 'team2_total_shots',\n",
       " 'date',\n",
       " 'is_future_match',\n",
       " 'goal_diff_team1',\n",
       " 'goal_diff_team2',\n",
       " 'corners_diff_team1',\n",
       " 'corners_diff_team2',\n",
       " 'team1_big_win',\n",
       " 'team1_big_loss',\n",
       " 'team2_big_win',\n",
       " 'team2_big_loss',\n",
       " 'team1_ah-2.5_win',\n",
       " 'team1_ah-2.5_loss',\n",
       " 'team2_ah-2.5_win',\n",
       " 'team2_ah-2.5_loss',\n",
       " 'team1_ah+2.5_win',\n",
       " 'team1_ah+2.5_loss',\n",
       " 'team2_ah+2.5_win',\n",
       " 'team2_ah+2.5_loss',\n",
       " 'team1_over4.5',\n",
       " 'team1_under4.5',\n",
       " 'team2_over4.5',\n",
       " 'team2_under4.5',\n",
       " 'team1_over3.5',\n",
       " 'team1_under3.5',\n",
       " 'team2_over3.5',\n",
       " 'team2_under3.5',\n",
       " 'team1_over6.5',\n",
       " 'team1_under6.5',\n",
       " 'team2_over6.5',\n",
       " 'team2_under6.5',\n",
       " 'team1_big_wins_last5',\n",
       " 'team1_big_losses_last5',\n",
       " 'team2_big_wins_last5',\n",
       " 'team2_big_losses_last5',\n",
       " 'team1_ah-2.5_wins_last5',\n",
       " 'team1_ah-2.5_losses_last5',\n",
       " 'team2_ah-2.5_wins_last5',\n",
       " 'team2_ah-2.5_losses_last5',\n",
       " 'team1_ah+2.5_wins_last5',\n",
       " 'team1_ah+2.5_losses_last5',\n",
       " 'team2_ah+2.5_wins_last5',\n",
       " 'team2_ah+2.5_losses_last5',\n",
       " 'team1_over3.5_last5',\n",
       " 'team1_under3.5_last5',\n",
       " 'team2_over3.5_last5',\n",
       " 'team2_under3.5_last5',\n",
       " 'team1_over4.5_last5',\n",
       " 'team1_under4.5_last5',\n",
       " 'team2_over4.5_last5',\n",
       " 'team2_under4.5_last5',\n",
       " 'team1_over6.5_last5',\n",
       " 'team1_under6.5_last5',\n",
       " 'team2_over6.5_last5',\n",
       " 'team2_under6.5_last5',\n",
       " 'avg_scr_lasts3_1_home',\n",
       " 'avg_scr_lasts5_1_home',\n",
       " 'avg_scr_lasts3_1_away',\n",
       " 'avg_scr_lasts5_1_away',\n",
       " 'avg_conc_lasts3_1_home',\n",
       " 'avg_conc_lasts5_1_home',\n",
       " 'avg_conc_lasts3_1_away',\n",
       " 'avg_conc_lasts5_1_away',\n",
       " 'avg_scr_lasts3_2_home',\n",
       " 'avg_scr_lasts5_2_home',\n",
       " 'avg_scr_lasts3_2_away',\n",
       " 'avg_scr_lasts5_2_away',\n",
       " 'avg_conc_lasts3_2_home',\n",
       " 'avg_conc_lasts5_2_home',\n",
       " 'avg_conc_lasts3_2_away',\n",
       " 'avg_conc_lasts5_2_away',\n",
       " 'avg_total_shots_lasts5_1_home',\n",
       " 'avg_total_shots_lasts5_1_away',\n",
       " 'avg_total_shots_lasts5_2_home',\n",
       " 'avg_total_shots_lasts5_2_away',\n",
       " 'avg_otarget_shots_lasts5_1_home',\n",
       " 'avg_otarget_shots_lasts5_1_away',\n",
       " 'avg_otarget_shots_lasts5_2_home',\n",
       " 'avg_otarget_shots_lasts5_2_away',\n",
       " 'avg_out_shots_lasts5_1_home',\n",
       " 'avg_out_shots_lasts5_1_away',\n",
       " 'avg_out_shots_lasts5_2_home',\n",
       " 'avg_out_shots_lasts5_2_away',\n",
       " 'avg_conc_total_shots_lasts5_1_home',\n",
       " 'avg_conc_total_shots_lasts5_1_away',\n",
       " 'avg_conc_total_shots_lasts5_2_home',\n",
       " 'avg_conc_total_shots_lasts5_2_away',\n",
       " 'avg_corners_lasts5_1_home',\n",
       " 'avg_corners_lasts5_1_away',\n",
       " 'avg_corners_conc_lasts5_1_home',\n",
       " 'avg_corners_conc_lasts5_1_away',\n",
       " 'avg_corners_lasts5_2_home',\n",
       " 'avg_corners_lasts5_2_away',\n",
       " 'avg_corners_conc_lasts5_2_home',\n",
       " 'avg_corners_conc_lasts5_2_away',\n",
       " 'avg_fouls_lasts5_1_home',\n",
       " 'avg_fouls_lasts5_1_away',\n",
       " 'avg_fouls_conc_lasts5_1_home',\n",
       " 'avg_fouls_conc_lasts5_1_away',\n",
       " 'avg_fouls_lasts5_2_home',\n",
       " 'avg_fouls_lasts5_2_away',\n",
       " 'avg_fouls_conc_lasts5_2_home',\n",
       " 'avg_fouls_conc_lasts5_2_away',\n",
       " 'result_team1',\n",
       " 'result_team2',\n",
       " 'avg_points_lasts5_1',\n",
       " 'avg_points_lasts5_2',\n",
       " 'championship_points_1',\n",
       " 'championship_points_2',\n",
       " 'rested_4_days_or_more_1',\n",
       " 'rested_4_days_or_more_2',\n",
       " 'team1_losing_streak',\n",
       " 'team1_strength',\n",
       " 'team1_undefeated_streak',\n",
       " 'team1_winning_streak',\n",
       " 'team1_without_winning_streak',\n",
       " 'team2_losing_streak',\n",
       " 'team2_strength',\n",
       " 'team2_undefeated_streak',\n",
       " 'team2_winning_streak',\n",
       " 'team2_without_winning_streak',\n",
       " 'team1_suspended_players',\n",
       " 'team2_suspended_players']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combined_df_2023.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    " 'team1_goals',\n",
    " 'team2_goals',\n",
    " 'team1_shots_on_target',\n",
    " 'team1_shots_out',\n",
    " 'team2_shots_on_target',\n",
    " 'team2_shots_out',\n",
    " 'team1_red_cards',\n",
    " 'team2_red_cards',\n",
    " 'team1_fouls',\n",
    " 'team2_fouls',\n",
    " 'team1_corners',\n",
    " 'team2_corners',\n",
    " 'team1_total_shots',\n",
    " 'team2_total_shots',\n",
    " 'date',\n",
    " 'is_future_match',\n",
    " 'goal_diff_team1',\n",
    " 'goal_diff_team2',\n",
    " 'corners_diff_team1',\n",
    " 'corners_diff_team2',\n",
    " 'team1_big_win',\n",
    " 'team1_big_loss',\n",
    " 'team2_big_win',\n",
    " 'team2_big_loss',\n",
    " 'team1_ah-2.5_win',\n",
    " 'team1_ah-2.5_loss',\n",
    " 'team2_ah-2.5_win',\n",
    " 'team2_ah-2.5_loss',\n",
    " 'team1_ah+2.5_win',\n",
    " 'team1_ah+2.5_loss',\n",
    " 'team2_ah+2.5_win',\n",
    " 'team2_ah+2.5_loss',\n",
    " 'team1_over4.5',\n",
    " 'team1_under4.5',\n",
    " 'team2_over4.5',\n",
    " 'team2_under4.5',\n",
    " 'team1_over3.5',\n",
    " 'team1_under3.5',\n",
    " 'team2_over3.5',\n",
    " 'team2_under3.5',\n",
    " 'team1_over6.5',\n",
    " 'team1_under6.5',\n",
    " 'team2_over6.5',\n",
    " 'team2_under6.5',\n",
    " 'result_team1',\n",
    " 'result_team2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando future Match baseado na data de hoje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(261, 140)\n",
      "(18, 93)\n"
     ]
    }
   ],
   "source": [
    "dataset2 = combined_df_2023.copy()\n",
    "\n",
    "# filter the DataFrame\n",
    "future_matches = dataset2[dataset2['is_future_match'] == True]\n",
    "future_matches.sort_values(by='date')\n",
    "print(future_matches.shape)\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Get yesterday's date\n",
    "yesterday = datetime.now() - timedelta(days=1)\n",
    "\n",
    "# Filter the DataFrame to include only rows with dates greater than yesterday\n",
    "#future_matches = future_matches[future_matches['date'] > yesterday]\n",
    "\n",
    "# Liste todas as colunas que você deseja verificar\n",
    "columns_to_check= [col for col in future_matches.columns if col not in columns_to_drop]\n",
    "\n",
    "# Drop as linhas com 'np.nan' nas colunas especificadas\n",
    "future_matches = future_matches.dropna(subset=columns_to_check)\n",
    "future_matches_calculado = future_matches.drop(columns_to_drop,axis=1)\n",
    "future_matches_calculado = future_matches_calculado.drop('season',axis=1)\n",
    "\"\"\"# Contando os valores NaN em cada coluna\n",
    "nan_counts = future_matches.isna().sum()\n",
    "\n",
    "# Transformando em uma lista de pares (nome da coluna, contagem de np.nan)\n",
    "nan_list = list(nan_counts.items())\n",
    "\n",
    "# Percorrendo a lista e imprimindo cada valor individualmente com o nome da coluna\n",
    "for col_name, nan_count in nan_list:\n",
    "    print(f'{col_name}: {nan_count}')\"\"\"\n",
    "    \n",
    "print(future_matches_calculado.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(246, 140)\n",
      "A quantidade de np.nan em linhas eram 0\n",
      "Total number of rows with 'NaN' or an empty value: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(246, 140)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CORTAR AS LINHAS COM MATCHES FUTUROS AQUI\n",
    "\n",
    "# Replace empty strings with NaN\n",
    "print(dataset2.shape)\n",
    "dataset2.replace('', np.nan, inplace=True)\n",
    "print(f\"A quantidade de np.nan em linhas eram {dataset2.isna().sum().sum()}\")\n",
    "# Remove rows that contain any missing values\n",
    "dataset2.dropna(inplace=True)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "counter = 0  # Initialize counter\n",
    "for index, row in dataset2.iterrows():\n",
    "    if row.isnull().any() or row.eq('').any():\n",
    "        print(f\"Row {index} contains 'NaN' or an empty value.\")\n",
    "        counter += 1  # Increase counter if condition is met\n",
    "\n",
    "print(f\"Total number of rows with 'NaN' or an empty value: {counter}\")\n",
    "dataset2.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenando os 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>championship</th>\n",
       "      <th>date</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>team1_goals</th>\n",
       "      <th>team2_goals</th>\n",
       "      <th>team1_total_shots</th>\n",
       "      <th>team2_total_shots</th>\n",
       "      <th>team1_shots_on_target</th>\n",
       "      <th>team2_shots_on_target</th>\n",
       "      <th>...</th>\n",
       "      <th>team1_winning_streak</th>\n",
       "      <th>team1_without_winning_streak</th>\n",
       "      <th>team2_losing_streak</th>\n",
       "      <th>team2_strength</th>\n",
       "      <th>team2_undefeated_streak</th>\n",
       "      <th>team2_winning_streak</th>\n",
       "      <th>team2_without_winning_streak</th>\n",
       "      <th>team1_suspended_players</th>\n",
       "      <th>team2_suspended_players</th>\n",
       "      <th>is_future_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E0</td>\n",
       "      <td>2002-09-14</td>\n",
       "      <td>Charlton</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666297</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E0</td>\n",
       "      <td>2002-09-14</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.665927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E0</td>\n",
       "      <td>2002-09-14</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Man United</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.554939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E0</td>\n",
       "      <td>2002-09-14</td>\n",
       "      <td>West Brom</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332963</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E0</td>\n",
       "      <td>2002-09-15</td>\n",
       "      <td>Man City</td>\n",
       "      <td>Blackburn</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.454133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67081</th>\n",
       "      <td>BRA A</td>\n",
       "      <td>2023-08-20</td>\n",
       "      <td>bahia</td>\n",
       "      <td>red bull bragantino</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.613497</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67082</th>\n",
       "      <td>BRA A</td>\n",
       "      <td>2023-08-20</td>\n",
       "      <td>santos</td>\n",
       "      <td>grêmio</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.531802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67083</th>\n",
       "      <td>SUE A</td>\n",
       "      <td>2023-08-20</td>\n",
       "      <td>kalmar</td>\n",
       "      <td>hammarby if</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67084</th>\n",
       "      <td>SUE A</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>norrkoping</td>\n",
       "      <td>aik</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.438917</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67085</th>\n",
       "      <td>BRA A</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>goiás</td>\n",
       "      <td>athletico-pr</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555432</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67086 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      championship       date       team1                team2  team1_goals  \\\n",
       "0               E0 2002-09-14    Charlton              Arsenal          0.0   \n",
       "1               E0 2002-09-14     Everton        Middlesbrough          2.0   \n",
       "2               E0 2002-09-14       Leeds           Man United          1.0   \n",
       "3               E0 2002-09-14   West Brom          Southampton          1.0   \n",
       "4               E0 2002-09-15    Man City            Blackburn          2.0   \n",
       "...            ...        ...         ...                  ...          ...   \n",
       "67081        BRA A 2023-08-20       bahia  red bull bragantino          4.0   \n",
       "67082        BRA A 2023-08-20      santos               grêmio          2.0   \n",
       "67083        SUE A 2023-08-20      kalmar          hammarby if          0.0   \n",
       "67084        SUE A 2023-08-21  norrkoping                  aik          3.0   \n",
       "67085        BRA A 2023-08-21       goiás         athletico-pr          1.0   \n",
       "\n",
       "       team2_goals  team1_total_shots  team2_total_shots  \\\n",
       "0              3.0                9.0               10.0   \n",
       "1              1.0               13.0               10.0   \n",
       "2              0.0                8.0                6.0   \n",
       "3              0.0               11.0               10.0   \n",
       "4              2.0               15.0               12.0   \n",
       "...            ...                ...                ...   \n",
       "67081          0.0                9.0               10.0   \n",
       "67082          1.0               15.0                6.0   \n",
       "67083          0.0                2.0                4.0   \n",
       "67084          1.0               10.0               12.0   \n",
       "67085          1.0               13.0               11.0   \n",
       "\n",
       "       team1_shots_on_target  team2_shots_on_target  ...  \\\n",
       "0                        3.0                    8.0  ...   \n",
       "1                        8.0                    5.0  ...   \n",
       "2                        2.0                    5.0  ...   \n",
       "3                        7.0                    5.0  ...   \n",
       "4                        7.0                    8.0  ...   \n",
       "...                      ...                    ...  ...   \n",
       "67081                    6.0                    8.0  ...   \n",
       "67082                    8.0                    4.0  ...   \n",
       "67083                    1.0                    2.0  ...   \n",
       "67084                    5.0                    8.0  ...   \n",
       "67085                    4.0                    5.0  ...   \n",
       "\n",
       "       team1_winning_streak  team1_without_winning_streak  \\\n",
       "0                       0.0                           1.0   \n",
       "1                       0.0                           3.0   \n",
       "2                       1.0                           0.0   \n",
       "3                       2.0                           0.0   \n",
       "4                       0.0                           1.0   \n",
       "...                     ...                           ...   \n",
       "67081                   0.0                           7.0   \n",
       "67082                   0.0                           5.0   \n",
       "67083                   0.0                           3.0   \n",
       "67084                   4.0                           0.0   \n",
       "67085                   2.0                           0.0   \n",
       "\n",
       "       team2_losing_streak  team2_strength  team2_undefeated_streak  \\\n",
       "0                      0.0        0.666297                      5.0   \n",
       "1                      0.0        0.665927                      1.0   \n",
       "2                      1.0        0.554939                      0.0   \n",
       "3                      0.0        0.332963                      1.0   \n",
       "4                      2.0        0.454133                      0.0   \n",
       "...                    ...             ...                      ...   \n",
       "67081                  0.0        0.613497                      4.0   \n",
       "67082                  0.0        0.531802                      1.0   \n",
       "67083                  0.0        0.469292                      1.0   \n",
       "67084                  0.0        0.438917                      5.0   \n",
       "67085                  0.0        0.555432                      5.0   \n",
       "\n",
       "       team2_winning_streak  team2_without_winning_streak  \\\n",
       "0                       1.0                           0.0   \n",
       "1                       1.0                           0.0   \n",
       "2                       0.0                           1.0   \n",
       "3                       1.0                           0.0   \n",
       "4                       0.0                           3.0   \n",
       "...                     ...                           ...   \n",
       "67081                   0.0                           1.0   \n",
       "67082                   1.0                           0.0   \n",
       "67083                   1.0                           0.0   \n",
       "67084                   0.0                           2.0   \n",
       "67085                   1.0                           0.0   \n",
       "\n",
       "       team1_suspended_players team2_suspended_players  is_future_match  \n",
       "0                          0.0                     0.0              NaN  \n",
       "1                          0.0                     0.0              NaN  \n",
       "2                          0.0                     0.0              NaN  \n",
       "3                          0.0                     0.0              NaN  \n",
       "4                          1.0                     0.0              NaN  \n",
       "...                        ...                     ...              ...  \n",
       "67081                      0.0                     0.0            False  \n",
       "67082                      0.0                     0.0            False  \n",
       "67083                      0.0                     0.0            False  \n",
       "67084                      0.0                     0.0            False  \n",
       "67085                      0.0                     0.0            False  \n",
       "\n",
       "[67086 rows x 140 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatotal = pd.concat([dataset, dataset2], ignore_index=True)#mudei o 'dataset' por combined_df_13c_new\n",
    "\n",
    "datatotal.sort_values(by='date', inplace=True)\n",
    "\n",
    "if 'team1_yellow_cards' in datatotal.columns:\n",
    "    datatotal = datatotal.drop(['team1_yellow_cards'], axis=1)\n",
    "\n",
    "if 'team2_yellow_cards' in datatotal.columns:\n",
    "    datatotal = datatotal.drop(['team2_yellow_cards'], axis=1)\n",
    "\n",
    "# Substituir valores maiores que 15 por 15 na coluna 'team1_corners'\n",
    "datatotal.loc[datatotal['team1_corners'] > 15, 'team1_corners'] = 15\n",
    "\n",
    "# Substituir valores maiores que 15 por 15 na coluna 'team2_corners'\n",
    "datatotal.loc[datatotal['team2_corners'] > 15, 'team2_corners'] = 15    \n",
    "\n",
    "datatotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E0' 'SC0' 'E3' 'E2' 'E1' 'I1' 'SP1' 'D1' 'F1' 'D2' 'P1' 'SP2' 'T1' 'I2'\n",
      " 'N1' 'F2' 'B1' 'G1' 'SUE A' 'BRA A']\n"
     ]
    }
   ],
   "source": [
    "champ_uniques = datatotal['championship'].unique()\n",
    "print(champ_uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converta Categorias em IDs Numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Suponho que 'datatotal' e 'future_matches' já estejam definidos e tenham as mesmas colunas relevantes\n",
    "\n",
    "# Treinar o LabelEncoder com 'datatotal' e 'future_matches'\n",
    "le_teams = LabelEncoder().fit(pd.concat([datatotal['team1'], datatotal['team2'], future_matches_calculado['team1'], future_matches_calculado['team2']]).astype(str))\n",
    "le_champ = LabelEncoder().fit(pd.concat([datatotal['championship'], future_matches_calculado['championship']]).astype(str))\n",
    "\n",
    "# Aplicar o LabelEncoder a 'datatotal'\n",
    "datatotal['team1'] = le_teams.transform(datatotal['team1'].astype(str))\n",
    "datatotal['team2'] = le_teams.transform(datatotal['team2'].astype(str))\n",
    "datatotal['championship'] = le_champ.transform(datatotal['championship'].astype(str))\n",
    "\n",
    "# Agora, aplicar o mesmo LabelEncoder a 'future_matches'\n",
    "future_matches_calculado['team1'] = le_teams.transform(future_matches_calculado['team1'].astype(str))\n",
    "future_matches_calculado['team2'] = le_teams.transform(future_matches_calculado['team2'].astype(str))\n",
    "future_matches_calculado['championship'] = le_champ.transform(future_matches_calculado['championship'].astype(str))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>championship</th>\n",
       "      <th>team1_big_wins_last5</th>\n",
       "      <th>team1_big_losses_last5</th>\n",
       "      <th>team2_big_wins_last5</th>\n",
       "      <th>team2_big_losses_last5</th>\n",
       "      <th>team1_ah-2.5_wins_last5</th>\n",
       "      <th>team1_ah-2.5_losses_last5</th>\n",
       "      <th>team2_ah-2.5_wins_last5</th>\n",
       "      <th>...</th>\n",
       "      <th>team1_undefeated_streak</th>\n",
       "      <th>team1_winning_streak</th>\n",
       "      <th>team1_without_winning_streak</th>\n",
       "      <th>team2_losing_streak</th>\n",
       "      <th>team2_strength</th>\n",
       "      <th>team2_undefeated_streak</th>\n",
       "      <th>team2_winning_streak</th>\n",
       "      <th>team2_without_winning_streak</th>\n",
       "      <th>team1_suspended_players</th>\n",
       "      <th>team2_suspended_players</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>475</td>\n",
       "      <td>485</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386276</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>482</td>\n",
       "      <td>492</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.410151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>486</td>\n",
       "      <td>477</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>498</td>\n",
       "      <td>478</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.476077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>495</td>\n",
       "      <td>488</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469292</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     team1  team2  championship  team1_big_wins_last5  team1_big_losses_last5  \\\n",
       "190    475    485             1                   2.0                     0.0   \n",
       "189    482    492             1                   0.0                     1.0   \n",
       "197    486    477             1                   0.0                     0.0   \n",
       "192    498    478             1                   1.0                     1.0   \n",
       "524    495    488            18                   1.0                     1.0   \n",
       "\n",
       "     team2_big_wins_last5  team2_big_losses_last5  team1_ah-2.5_wins_last5  \\\n",
       "190                   0.0                     0.0                      1.0   \n",
       "189                   0.0                     1.0                      2.0   \n",
       "197                   0.0                     0.0                      0.0   \n",
       "192                   1.0                     2.0                      3.0   \n",
       "524                   1.0                     0.0                      1.0   \n",
       "\n",
       "     team1_ah-2.5_losses_last5  team2_ah-2.5_wins_last5  ...  \\\n",
       "190                        4.0                      1.0  ...   \n",
       "189                        3.0                      1.0  ...   \n",
       "197                        5.0                      3.0  ...   \n",
       "192                        2.0                      2.0  ...   \n",
       "524                        4.0                      3.0  ...   \n",
       "\n",
       "     team1_undefeated_streak  team1_winning_streak  \\\n",
       "190                      6.0                   0.0   \n",
       "189                      2.0                   1.0   \n",
       "197                      0.0                   0.0   \n",
       "192                      0.0                   0.0   \n",
       "524                      0.0                   0.0   \n",
       "\n",
       "     team1_without_winning_streak  team2_losing_streak  team2_strength  \\\n",
       "190                           1.0                  0.0        0.386276   \n",
       "189                           0.0                  2.0        0.410151   \n",
       "197                           1.0                  0.0        0.483715   \n",
       "192                           2.0                  2.0        0.476077   \n",
       "524                           1.0                  0.0        0.469292   \n",
       "\n",
       "     team2_undefeated_streak  team2_winning_streak  \\\n",
       "190                      6.0                   0.0   \n",
       "189                      0.0                   0.0   \n",
       "197                      1.0                   0.0   \n",
       "192                      0.0                   0.0   \n",
       "524                      2.0                   0.0   \n",
       "\n",
       "     team2_without_winning_streak  team1_suspended_players  \\\n",
       "190                           1.0                      0.0   \n",
       "189                           8.0                      0.0   \n",
       "197                           6.0                      1.0   \n",
       "192                           2.0                      0.0   \n",
       "524                           1.0                      0.0   \n",
       "\n",
       "     team2_suspended_players  \n",
       "190                      0.0  \n",
       "189                      0.0  \n",
       "197                      0.0  \n",
       "192                      0.0  \n",
       "524                      0.0  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_matches_calculado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "n_teams = len(le_teams.classes_)\n",
    "n_champ = len(le_champ.classes_)\n",
    "print(n_teams)\n",
    "print(n_champ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatotal['season'] = datatotal['season'].astype('float64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando X e Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67086, 94)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = datatotal.drop(columns_to_drop, axis=1)\n",
    "y1 = datatotal['team1_corners']\n",
    "y2 = datatotal['team2_corners']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dtype('int32'),\n",
       " dtype('int32'),\n",
       " dtype('int32'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64')]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['championship',\n",
       " 'team1',\n",
       " 'team2',\n",
       " 'season',\n",
       " 'team1_big_wins_last5',\n",
       " 'team1_big_losses_last5',\n",
       " 'team2_big_wins_last5',\n",
       " 'team2_big_losses_last5',\n",
       " 'team1_ah-2.5_wins_last5',\n",
       " 'team1_ah-2.5_losses_last5',\n",
       " 'team2_ah-2.5_wins_last5',\n",
       " 'team2_ah-2.5_losses_last5',\n",
       " 'team1_ah+2.5_wins_last5',\n",
       " 'team1_ah+2.5_losses_last5',\n",
       " 'team2_ah+2.5_wins_last5',\n",
       " 'team2_ah+2.5_losses_last5',\n",
       " 'team1_over3.5_last5',\n",
       " 'team1_under3.5_last5',\n",
       " 'team2_over3.5_last5',\n",
       " 'team2_under3.5_last5',\n",
       " 'team1_over4.5_last5',\n",
       " 'team1_under4.5_last5',\n",
       " 'team2_over4.5_last5',\n",
       " 'team2_under4.5_last5',\n",
       " 'team1_over6.5_last5',\n",
       " 'team1_under6.5_last5',\n",
       " 'team2_over6.5_last5',\n",
       " 'team2_under6.5_last5',\n",
       " 'avg_scr_lasts3_1_home',\n",
       " 'avg_scr_lasts5_1_home',\n",
       " 'avg_scr_lasts3_1_away',\n",
       " 'avg_scr_lasts5_1_away',\n",
       " 'avg_conc_lasts3_1_home',\n",
       " 'avg_conc_lasts5_1_home',\n",
       " 'avg_conc_lasts3_1_away',\n",
       " 'avg_conc_lasts5_1_away',\n",
       " 'avg_scr_lasts3_2_home',\n",
       " 'avg_scr_lasts5_2_home',\n",
       " 'avg_scr_lasts3_2_away',\n",
       " 'avg_scr_lasts5_2_away',\n",
       " 'avg_conc_lasts3_2_home',\n",
       " 'avg_conc_lasts5_2_home',\n",
       " 'avg_conc_lasts3_2_away',\n",
       " 'avg_conc_lasts5_2_away',\n",
       " 'avg_total_shots_lasts5_1_home',\n",
       " 'avg_total_shots_lasts5_1_away',\n",
       " 'avg_total_shots_lasts5_2_home',\n",
       " 'avg_total_shots_lasts5_2_away',\n",
       " 'avg_otarget_shots_lasts5_1_home',\n",
       " 'avg_otarget_shots_lasts5_1_away',\n",
       " 'avg_otarget_shots_lasts5_2_home',\n",
       " 'avg_otarget_shots_lasts5_2_away',\n",
       " 'avg_out_shots_lasts5_1_home',\n",
       " 'avg_out_shots_lasts5_1_away',\n",
       " 'avg_out_shots_lasts5_2_home',\n",
       " 'avg_out_shots_lasts5_2_away',\n",
       " 'avg_conc_total_shots_lasts5_1_home',\n",
       " 'avg_conc_total_shots_lasts5_1_away',\n",
       " 'avg_conc_total_shots_lasts5_2_home',\n",
       " 'avg_conc_total_shots_lasts5_2_away',\n",
       " 'avg_corners_lasts5_1_home',\n",
       " 'avg_corners_lasts5_1_away',\n",
       " 'avg_corners_conc_lasts5_1_home',\n",
       " 'avg_corners_conc_lasts5_1_away',\n",
       " 'avg_corners_lasts5_2_home',\n",
       " 'avg_corners_lasts5_2_away',\n",
       " 'avg_corners_conc_lasts5_2_home',\n",
       " 'avg_corners_conc_lasts5_2_away',\n",
       " 'avg_fouls_lasts5_1_home',\n",
       " 'avg_fouls_lasts5_1_away',\n",
       " 'avg_fouls_conc_lasts5_1_home',\n",
       " 'avg_fouls_conc_lasts5_1_away',\n",
       " 'avg_fouls_lasts5_2_home',\n",
       " 'avg_fouls_lasts5_2_away',\n",
       " 'avg_fouls_conc_lasts5_2_home',\n",
       " 'avg_fouls_conc_lasts5_2_away',\n",
       " 'avg_points_lasts5_1',\n",
       " 'avg_points_lasts5_2',\n",
       " 'championship_points_1',\n",
       " 'championship_points_2',\n",
       " 'rested_4_days_or_more_1',\n",
       " 'rested_4_days_or_more_2',\n",
       " 'team1_losing_streak',\n",
       " 'team1_strength',\n",
       " 'team1_undefeated_streak',\n",
       " 'team1_winning_streak',\n",
       " 'team1_without_winning_streak',\n",
       " 'team2_losing_streak',\n",
       " 'team2_strength',\n",
       " 'team2_undefeated_streak',\n",
       " 'team2_winning_streak',\n",
       " 'team2_without_winning_streak',\n",
       " 'team1_suspended_players',\n",
       " 'team2_suspended_players']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. 10.  4.  0. 15.  9.  8.  5.  6.  7.  3. 12. 11. 14.  2. 13.]\n"
     ]
    }
   ],
   "source": [
    "y1_uniques = datatotal['team1_corners'].unique()\n",
    "print(y1_uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem de ocorrências para y1:\n",
      "team1_corners\n",
      "0      695\n",
      "1     2435\n",
      "2     5020\n",
      "3     7572\n",
      "4     9206\n",
      "5     9501\n",
      "6     8621\n",
      "7     7231\n",
      "8     5569\n",
      "9     3947\n",
      "10    2772\n",
      "11    1817\n",
      "12    1112\n",
      "13     710\n",
      "14     416\n",
      "15     462\n",
      "16       0\n",
      "17       0\n",
      "18       0\n",
      "19       0\n",
      "20       0\n",
      "21       0\n",
      "22       0\n",
      "23       0\n",
      "24       0\n",
      "25       0\n",
      "26       0\n",
      "27       0\n",
      "28       0\n",
      "29       0\n",
      "30       0\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Contagem de ocorrências para y2:\n",
      "team2_corners\n",
      "0      1556\n",
      "1      4938\n",
      "2      8146\n",
      "3     10270\n",
      "4     10632\n",
      "5      9468\n",
      "6      7381\n",
      "7      5625\n",
      "8      3580\n",
      "9      2335\n",
      "10     1369\n",
      "11      847\n",
      "12      415\n",
      "13      283\n",
      "14      137\n",
      "15      104\n",
      "16        0\n",
      "17        0\n",
      "18        0\n",
      "19        0\n",
      "20        0\n",
      "21        0\n",
      "22        0\n",
      "23        0\n",
      "24        0\n",
      "25        0\n",
      "26        0\n",
      "27        0\n",
      "28        0\n",
      "29        0\n",
      "30        0\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contar ocorrências para 'y1'\n",
    "y1_counts = y1.value_counts().sort_index().reindex(range(0, 31), fill_value=0)\n",
    "print(\"Contagem de ocorrências para y1:\")\n",
    "print(y1_counts)\n",
    "\n",
    "# Contar ocorrências para 'y2'\n",
    "y2_counts = y2.value_counts().sort_index().reindex(range(0, 31), fill_value=0)\n",
    "print(\"\\nContagem de ocorrências para y2:\")\n",
    "print(y2_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando o treino e o teste e a normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Dividindo os dados com base na coluna 'season'\n",
    "X_train1 = X[X['season'] < 2022].drop(['team1', 'team2', 'championship', 'season'], axis=1)\n",
    "X_test1 = X[X['season'] >= 2022].drop(['team1', 'team2', 'championship', 'season'], axis=1)\n",
    "y_train1 = y1[X['season'] < 2022]\n",
    "y_test1 = y1[X['season'] >= 2022]\n",
    "\n",
    "X_train2 = X[X['season'] < 2022].drop(['team1', 'team2', 'championship', 'season'], axis=1)\n",
    "X_test2 = X[X['season'] >= 2022].drop(['team1', 'team2', 'championship', 'season'], axis=1)\n",
    "y_train2 = y2[X['season'] < 2022]\n",
    "y_test2 = y2[X['season'] >= 2022]\n",
    "\n",
    "# Escalando os dados\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustar o escalonador com base no conjunto de treinamento\n",
    "scaler.fit(X_train1)\n",
    "\n",
    "\n",
    "# Escalando apenas as colunas que você quer (ajuste isso conforme suas necessidades)\n",
    "cols_to_scale = [col for col in future_matches_calculado.columns if col not in ['team1', 'team2', 'championship']]\n",
    "scaler = StandardScaler().fit(X_train1[cols_to_scale])\n",
    "\n",
    "# Aplicar o escalonamento\n",
    "future_matches_calculado_scaled = future_matches_calculado.copy()\n",
    "future_matches_calculado_scaled[cols_to_scale] = scaler.transform(future_matches_calculado[cols_to_scale])\n",
    "\n",
    "# Agora, você pode usar future_matches_calculado_scaled para fazer previsões\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Transformar os conjuntos de treinamento e teste\n",
    "X_train1_scaled = scaler.transform(X_train1)\n",
    "X_test1_scaled = scaler.transform(X_test1)\n",
    "\n",
    "X_train2_scaled = scaler.transform(X_train2)\n",
    "X_test2_scaled = scaler.transform(X_test2)\n",
    "\n",
    "# Preparar as colunas para o embedding\n",
    "X_train1_embed = X[X['season'] < 2022][['team1', 'team2', 'championship']]\n",
    "X_test1_embed = X[X['season'] >= 2022][['team1', 'team2', 'championship']]\n",
    "\n",
    "X_train2_embed = X[X['season'] < 2022][['team1', 'team2', 'championship']]\n",
    "X_test2_embed = X[X['season'] >= 2022][['team1', 'team2', 'championship']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['team1_big_wins_last5',\n",
       " 'team1_big_losses_last5',\n",
       " 'team2_big_wins_last5',\n",
       " 'team2_big_losses_last5',\n",
       " 'team1_ah-2.5_wins_last5',\n",
       " 'team1_ah-2.5_losses_last5',\n",
       " 'team2_ah-2.5_wins_last5',\n",
       " 'team2_ah-2.5_losses_last5',\n",
       " 'team1_ah+2.5_wins_last5',\n",
       " 'team1_ah+2.5_losses_last5',\n",
       " 'team2_ah+2.5_wins_last5',\n",
       " 'team2_ah+2.5_losses_last5',\n",
       " 'team1_over3.5_last5',\n",
       " 'team1_under3.5_last5',\n",
       " 'team2_over3.5_last5',\n",
       " 'team2_under3.5_last5',\n",
       " 'team1_over4.5_last5',\n",
       " 'team1_under4.5_last5',\n",
       " 'team2_over4.5_last5',\n",
       " 'team2_under4.5_last5',\n",
       " 'team1_over6.5_last5',\n",
       " 'team1_under6.5_last5',\n",
       " 'team2_over6.5_last5',\n",
       " 'team2_under6.5_last5',\n",
       " 'avg_scr_lasts3_1_home',\n",
       " 'avg_scr_lasts5_1_home',\n",
       " 'avg_scr_lasts3_1_away',\n",
       " 'avg_scr_lasts5_1_away',\n",
       " 'avg_conc_lasts3_1_home',\n",
       " 'avg_conc_lasts5_1_home',\n",
       " 'avg_conc_lasts3_1_away',\n",
       " 'avg_conc_lasts5_1_away',\n",
       " 'avg_scr_lasts3_2_home',\n",
       " 'avg_scr_lasts5_2_home',\n",
       " 'avg_scr_lasts3_2_away',\n",
       " 'avg_scr_lasts5_2_away',\n",
       " 'avg_conc_lasts3_2_home',\n",
       " 'avg_conc_lasts5_2_home',\n",
       " 'avg_conc_lasts3_2_away',\n",
       " 'avg_conc_lasts5_2_away',\n",
       " 'avg_total_shots_lasts5_1_home',\n",
       " 'avg_total_shots_lasts5_1_away',\n",
       " 'avg_total_shots_lasts5_2_home',\n",
       " 'avg_total_shots_lasts5_2_away',\n",
       " 'avg_otarget_shots_lasts5_1_home',\n",
       " 'avg_otarget_shots_lasts5_1_away',\n",
       " 'avg_otarget_shots_lasts5_2_home',\n",
       " 'avg_otarget_shots_lasts5_2_away',\n",
       " 'avg_out_shots_lasts5_1_home',\n",
       " 'avg_out_shots_lasts5_1_away',\n",
       " 'avg_out_shots_lasts5_2_home',\n",
       " 'avg_out_shots_lasts5_2_away',\n",
       " 'avg_conc_total_shots_lasts5_1_home',\n",
       " 'avg_conc_total_shots_lasts5_1_away',\n",
       " 'avg_conc_total_shots_lasts5_2_home',\n",
       " 'avg_conc_total_shots_lasts5_2_away',\n",
       " 'avg_corners_lasts5_1_home',\n",
       " 'avg_corners_lasts5_1_away',\n",
       " 'avg_corners_conc_lasts5_1_home',\n",
       " 'avg_corners_conc_lasts5_1_away',\n",
       " 'avg_corners_lasts5_2_home',\n",
       " 'avg_corners_lasts5_2_away',\n",
       " 'avg_corners_conc_lasts5_2_home',\n",
       " 'avg_corners_conc_lasts5_2_away',\n",
       " 'avg_fouls_lasts5_1_home',\n",
       " 'avg_fouls_lasts5_1_away',\n",
       " 'avg_fouls_conc_lasts5_1_home',\n",
       " 'avg_fouls_conc_lasts5_1_away',\n",
       " 'avg_fouls_lasts5_2_home',\n",
       " 'avg_fouls_lasts5_2_away',\n",
       " 'avg_fouls_conc_lasts5_2_home',\n",
       " 'avg_fouls_conc_lasts5_2_away',\n",
       " 'avg_points_lasts5_1',\n",
       " 'avg_points_lasts5_2',\n",
       " 'championship_points_1',\n",
       " 'championship_points_2',\n",
       " 'rested_4_days_or_more_1',\n",
       " 'rested_4_days_or_more_2',\n",
       " 'team1_losing_streak',\n",
       " 'team1_strength',\n",
       " 'team1_undefeated_streak',\n",
       " 'team1_winning_streak',\n",
       " 'team1_without_winning_streak',\n",
       " 'team2_losing_streak',\n",
       " 'team2_strength',\n",
       " 'team2_undefeated_streak',\n",
       " 'team2_winning_streak',\n",
       " 'team2_without_winning_streak',\n",
       " 'team1_suspended_players',\n",
       " 'team2_suspended_players']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_train1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61353, 90)\n",
      "(5733, 90)\n",
      "(61353,)\n",
      "(5733,)\n",
      "(61353, 90)\n",
      "(5733, 90)\n",
      "(61353,)\n",
      "(5733,)\n",
      "(61353, 3)\n",
      "(5733, 3)\n",
      "(61353, 3)\n",
      "(5733, 3)\n",
      "(18, 93)\n"
     ]
    }
   ],
   "source": [
    "print(X_train1_scaled.shape)\n",
    "print(X_test1_scaled.shape)\n",
    "print(y_train1.shape)\n",
    "print(y_test1.shape)\n",
    "print(X_train2_scaled.shape)\n",
    "print(X_test2_scaled.shape)\n",
    "print(y_train2.shape)\n",
    "print(y_test2.shape)\n",
    "print(X_train1_embed.shape)\n",
    "print(X_test1_embed.shape)\n",
    "print(X_train2_embed.shape)\n",
    "print(X_test2_embed.shape)\n",
    "print(future_matches_calculado_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função de perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, [-1])\n",
    "    y_pred = tf.reshape(y_pred, [-1])\n",
    "\n",
    "    avg = tf.reduce_mean(y_true)\n",
    "    abs_error = tf.abs(y_true - y_pred)\n",
    "    distance_to_avg = tf.abs(y_pred - avg)\n",
    "    reward = tf.math.log(distance_to_avg + 3)\n",
    "    penalty = 2 * abs_error / (distance_to_avg + 3)\n",
    "    \n",
    "    # Aplicando a função tanh ao resultado de (penalty - reward)\n",
    "    normalized_diff = tf.math.tanh(penalty - reward)\n",
    "    \n",
    "    # Somando com abs_error\n",
    "    custom_loss_value = abs_error + normalized_diff\n",
    "    \n",
    "    # Garantindo que o valor mínimo da perda seja 0.0001\n",
    "    custom_loss_value = tf.maximum(custom_loss_value, 0.0001)\n",
    "    \n",
    "    return tf.reduce_mean(custom_loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testes de funções de erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 1:\n",
      "y_true: 13.0\n",
      "y_pred: 1.1799863576889038\n",
      "Custom Loss Value: 12.7691\n",
      "=========================\n",
      "Scenario 2:\n",
      "y_true: 5.0\n",
      "y_pred: 11.976266860961914\n",
      "Custom Loss Value: 6.2168\n",
      "=========================\n",
      "Scenario 3:\n",
      "y_true: 15.0\n",
      "y_pred: 5.410640716552734\n",
      "Custom Loss Value: 10.5881\n",
      "=========================\n",
      "Scenario 4:\n",
      "y_true: 8.0\n",
      "y_pred: 12.097575187683105\n",
      "Custom Loss Value: 3.1805\n",
      "=========================\n",
      "Scenario 5:\n",
      "y_true: 9.0\n",
      "y_pred: 0.09384145587682724\n",
      "Custom Loss Value: 9.2490\n",
      "=========================\n",
      "Scenario 6:\n",
      "y_true: 8.0\n",
      "y_pred: 13.799418449401855\n",
      "Custom Loss Value: 4.8855\n",
      "=========================\n",
      "Scenario 7:\n",
      "y_true: 11.0\n",
      "y_pred: 6.310484409332275\n",
      "Custom Loss Value: 5.1042\n",
      "=========================\n",
      "Scenario 8:\n",
      "y_true: 13.0\n",
      "y_pred: 4.798759460449219\n",
      "Custom Loss Value: 9.2005\n",
      "=========================\n",
      "Scenario 9:\n",
      "y_true: 5.0\n",
      "y_pred: 9.279520034790039\n",
      "Custom Loss Value: 3.5517\n",
      "=========================\n",
      "Scenario 10:\n",
      "y_true: 10.0\n",
      "y_pred: 7.56310510635376\n",
      "Custom Loss Value: 1.6890\n",
      "=========================\n",
      "Scenario 11:\n",
      "y_true: 6.0\n",
      "y_pred: 11.377161026000977\n",
      "Custom Loss Value: 4.5497\n",
      "=========================\n",
      "Scenario 12:\n",
      "y_true: 10.0\n",
      "y_pred: 1.765364170074463\n",
      "Custom Loss Value: 9.0199\n",
      "=========================\n",
      "Scenario 13:\n",
      "y_true: 13.0\n",
      "y_pred: 7.460981369018555\n",
      "Custom Loss Value: 5.6602\n",
      "=========================\n",
      "Scenario 14:\n",
      "y_true: 10.0\n",
      "y_pred: 14.780413627624512\n",
      "Custom Loss Value: 3.8284\n",
      "=========================\n",
      "Scenario 15:\n",
      "y_true: 7.0\n",
      "y_pred: 8.64370346069336\n",
      "Custom Loss Value: 0.7412\n",
      "=========================\n",
      "Scenario 16:\n",
      "y_true: 11.0\n",
      "y_pred: 14.279133796691895\n",
      "Custom Loss Value: 2.3135\n",
      "=========================\n",
      "Scenario 17:\n",
      "y_true: 15.0\n",
      "y_pred: 3.158615827560425\n",
      "Custom Loss Value: 12.8405\n",
      "=========================\n",
      "Scenario 18:\n",
      "y_true: 10.0\n",
      "y_pred: 13.690688133239746\n",
      "Custom Loss Value: 2.7360\n",
      "=========================\n",
      "Scenario 19:\n",
      "y_true: 2.0\n",
      "y_pred: 4.717651844024658\n",
      "Custom Loss Value: 3.2592\n",
      "=========================\n",
      "Scenario 20:\n",
      "y_true: 9.0\n",
      "y_pred: 14.89667797088623\n",
      "Custom Loss Value: 4.9612\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def custom_loss_test(y_true, y_pred):\n",
    "\n",
    "\n",
    "    avg = 4.6\n",
    "    abs_error = tf.abs(y_true - y_pred)\n",
    "    distance_to_avg = tf.abs(y_pred - avg)\n",
    "    reward = tf.math.log(distance_to_avg + 3)\n",
    "    penalty = 2 * abs_error / (distance_to_avg + 3)\n",
    "    \n",
    "    # Aplicando a função tanh ao resultado de (penalty - reward)\n",
    "    normalized_diff = tf.math.tanh(penalty - reward)\n",
    "    \n",
    "    # Somando com abs_error\n",
    "    custom_loss_value = abs_error + normalized_diff\n",
    "    \n",
    "    # Garantindo que o valor mínimo da perda seja 0.0001\n",
    "    custom_loss_value = tf.maximum(custom_loss_value, 0.0001)\n",
    "    \n",
    "    return tf.reduce_mean(custom_loss_value)\n",
    "\n",
    "# Simulando 20 cenários diferentes\n",
    "for i in range(20):\n",
    "    y_true = tf.constant(np.random.randint(0, 16), dtype=tf.float32)\n",
    "    y_pred = tf.constant(np.random.uniform(0, 16), dtype=tf.float32)\n",
    "    \n",
    "    loss_value = custom_loss_test(y_true, y_pred)\n",
    "    \n",
    "    print(f\"Scenario {i+1}:\")\n",
    "    print(f\"y_true: {y_true.numpy()}\")\n",
    "    print(f\"y_pred: {y_pred.numpy()}\")\n",
    "    print(f\"Custom Loss Value: {loss_value.numpy():.4f}\")\n",
    "\n",
    "    print(\"=\"*25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ==== Parte 1: Definindo os Inputs para o Embedding ====\n",
    "# Estes são os inputs que vão alimentar os embeddings. \n",
    "# Cada input tem a dimensão de (1,) porque cada jogo tem exatamente um 'team1', um 'team2', e um 'championship'.\n",
    "team1_input = Input(shape=(1,), name='Team1-Input')\n",
    "team2_input = Input(shape=(1,), name='Team2-Input')\n",
    "champ_input = Input(shape=(1,), name='Championship-Input')\n",
    "\n",
    "# ==== Parte 2: Criando os Embeddings ====\n",
    "# n_teams e n_champ são o número de times e campeonatos únicos, respectivamente.\n",
    "# O output_dim é um hiperparâmetro para você ajustar. Ele define o tamanho do espaço de embedding.\n",
    "\n",
    "# Embedding para o time 1\n",
    "team1_embedding = Embedding(input_dim=n_teams, output_dim=50, name='Team1-Embedding')(team1_input)  # output_dim ajustável\n",
    "\n",
    "# Embedding para o time 2\n",
    "team2_embedding = Embedding(input_dim=n_teams, output_dim=50, name='Team2-Embedding')(team2_input)  # output_dim ajustável\n",
    "\n",
    "# Embedding para o campeonato\n",
    "champ_embedding = Embedding(input_dim=n_champ, output_dim=5, name='Championship-Embedding')(champ_input)  # output_dim ajustável\n",
    "\n",
    "# ==== Parte 3: Achatando os Embeddings ====\n",
    "# Cada embedding precisa ser achatado para ser concatenado posteriormente\n",
    "team1_embedding = Flatten()(team1_embedding)\n",
    "team2_embedding = Flatten()(team2_embedding)\n",
    "champ_embedding = Flatten()(champ_embedding)\n",
    "\n",
    "# ==== Parte 4: Outras Características ====\n",
    "# Este é o input para as outras características (já escaladas) do seu conjunto de dados.\n",
    "other_features_input = Input(shape=(X_train1_scaled.shape[1],), name='Other-Features-Input')\n",
    "\n",
    "# ==== Parte 5: Concatenando Tudo ====\n",
    "# Aqui, todos os embeddings e as outras características são concatenados em um único vetor\n",
    "merged = Concatenate()([team1_embedding, team2_embedding, champ_embedding, other_features_input])\n",
    "\n",
    "# ==== Parte 6: Camadas Ocultas ====\n",
    "# Estes são os neurônios e camadas totalmente conectadas (Dense) onde a \"aprendizagem\" real acontece.\n",
    "# Você pode ajustar o número de neurônios, a função de ativação, e outros hiperparâmetros aqui.\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "hidden_layer = Dense(512, activation='relu', kernel_regularizer=l2(0.0001))(merged)\n",
    "hidden_layer = Dropout(0.2)(hidden_layer)\n",
    "\n",
    "hidden_layer = Dense(256, activation='tanh')(hidden_layer)\n",
    "hidden_layer = Dropout(0.2)(hidden_layer)\n",
    "\n",
    "hidden_layer = Dense(128, activation='tanh')(hidden_layer)\n",
    "hidden_layer = Dropout(0.2)(hidden_layer)\n",
    "\n",
    "hidden_layer = Dense(64, activation='tanh')(hidden_layer)\n",
    "hidden_layer = Dropout(0.2)(hidden_layer)\n",
    "\n",
    "hidden_layer = Dense(32, activation='tanh')(hidden_layer)\n",
    "hidden_layer = Dropout(0.2)(hidden_layer)\n",
    "\n",
    "hidden_layer = Dense(16, activation='tanh')(hidden_layer)\n",
    "hidden_layer = Dropout(0.2)(hidden_layer)\n",
    "\n",
    "#hidden_layer = Dense(8, activation='tanh')(hidden_layer)\n",
    "#hidden_layer = Dropout(0.2)(hidden_layer)\n",
    "\n",
    "# ==== Parte 7: Camada de Saída ====\n",
    "# Esta é a camada de saída. A função de ativação 'linear' é usada para regressão.\n",
    "output = Dense(1, activation='linear', name='Output-Layer')(hidden_layer)\n",
    "\n",
    "# ==== Parte 8: Compilando o Modelo ====\n",
    "# Finalmente, o modelo é compilado. O otimizador Adam é usado, com uma taxa de aprendizagem de 0.001.\n",
    "# A perda é definida como 'mean_squared_error', que é comum para problemas de regressão.\n",
    "model = Model(\n",
    "    inputs=[team1_input, team2_input, champ_input, other_features_input], \n",
    "    outputs=[output]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "384/384 [==============================] - 6s 11ms/step - loss: 2.3696 - mean_absolute_error: 2.4618 - val_loss: 2.1255 - val_mean_absolute_error: 2.1901\n",
      "Epoch 2/100\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.2732 - mean_absolute_error: 2.3855 - val_loss: 2.1107 - val_mean_absolute_error: 2.2501\n",
      "Epoch 3/100\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.2465 - mean_absolute_error: 2.3803 - val_loss: 2.0924 - val_mean_absolute_error: 2.2127\n",
      "Epoch 4/100\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.2285 - mean_absolute_error: 2.3751 - val_loss: 2.0847 - val_mean_absolute_error: 2.2248\n",
      "Epoch 5/100\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.2118 - mean_absolute_error: 2.3642 - val_loss: 2.0759 - val_mean_absolute_error: 2.2569\n",
      "Epoch 6/100\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.1937 - mean_absolute_error: 2.3563 - val_loss: 2.1102 - val_mean_absolute_error: 2.2329\n",
      "Epoch 7/100\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.1839 - mean_absolute_error: 2.3505 - val_loss: 2.0968 - val_mean_absolute_error: 2.2646\n",
      "Epoch 8/100\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.1744 - mean_absolute_error: 2.3407 - val_loss: 2.0843 - val_mean_absolute_error: 2.3231\n",
      "Epoch 9/100\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.1603 - mean_absolute_error: 2.3365 - val_loss: 2.1017 - val_mean_absolute_error: 2.2940\n",
      "Epoch 10/100\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.1580 - mean_absolute_error: 2.3335 - val_loss: 2.1011 - val_mean_absolute_error: 2.2781\n",
      "Epoch 11/100\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 2.1469 - mean_absolute_error: 2.3249 - val_loss: 2.0861 - val_mean_absolute_error: 2.2648\n",
      "Epoch 11: early stopping\n",
      "Epoch 1/100\n",
      "384/384 [==============================] - 6s 11ms/step - loss: 2.0118 - mean_absolute_error: 2.1524 - val_loss: 1.8565 - val_mean_absolute_error: 1.9965\n",
      "Epoch 2/100\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.9415 - mean_absolute_error: 2.1133 - val_loss: 1.8358 - val_mean_absolute_error: 2.0058\n",
      "Epoch 3/100\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.9099 - mean_absolute_error: 2.0988 - val_loss: 1.8259 - val_mean_absolute_error: 2.0193\n",
      "Epoch 4/100\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.8935 - mean_absolute_error: 2.0889 - val_loss: 1.8257 - val_mean_absolute_error: 2.0386\n",
      "Epoch 5/100\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.8800 - mean_absolute_error: 2.0831 - val_loss: 1.8348 - val_mean_absolute_error: 2.0429\n",
      "Epoch 6/100\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.8682 - mean_absolute_error: 2.0815 - val_loss: 1.8283 - val_mean_absolute_error: 2.0575\n",
      "Epoch 7/100\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.8636 - mean_absolute_error: 2.0703 - val_loss: 1.8264 - val_mean_absolute_error: 2.0571\n",
      "Epoch 8/100\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.8637 - mean_absolute_error: 2.0771 - val_loss: 1.8417 - val_mean_absolute_error: 2.0694\n",
      "Epoch 9/100\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.8581 - mean_absolute_error: 2.0709 - val_loss: 1.8254 - val_mean_absolute_error: 2.0564\n",
      "Epoch 10/100\n",
      "384/384 [==============================] - 4s 10ms/step - loss: 1.8495 - mean_absolute_error: 2.0673 - val_loss: 1.8310 - val_mean_absolute_error: 2.0472\n",
      "Epoch 11/100\n",
      "384/384 [==============================] - 3s 9ms/step - loss: 1.8421 - mean_absolute_error: 2.0641 - val_loss: 1.8398 - val_mean_absolute_error: 2.0760\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Callbacks\n",
    "#model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "early_stopping = EarlyStopping(monitor='val_mean_absolute_error', patience=10, verbose=1, mode='min')\n",
    "#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001, mode='min')\n",
    "\n",
    "callbacks = [early_stopping]\n",
    "\n",
    "# \n",
    "from tensorflow.keras.models import clone_model\n",
    "\n",
    "model1 = clone_model(model)\n",
    "model1.compile(optimizer=Adam(0.001), loss=custom_loss, metrics=['mean_absolute_error'])\n",
    "\n",
    "model2 = clone_model(model)\n",
    "model2.compile(optimizer=Adam(0.001), loss=custom_loss, metrics=['mean_absolute_error'])\n",
    "\n",
    "# Treinamento do modelo (precisará ajustar os conjuntos de entrada e saída)\n",
    "history1 = model1.fit(\n",
    "    [X_train1_embed['team1'], X_train1_embed['team2'], X_train1_embed['championship'], X_train1_scaled], \n",
    "    y_train1, \n",
    "    epochs=100,  # ajuste o número de épocas conforme necessário\n",
    "    batch_size=128,  # ajuste o tamanho do lote conforme necessário\n",
    "    verbose=1, \n",
    "    validation_split=0.2,  # usando 20% dos dados para validação; ajuste conforme necessário\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "history2 = model2.fit(\n",
    "    [X_train2_embed['team1'], X_train2_embed['team2'], X_train2_embed['championship'], X_train2_scaled], \n",
    "    y_train2, \n",
    "    epochs=100,  # ajuste o número de épocas conforme necessário\n",
    "    batch_size=128,  # ajuste o tamanho do lote conforme necessário\n",
    "    verbose=1, \n",
    "    validation_split=0.2,  # usando 20% dos dados para validação; ajuste conforme necessário\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1901447772979736\n",
      "1.996545672416687\n"
     ]
    }
   ],
   "source": [
    "best_val_mae1 = min(history1.history['val_mean_absolute_error'])\n",
    "best_val_mae2 = min(history2.history['val_mean_absolute_error'])\n",
    "print(best_val_mae1)\n",
    "print(best_val_mae2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 93)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_matches_calculado_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>championship</th>\n",
       "      <th>team1_big_wins_last5</th>\n",
       "      <th>team1_big_losses_last5</th>\n",
       "      <th>team2_big_wins_last5</th>\n",
       "      <th>team2_big_losses_last5</th>\n",
       "      <th>team1_ah-2.5_wins_last5</th>\n",
       "      <th>team1_ah-2.5_losses_last5</th>\n",
       "      <th>team2_ah-2.5_wins_last5</th>\n",
       "      <th>...</th>\n",
       "      <th>team1_undefeated_streak</th>\n",
       "      <th>team1_winning_streak</th>\n",
       "      <th>team1_without_winning_streak</th>\n",
       "      <th>team2_losing_streak</th>\n",
       "      <th>team2_strength</th>\n",
       "      <th>team2_undefeated_streak</th>\n",
       "      <th>team2_winning_streak</th>\n",
       "      <th>team2_without_winning_streak</th>\n",
       "      <th>team1_suspended_players</th>\n",
       "      <th>team2_suspended_players</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>475</td>\n",
       "      <td>485</td>\n",
       "      <td>1</td>\n",
       "      <td>1.257310</td>\n",
       "      <td>-0.986648</td>\n",
       "      <td>-0.939662</td>\n",
       "      <td>-0.950273</td>\n",
       "      <td>-0.333442</td>\n",
       "      <td>0.333442</td>\n",
       "      <td>-0.405417</td>\n",
       "      <td>...</td>\n",
       "      <td>1.228464</td>\n",
       "      <td>-0.478941</td>\n",
       "      <td>-0.389724</td>\n",
       "      <td>-0.525751</td>\n",
       "      <td>-1.372864</td>\n",
       "      <td>1.143038</td>\n",
       "      <td>-0.569612</td>\n",
       "      <td>-0.314683</td>\n",
       "      <td>-0.334677</td>\n",
       "      <td>-0.305174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>482</td>\n",
       "      <td>492</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.907378</td>\n",
       "      <td>0.123596</td>\n",
       "      <td>-0.939662</td>\n",
       "      <td>0.184672</td>\n",
       "      <td>0.596325</td>\n",
       "      <td>-0.596325</td>\n",
       "      <td>-0.405417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006032</td>\n",
       "      <td>0.327638</td>\n",
       "      <td>-0.759254</td>\n",
       "      <td>1.364236</td>\n",
       "      <td>-1.075121</td>\n",
       "      <td>-0.661135</td>\n",
       "      <td>-0.569612</td>\n",
       "      <td>2.313513</td>\n",
       "      <td>-0.334677</td>\n",
       "      <td>-0.305174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>486</td>\n",
       "      <td>477</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.907378</td>\n",
       "      <td>-0.986648</td>\n",
       "      <td>-0.939662</td>\n",
       "      <td>-0.950273</td>\n",
       "      <td>-1.263209</td>\n",
       "      <td>1.263209</td>\n",
       "      <td>1.415019</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.605184</td>\n",
       "      <td>-0.478941</td>\n",
       "      <td>-0.389724</td>\n",
       "      <td>-0.525751</td>\n",
       "      <td>-0.157732</td>\n",
       "      <td>-0.360440</td>\n",
       "      <td>-0.569612</td>\n",
       "      <td>1.562600</td>\n",
       "      <td>2.587813</td>\n",
       "      <td>-0.305174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>498</td>\n",
       "      <td>478</td>\n",
       "      <td>1</td>\n",
       "      <td>0.174966</td>\n",
       "      <td>0.123596</td>\n",
       "      <td>0.117516</td>\n",
       "      <td>1.319616</td>\n",
       "      <td>1.526092</td>\n",
       "      <td>-1.526092</td>\n",
       "      <td>0.504801</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.605184</td>\n",
       "      <td>-0.478941</td>\n",
       "      <td>-0.020195</td>\n",
       "      <td>1.364236</td>\n",
       "      <td>-0.252980</td>\n",
       "      <td>-0.661135</td>\n",
       "      <td>-0.569612</td>\n",
       "      <td>0.060774</td>\n",
       "      <td>-0.334677</td>\n",
       "      <td>-0.305174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>495</td>\n",
       "      <td>488</td>\n",
       "      <td>18</td>\n",
       "      <td>0.174966</td>\n",
       "      <td>0.123596</td>\n",
       "      <td>0.117516</td>\n",
       "      <td>-0.950273</td>\n",
       "      <td>-0.333442</td>\n",
       "      <td>0.333442</td>\n",
       "      <td>1.415019</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.605184</td>\n",
       "      <td>-0.478941</td>\n",
       "      <td>-0.389724</td>\n",
       "      <td>-0.525751</td>\n",
       "      <td>-0.337596</td>\n",
       "      <td>-0.059744</td>\n",
       "      <td>-0.569612</td>\n",
       "      <td>-0.314683</td>\n",
       "      <td>-0.334677</td>\n",
       "      <td>-0.305174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     team1  team2  championship  team1_big_wins_last5  team1_big_losses_last5  \\\n",
       "190    475    485             1              1.257310               -0.986648   \n",
       "189    482    492             1             -0.907378                0.123596   \n",
       "197    486    477             1             -0.907378               -0.986648   \n",
       "192    498    478             1              0.174966                0.123596   \n",
       "524    495    488            18              0.174966                0.123596   \n",
       "\n",
       "     team2_big_wins_last5  team2_big_losses_last5  team1_ah-2.5_wins_last5  \\\n",
       "190             -0.939662               -0.950273                -0.333442   \n",
       "189             -0.939662                0.184672                 0.596325   \n",
       "197             -0.939662               -0.950273                -1.263209   \n",
       "192              0.117516                1.319616                 1.526092   \n",
       "524              0.117516               -0.950273                -0.333442   \n",
       "\n",
       "     team1_ah-2.5_losses_last5  team2_ah-2.5_wins_last5  ...  \\\n",
       "190                   0.333442                -0.405417  ...   \n",
       "189                  -0.596325                -0.405417  ...   \n",
       "197                   1.263209                 1.415019  ...   \n",
       "192                  -1.526092                 0.504801  ...   \n",
       "524                   0.333442                 1.415019  ...   \n",
       "\n",
       "     team1_undefeated_streak  team1_winning_streak  \\\n",
       "190                 1.228464             -0.478941   \n",
       "189                 0.006032              0.327638   \n",
       "197                -0.605184             -0.478941   \n",
       "192                -0.605184             -0.478941   \n",
       "524                -0.605184             -0.478941   \n",
       "\n",
       "     team1_without_winning_streak  team2_losing_streak  team2_strength  \\\n",
       "190                     -0.389724            -0.525751       -1.372864   \n",
       "189                     -0.759254             1.364236       -1.075121   \n",
       "197                     -0.389724            -0.525751       -0.157732   \n",
       "192                     -0.020195             1.364236       -0.252980   \n",
       "524                     -0.389724            -0.525751       -0.337596   \n",
       "\n",
       "     team2_undefeated_streak  team2_winning_streak  \\\n",
       "190                 1.143038             -0.569612   \n",
       "189                -0.661135             -0.569612   \n",
       "197                -0.360440             -0.569612   \n",
       "192                -0.661135             -0.569612   \n",
       "524                -0.059744             -0.569612   \n",
       "\n",
       "     team2_without_winning_streak  team1_suspended_players  \\\n",
       "190                     -0.314683                -0.334677   \n",
       "189                      2.313513                -0.334677   \n",
       "197                      1.562600                 2.587813   \n",
       "192                      0.060774                -0.334677   \n",
       "524                     -0.314683                -0.334677   \n",
       "\n",
       "     team2_suspended_players  \n",
       "190                -0.305174  \n",
       "189                -0.305174  \n",
       "197                -0.305174  \n",
       "192                -0.305174  \n",
       "524                -0.305174  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_matches_calculado_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 120ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step\n",
      "Prediction for corinthians: 4.193365097045898 corners\n",
      "Prediction for goiás: 3.533968448638916 corners\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Prediction for flamengo: 7.220284938812256 corners\n",
      "Prediction for internacional: 2.8095383644104004 corners\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Prediction for grêmio: 4.431801795959473 corners\n",
      "Prediction for cruzeiro: 5.8556952476501465 corners\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Prediction for red bull bragantino: 7.220280647277832 corners\n",
      "Prediction for cuiabá: 2.871609687805176 corners\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Prediction for mjallby: 3.866453170776367 corners\n",
      "Prediction for hammarby if: 5.855721950531006 corners\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Prediction for atlético mineiro: 7.220322608947754 corners\n",
      "Prediction for santos: 2.8193790912628174 corners\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Prediction for ifk gotemburgo: 4.04388952255249 corners\n",
      "Prediction for bk hacken: 5.549619197845459 corners\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Prediction for djurgardens if: 7.219966411590576 corners\n",
      "Prediction for degerfors if: 2.837491512298584 corners\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Prediction for fortaleza: 6.853286266326904 corners\n",
      "Prediction for coritiba: 2.8321261405944824 corners\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Prediction for ifk varnamo: 6.734647750854492 corners\n",
      "Prediction for halmstad: 3.3196024894714355 corners\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Prediction for athletico-pr: 4.21071720123291 corners\n",
      "Prediction for fluminense: 3.4663877487182617 corners\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Prediction for palmeiras: 7.209600448608398 corners\n",
      "Prediction for vasco da gama: 2.804981231689453 corners\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Prediction for américa-mg: 4.0578083992004395 corners\n",
      "Prediction for são paulo: 3.642134666442871 corners\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Prediction for botafogo: 7.220271587371826 corners\n",
      "Prediction for bahia: 2.9113292694091797 corners\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Prediction for brommapojkarna: 5.8579912185668945 corners\n",
      "Prediction for kalmar: 3.479783535003662 corners\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Prediction for ik sirius: 3.8248276710510254 corners\n",
      "Prediction for malmo: 5.855720043182373 corners\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Prediction for elfsborg: 7.220033168792725 corners\n",
      "Prediction for norrkoping: 2.9217727184295654 corners\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Prediction for aik: 7.218727111816406 corners\n",
      "Prediction for varbergs bois fc: 3.1759896278381348 corners\n",
      "Corner Predictions: {'corinthians': 4.193365, 'goiás': 3.5339684, 'flamengo': 7.220285, 'internacional': 2.8095384, 'grêmio': 4.431802, 'cruzeiro': 5.8556952, 'red bull bragantino': 7.2202806, 'cuiabá': 2.8716097, 'mjallby': 3.8664532, 'hammarby if': 5.855722, 'atlético mineiro': 7.2203226, 'santos': 2.819379, 'ifk gotemburgo': 4.0438895, 'bk hacken': 5.549619, 'djurgardens if': 7.2199664, 'degerfors if': 2.8374915, 'fortaleza': 6.8532863, 'coritiba': 2.8321261, 'ifk varnamo': 6.7346478, 'halmstad': 3.3196025, 'athletico-pr': 4.210717, 'fluminense': 3.4663877, 'palmeiras': 7.2096004, 'vasco da gama': 2.8049812, 'américa-mg': 4.0578084, 'são paulo': 3.6421347, 'botafogo': 7.2202716, 'bahia': 2.9113293, 'brommapojkarna': 5.857991, 'kalmar': 3.4797835, 'ik sirius': 3.8248277, 'malmo': 5.85572, 'elfsborg': 7.220033, 'norrkoping': 2.9217727, 'aik': 7.218727, 'varbergs bois fc': 3.1759896}\n"
     ]
    }
   ],
   "source": [
    "#STEP 1\n",
    "\n",
    "# Inicializando um dicionário vazio para armazenar as previsões\n",
    "corner_predictions = {}\n",
    "\n",
    "# Iterar sobre cada linha em 'future_matches' e 'future_matches_calculado_scaled'\n",
    "for (index1, row1), (index2, row2) in zip(future_matches.iterrows(), future_matches_calculado_scaled.iterrows()):\n",
    "    # Prepare os dados de entrada para a previsão\n",
    "    team1_input_data = np.array([[row2['team1']]], dtype=np.float32)\n",
    "    team2_input_data = np.array([[row2['team2']]], dtype=np.float32)\n",
    "    champ_input_data = np.array([[row2['championship']]], dtype=np.float32)\n",
    "    \n",
    "    # Certifique-se de que 'other_features_data' contém todas as outras características na mesma ordem que foram usadas para treinar o modelo\n",
    "    other_features_data = np.array([row2.drop(['team1', 'team2', 'championship']).astype(np.float32)])\n",
    "    \n",
    "    # Faça a previsão usando 'model1' e 'model2'\n",
    "    pred1 = model1.predict([team1_input_data, team2_input_data, champ_input_data, other_features_data])\n",
    "    pred2 = model2.predict([team1_input_data, team2_input_data, champ_input_data, other_features_data])\n",
    "    \n",
    "    # Armazenar as previsões no dicionário\n",
    "    corner_predictions[row1['team1']] = pred1[0][0]\n",
    "    corner_predictions[row1['team2']] = pred2[0][0]\n",
    "    \n",
    "    # Imprimir as previsões\n",
    "    print(f\"Prediction for {row1['team1']}: {pred1[0][0]} corners\")\n",
    "    print(f\"Prediction for {row1['team2']}: {pred2[0][0]} corners\")\n",
    "\n",
    "# Exibindo o dicionário de previsões\n",
    "print(\"Corner Predictions:\", corner_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team1_name</th>\n",
       "      <th>Team1_prediction</th>\n",
       "      <th>Team2_name</th>\n",
       "      <th>Team2_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>corinthians</td>\n",
       "      <td>4.193365</td>\n",
       "      <td>goiás</td>\n",
       "      <td>3.533968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flamengo</td>\n",
       "      <td>7.220285</td>\n",
       "      <td>internacional</td>\n",
       "      <td>2.809538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grêmio</td>\n",
       "      <td>4.431802</td>\n",
       "      <td>cruzeiro</td>\n",
       "      <td>5.855695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>red bull bragantino</td>\n",
       "      <td>7.220281</td>\n",
       "      <td>cuiabá</td>\n",
       "      <td>2.871610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mjallby</td>\n",
       "      <td>3.866453</td>\n",
       "      <td>hammarby if</td>\n",
       "      <td>5.855722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>atlético mineiro</td>\n",
       "      <td>7.220323</td>\n",
       "      <td>santos</td>\n",
       "      <td>2.819379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ifk gotemburgo</td>\n",
       "      <td>4.043890</td>\n",
       "      <td>bk hacken</td>\n",
       "      <td>5.549619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>djurgardens if</td>\n",
       "      <td>7.219966</td>\n",
       "      <td>degerfors if</td>\n",
       "      <td>2.837492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fortaleza</td>\n",
       "      <td>6.853286</td>\n",
       "      <td>coritiba</td>\n",
       "      <td>2.832126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ifk varnamo</td>\n",
       "      <td>6.734648</td>\n",
       "      <td>halmstad</td>\n",
       "      <td>3.319602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>athletico-pr</td>\n",
       "      <td>4.210717</td>\n",
       "      <td>fluminense</td>\n",
       "      <td>3.466388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>palmeiras</td>\n",
       "      <td>7.209600</td>\n",
       "      <td>vasco da gama</td>\n",
       "      <td>2.804981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>américa-mg</td>\n",
       "      <td>4.057808</td>\n",
       "      <td>são paulo</td>\n",
       "      <td>3.642135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>botafogo</td>\n",
       "      <td>7.220272</td>\n",
       "      <td>bahia</td>\n",
       "      <td>2.911329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>brommapojkarna</td>\n",
       "      <td>5.857991</td>\n",
       "      <td>kalmar</td>\n",
       "      <td>3.479784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ik sirius</td>\n",
       "      <td>3.824828</td>\n",
       "      <td>malmo</td>\n",
       "      <td>5.855720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>elfsborg</td>\n",
       "      <td>7.220033</td>\n",
       "      <td>norrkoping</td>\n",
       "      <td>2.921773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aik</td>\n",
       "      <td>7.218727</td>\n",
       "      <td>varbergs bois fc</td>\n",
       "      <td>3.175990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Team1_name  Team1_prediction        Team2_name  Team2_prediction\n",
       "0           corinthians          4.193365             goiás          3.533968\n",
       "1              flamengo          7.220285     internacional          2.809538\n",
       "2                grêmio          4.431802          cruzeiro          5.855695\n",
       "3   red bull bragantino          7.220281            cuiabá          2.871610\n",
       "4               mjallby          3.866453       hammarby if          5.855722\n",
       "5      atlético mineiro          7.220323            santos          2.819379\n",
       "6        ifk gotemburgo          4.043890         bk hacken          5.549619\n",
       "7        djurgardens if          7.219966      degerfors if          2.837492\n",
       "8             fortaleza          6.853286          coritiba          2.832126\n",
       "9           ifk varnamo          6.734648          halmstad          3.319602\n",
       "10         athletico-pr          4.210717        fluminense          3.466388\n",
       "11            palmeiras          7.209600     vasco da gama          2.804981\n",
       "12           américa-mg          4.057808         são paulo          3.642135\n",
       "13             botafogo          7.220272             bahia          2.911329\n",
       "14       brommapojkarna          5.857991            kalmar          3.479784\n",
       "15            ik sirius          3.824828             malmo          5.855720\n",
       "16             elfsborg          7.220033        norrkoping          2.921773\n",
       "17                  aik          7.218727  varbergs bois fc          3.175990"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformar o dicionário em uma lista de listas, quebrando a cada 2 itens\n",
    "items = list(corner_predictions.items())\n",
    "rows = [items[i:i + 2] for i in range(0, len(items), 2)]\n",
    "\n",
    "# Criar um DataFrame a partir da lista de listas\n",
    "df = pd.DataFrame(rows, columns=['Team1', 'Team2'])\n",
    "\n",
    "# Separar as tuplas em duas colunas separadas para os nomes das equipes e as previsões\n",
    "df[['Team1_name', 'Team1_prediction']] = pd.DataFrame(df['Team1'].tolist(), index=df.index)\n",
    "df[['Team2_name', 'Team2_prediction']] = pd.DataFrame(df['Team2'].tolist(), index=df.index)\n",
    "\n",
    "# Descartar as colunas originais e reordenar\n",
    "df = df[['Team1_name', 'Team1_prediction', 'Team2_name', 'Team2_prediction']]\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 4)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 2\n",
    "\n",
    "from scipy.stats import poisson\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def poisson_probabilities(lam, max_corners=15):\n",
    "    probs = [poisson.pmf(k, lam) for k in range(max_corners + 1)]\n",
    "    probs.append(1 - sum(probs))\n",
    "    return probs\n",
    "\n",
    "def calculate_probabilities(team1_corners_prediction, team2_corners_prediction):\n",
    "    team1_corners_probabilities = poisson_probabilities(team1_corners_prediction)\n",
    "    team2_corners_probabilities = poisson_probabilities(team2_corners_prediction)\n",
    "\n",
    "    joint_prob_matrix = np.outer(team1_corners_probabilities, team2_corners_probabilities)\n",
    "\n",
    "    team1_win_prob = np.sum(np.tril(joint_prob_matrix, -1))\n",
    "    draw_prob = np.sum(np.diag(joint_prob_matrix))\n",
    "    team2_win_prob = np.sum(np.triu(joint_prob_matrix, 1))\n",
    "\n",
    "    team1_minus25_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if i-j>=3])\n",
    "    team1_plus25_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if i-j>=-2])\n",
    "    team2_minus25_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if j-i>=3])\n",
    "    team2_plus25_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if j-i>=-2])\n",
    "\n",
    "    team1_minus15_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if i-j>=2])\n",
    "    team1_plus15_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if i-j>=-1])\n",
    "    team2_minus15_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if j-i>=2])\n",
    "    team2_plus15_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if j-i>=-1])\n",
    "\n",
    "    team1_over45_prob = 1 - sum(team1_corners_probabilities[:5])\n",
    "    team1_under45_prob = sum(team1_corners_probabilities[:5])\n",
    "    team2_over45_prob = 1 - sum(team2_corners_probabilities[:5])\n",
    "    team2_under45_prob = sum(team2_corners_probabilities[:5])\n",
    "\n",
    "    team1_over55_prob = 1 - sum(team1_corners_probabilities[:6])\n",
    "    team1_under55_prob = sum(team1_corners_probabilities[:6])\n",
    "    team2_over55_prob = 1 - sum(team2_corners_probabilities[:6])\n",
    "    team2_under55_prob = sum(team2_corners_probabilities[:6])\n",
    "\n",
    "    team1_over65_prob = 1 - sum(team1_corners_probabilities[:7])\n",
    "    team1_under65_prob = sum(team1_corners_probabilities[:7])\n",
    "    team2_over65_prob = 1 - sum(team2_corners_probabilities[:7])\n",
    "    team2_under65_prob = sum(team2_corners_probabilities[:7])\n",
    "    \n",
    "    return (team1_win_prob, draw_prob, team2_win_prob,\n",
    "        team1_minus15_prob, team1_plus15_prob, team2_minus15_prob, team2_plus15_prob,\n",
    "        team1_minus25_prob, team1_plus25_prob, team2_minus25_prob, team2_plus25_prob,\n",
    "        team1_over45_prob, team1_under45_prob, team2_over45_prob, team2_under45_prob,\n",
    "        team1_over55_prob, team1_under55_prob, team2_over55_prob, team2_under55_prob,\n",
    "        team1_over65_prob, team1_under65_prob, team2_over65_prob, team2_under65_prob)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 27)\n"
     ]
    }
   ],
   "source": [
    "# Inicializando o DataFrame para armazenar as odds\n",
    "odds_df = pd.DataFrame(columns=['Team 1', 'Team 2', 'Team 1 Win Odd', 'Draw Odd', 'Team 2 Win Odd',\n",
    "                                'Team 1 -1.5 Odd', 'Team 1 +1.5 Odd', 'Team 2 -1.5 Odd', 'Team 2 +1.5 Odd',\n",
    "                                'Team 1 -2.5 Odd', 'Team 1 +2.5 Odd', 'Team 2 -2.5 Odd', 'Team 2 +2.5 Odd',\n",
    "                                'Team 1 Over 4.5', 'Team 1 Under 4.5', 'Team 2 Over 4.5', 'Team 2 Under 4.5',\n",
    "                                'Team 1 Over 5.5', 'Team 1 Under 5.5', 'Team 2 Over 5.5', 'Team 2 Under 5.5',\n",
    "                                'Team 1 Over 6.5', 'Team 1 Under 6.5', 'Team 2 Over 6.5', 'Team 2 Under 6.5'])\n",
    "\n",
    "# Iterar sobre cada linha no DataFrame 'df'\n",
    "for index, row in df.iterrows():\n",
    "    team1_name = row['Team1_name']\n",
    "    team1_prediction = row['Team1_prediction']\n",
    "    team2_name = row['Team2_name']\n",
    "    team2_prediction = row['Team2_prediction']\n",
    "    \n",
    "    # Calculando as probabilidades usando a função do STEP 2\n",
    "    probabilities = calculate_probabilities(team1_prediction, team2_prediction)\n",
    "    \n",
    "    # Calculando as odds\n",
    "    odds = [1 / prob for prob in probabilities]\n",
    "    \n",
    "    # Adicionando as odds ao DataFrame\n",
    "    odds_df.loc[len(odds_df)] = [team1_name, team2_name] + odds\n",
    "\n",
    "    # Inicializando as novas colunas\n",
    "odds_df['date'] = None\n",
    "odds_df['championship'] = None\n",
    "\n",
    "# Preenchendo as novas colunas\n",
    "for index, row in odds_df.iterrows():\n",
    "    team1 = row['Team 1']\n",
    "    team2 = row['Team 2']\n",
    "    \n",
    "    # Encontrando a linha correspondente em 'future_matches'\n",
    "    match_row = future_matches[(future_matches['team1'] == team1) & (future_matches['team2'] == team2)]\n",
    "    \n",
    "    if not match_row.empty:\n",
    "        # Se encontrarmos uma linha correspondente, atualizamos 'odds_df'\n",
    "        odds_df.at[index, 'date'] = match_row.iloc[0]['date']\n",
    "        odds_df.at[index, 'championship'] = match_row.iloc[0]['championship']\n",
    "\n",
    "# Converte a coluna 'date' para o tipo de data do pandas\n",
    "odds_df['date'] = pd.to_datetime(odds_df['date'])\n",
    "\n",
    "# Formata a coluna 'date' para o formato de data brasileiro (dd/mm/yyyy)\n",
    "odds_df['date'] = odds_df['date'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "odds_df = odds_df.sort_values(['championship', 'date'])\n",
    "\n",
    "# Lista das colunas atuais\n",
    "cols = odds_df.columns.tolist()\n",
    "\n",
    "# Removendo 'date' e 'championship' da lista\n",
    "cols.remove('date')\n",
    "cols.remove('championship')\n",
    "\n",
    "# Reordenando as colunas\n",
    "new_cols = ['date', 'championship'] + cols\n",
    "\n",
    "# Atualizando o DataFrame com a nova ordem de colunas\n",
    "odds_df = odds_df[new_cols]\n",
    "\n",
    "odds_df.to_excel(\"output_corners_NNNN_AH.xlsx\", index=False)\n",
    "\n",
    "# Exibindo o DataFrame de odds\n",
    "print(odds_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
