{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(66840, 141)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_pickle(r'C:\\Users\\mathe\\OneDrive\\Área de Trabalho\\SoccerIA\\MathIA_v7\\dataset_141cols_europeu.pkl')\n",
    "\n",
    "nan_counts = dataset.isna().sum()\n",
    "nan_tot = nan_counts.sum()\n",
    "print(nan_tot)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando os dataframes de 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe2023_BRA_A.xlsx\n",
      "(370, 19)\n",
      "team1                      0\n",
      "team2                      0\n",
      "team1_goals              181\n",
      "team2_goals              181\n",
      "season                     0\n",
      "championship               0\n",
      "team1_shots_on_target    181\n",
      "team1_shots_out          181\n",
      "team2_shots_on_target    181\n",
      "team2_shots_out          181\n",
      "team1_red_cards          181\n",
      "team2_red_cards          181\n",
      "team1_fouls              181\n",
      "team2_fouls              181\n",
      "team1_corners            181\n",
      "team2_corners            181\n",
      "team1_total_shots        181\n",
      "team2_total_shots        181\n",
      "date                       0\n",
      "dtype: int64\n",
      "dataframe2023_SUE_A.xlsx\n",
      "(230, 19)\n",
      "team1                     0\n",
      "team2                     0\n",
      "team1_goals              80\n",
      "team2_goals              80\n",
      "season                    0\n",
      "championship              0\n",
      "team1_shots_on_target    80\n",
      "team1_shots_out          80\n",
      "team2_shots_on_target    80\n",
      "team2_shots_out          80\n",
      "team1_red_cards          80\n",
      "team2_red_cards          80\n",
      "team1_fouls              80\n",
      "team2_fouls              80\n",
      "team1_corners            80\n",
      "team2_corners            80\n",
      "team1_total_shots        80\n",
      "team2_total_shots        80\n",
      "date                      0\n",
      "dtype: int64\n",
      "Index(['team1', 'team2', 'team1_goals', 'team2_goals', 'season',\n",
      "       'championship', 'team1_shots_on_target', 'team1_shots_out',\n",
      "       'team2_shots_on_target', 'team2_shots_out', 'team1_red_cards',\n",
      "       'team2_red_cards', 'team1_fouls', 'team2_fouls', 'team1_corners',\n",
      "       'team2_corners', 'team1_total_shots', 'team2_total_shots', 'date',\n",
      "       'is_future_match'],\n",
      "      dtype='object')\n",
      "(600, 20)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Caminho para a pasta que contém os arquivos .xlsx de 2023\n",
    "path = r'C:\\Users\\mathe\\OneDrive\\Área de Trabalho\\SoccerIA\\webScrappingOddspedia'\n",
    "\n",
    "# Dicionário para armazenar os dataframes\n",
    "dataframes = {}\n",
    "dfss = []\n",
    "# Lista todos os arquivos na pasta\n",
    "files = os.listdir(path)\n",
    "\n",
    "# Filtra a lista de arquivos para incluir apenas os arquivos .xlsx\n",
    "xlsx_files = [f for f in files if f.endswith('.xlsx')]\n",
    "\n",
    "# Carrega cada arquivo .xlsx em um dataframe e armazena no dicionário\n",
    "for file in xlsx_files:\n",
    "    full_path = os.path.join(path, file)  # junta o caminho do diretório com o nome do arquivo\n",
    "    dataframes[file] = pd.read_excel(full_path)  # lê o arquivo .xlsx do caminho completo\n",
    "\n",
    "    if \"Unnamed: 0\" in dataframes[file].columns:\n",
    "        dataframes[file].drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "\n",
    "    if \"match_report_url\" in dataframes[file].columns:\n",
    "        dataframes[file].drop(\"match_report_url\", axis=1, inplace=True)    \n",
    "\n",
    "    if \"team1_yellow_cards\" in dataframes[file].columns:\n",
    "        dataframes[file].drop(\"team1_yellow_cards\", axis=1, inplace=True)\n",
    "\n",
    "    if \"team2_yellow_cards\" in dataframes[file].columns:\n",
    "        dataframes[file].drop(\"team2_yellow_cards\", axis=1, inplace=True)  \n",
    "    dfss.append(dataframes[file])\n",
    "\n",
    "    print(file)\n",
    "    print(dataframes[file].shape)\n",
    "    nan_counts = dataframes[file].isna().sum()\n",
    "    print(nan_counts)\n",
    "\n",
    "\n",
    "# Combine all the DataFrames into a single DataFrame\n",
    "combined_df_2023 = pd.concat(dfss, ignore_index=True)\n",
    "\n",
    "\n",
    "combined_df_2023['team1'] = combined_df_2023['team1'].str.lower()\n",
    "combined_df_2023['team2'] = combined_df_2023['team2'].str.lower()\n",
    "combined_df_2023.replace('', np.nan, inplace=True)\n",
    "# Add a column to mark future matches\n",
    "combined_df_2023['is_future_match'] = combined_df_2023['team1_goals'].isna() | combined_df_2023['team2_goals'].isna()\n",
    "combined_df_2023['season'] = '2023'\n",
    "# Replace empty string with NaN\n",
    "combined_df_2023[\"team1_red_cards\"].replace('', np.nan, inplace=True)\n",
    "combined_df_2023[\"team2_red_cards\"].replace('', np.nan, inplace=True)\n",
    "\n",
    "# Replace NaN with 0\n",
    "combined_df_2023[\"team1_red_cards\"].fillna(0, inplace=True)\n",
    "combined_df_2023[\"team2_red_cards\"].fillna(0, inplace=True)\n",
    "\n",
    "combined_df_2023['date'] = pd.to_datetime(combined_df_2023['date'], format='%Y-%m-%d', errors='coerce')\n",
    "combined_df_2023.sort_values('date', inplace=True)\n",
    "\n",
    "print(combined_df_2023.columns)\n",
    "print(combined_df_2023.shape) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 120)"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "combined_df_2023.sort_values('date', inplace=True)\n",
    "\n",
    "\n",
    "combined_df_2023['team1_goals'] = pd.to_numeric(combined_df_2023['team1_goals'], errors='coerce')\n",
    "combined_df_2023['team2_goals'] = pd.to_numeric(combined_df_2023['team2_goals'], errors='coerce')\n",
    "\n",
    "# calculate goal differences\n",
    "combined_df_2023['goal_diff_team1'] = combined_df_2023['team1_goals'] - combined_df_2023['team2_goals']\n",
    "combined_df_2023['goal_diff_team2'] = combined_df_2023['team2_goals'] - combined_df_2023['team1_goals']\n",
    "\n",
    "# calculate corners differences\n",
    "combined_df_2023['corners_diff_team1'] = combined_df_2023['team1_corners'] - combined_df_2023['team2_corners']############# NEW\n",
    "combined_df_2023['corners_diff_team2'] = combined_df_2023['team2_corners'] - combined_df_2023['team1_corners']############# NEW\n",
    "\n",
    "# calculate big wins and losses\n",
    "combined_df_2023['team1_big_win'] = np.where(combined_df_2023['goal_diff_team1'] >= 2, 1, 0)\n",
    "combined_df_2023['team1_big_loss'] = np.where(combined_df_2023['goal_diff_team1'] <= -2, 1, 0)\n",
    "combined_df_2023['team2_big_win'] = np.where(combined_df_2023['goal_diff_team2'] >= 2, 1, 0)\n",
    "combined_df_2023['team2_big_loss'] = np.where(combined_df_2023['goal_diff_team2'] <= -2, 1, 0)\n",
    "\n",
    "# calculate AH-2.5 win and losses\n",
    "combined_df_2023['team1_ah-2.5_win'] = np.where(combined_df_2023['corners_diff_team1'] >= 3, 1, 0)############# NEW\n",
    "combined_df_2023['team1_ah-2.5_loss'] = np.where(combined_df_2023['corners_diff_team1'] <= 2, 1, 0)############# NEW\n",
    "combined_df_2023['team2_ah-2.5_win'] = np.where(combined_df_2023['corners_diff_team2'] >= 3, 1, 0)############# NEW\n",
    "combined_df_2023['team2_ah-2.5_loss'] = np.where(combined_df_2023['corners_diff_team2'] <= 2, 1, 0)############# NEW\n",
    "\n",
    "\n",
    "# calculate AH+2.5 win and losses\n",
    "combined_df_2023['team1_ah+2.5_win'] = np.where(combined_df_2023['corners_diff_team1'] >= -2, 1, 0)############# NEW\n",
    "combined_df_2023['team1_ah+2.5_loss'] = np.where(combined_df_2023['corners_diff_team1'] <= -3, 1, 0)############# NEW\n",
    "combined_df_2023['team2_ah+2.5_win'] = np.where(combined_df_2023['corners_diff_team2'] >= -2, 1, 0)############# NEW\n",
    "combined_df_2023['team2_ah+2.5_loss'] = np.where(combined_df_2023['corners_diff_team2'] <= -3, 1, 0)############# NEW\n",
    "\n",
    "\n",
    "# calculate over4.5 win and losses\n",
    "combined_df_2023['team1_over4.5'] = np.where(combined_df_2023['team1_corners'] >= 5, 1, 0)############# NEW\n",
    "combined_df_2023['team1_under4.5'] = np.where(combined_df_2023['team1_corners'] <= 4, 1, 0)############# NEW\n",
    "combined_df_2023['team2_over4.5'] = np.where(combined_df_2023['team2_corners'] >= 5, 1, 0)############# NEW\n",
    "combined_df_2023['team2_under4.5'] = np.where(combined_df_2023['team2_corners'] <= 4, 1, 0)############# NEW\n",
    "\n",
    "# calculate over3.5 win and losses\n",
    "combined_df_2023['team1_over3.5'] = np.where(combined_df_2023['team1_corners'] >= 4, 1, 0)############# NEW\n",
    "combined_df_2023['team1_under3.5'] = np.where(combined_df_2023['team1_corners'] <= 3, 1, 0)############# NEW\n",
    "combined_df_2023['team2_over3.5'] = np.where(combined_df_2023['team2_corners'] >= 4, 1, 0)############# NEW\n",
    "combined_df_2023['team2_under3.5'] = np.where(combined_df_2023['team2_corners'] <= 3, 1, 0)############# NEW\n",
    "\n",
    "# calculate over6.5 win and losses\n",
    "combined_df_2023['team1_over6.5'] = np.where(combined_df_2023['team1_corners'] >= 7, 1, 0)############# NEW\n",
    "combined_df_2023['team1_under6.5'] = np.where(combined_df_2023['team1_corners'] <= 6, 1, 0)############# NEW\n",
    "combined_df_2023['team2_over6.5'] = np.where(combined_df_2023['team2_corners'] >= 7, 1, 0)############# NEW\n",
    "combined_df_2023['team2_under6.5'] = np.where(combined_df_2023['team2_corners'] <= 6, 1, 0)############# NEW\n",
    "\n",
    "\n",
    "# Initialize these columns with 0\n",
    "combined_df_2023['team1_big_wins_last5'] = 0\n",
    "combined_df_2023['team1_big_losses_last5'] = 0\n",
    "combined_df_2023['team2_big_wins_last5'] = 0\n",
    "combined_df_2023['team2_big_losses_last5'] = 0\n",
    "\n",
    "combined_df_2023['team1_ah-2.5_wins_last5'] = 0############# NEW\n",
    "combined_df_2023['team1_ah-2.5_losses_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_ah-2.5_wins_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_ah-2.5_losses_last5'] = 0############# NEW\n",
    "\n",
    "combined_df_2023['team1_ah+2.5_wins_last5'] = 0############# NEW\n",
    "combined_df_2023['team1_ah+2.5_losses_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_ah+2.5_wins_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_ah+2.5_losses_last5'] = 0############# NEW\n",
    "\n",
    "combined_df_2023['team1_over3.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team1_under3.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_over3.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_under3.5_last5'] = 0############# NEW\n",
    "\n",
    "combined_df_2023['team1_over4.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team1_under4.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_over4.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_under4.5_last5'] = 0############# NEW\n",
    "\n",
    "combined_df_2023['team1_over6.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team1_under6.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_over6.5_last5'] = 0############# NEW\n",
    "combined_df_2023['team2_under6.5_last5'] = 0############# NEW\n",
    "\n",
    "\n",
    "new_cols = ['avg_scr_lasts3_1_home', 'avg_scr_lasts5_1_home', 'avg_scr_lasts3_1_away',\n",
    "            'avg_scr_lasts5_1_away', 'avg_conc_lasts3_1_home', 'avg_conc_lasts5_1_home',\n",
    "            'avg_conc_lasts3_1_away', 'avg_conc_lasts5_1_away', 'avg_scr_lasts3_2_home',\n",
    "            'avg_scr_lasts5_2_home', 'avg_scr_lasts3_2_away', 'avg_scr_lasts5_2_away',\n",
    "            'avg_conc_lasts3_2_home', 'avg_conc_lasts5_2_home', 'avg_conc_lasts3_2_away',\n",
    "            'avg_conc_lasts5_2_away','team1_big_wins_last5', 'team1_big_losses_last5', \n",
    "            'team2_big_wins_last5', 'team2_big_losses_last5',\n",
    "            #abaixo vai ser baseado em finalizações\n",
    "            'avg_total_shots_lasts5_1_home','avg_total_shots_lasts5_1_away','avg_total_shots_lasts5_2_home',\n",
    "            'avg_total_shots_lasts5_2_away', 'avg_otarget_shots_lasts5_1_home','avg_otarget_shots_lasts5_1_away',\n",
    "            'avg_otarget_shots_lasts5_2_home','avg_otarget_shots_lasts5_2_away','avg_out_shots_lasts5_1_home',\n",
    "            'avg_out_shots_lasts5_1_away','avg_out_shots_lasts5_2_home','avg_out_shots_lasts5_2_away',\n",
    "            'avg_conc_total_shots_lasts5_1_home','avg_conc_total_shots_lasts5_1_away',\n",
    "            'avg_conc_total_shots_lasts5_2_home','avg_conc_total_shots_lasts5_2_away',\n",
    "            #abaixo vai ser baseado em corners\n",
    "            'avg_corners_lasts5_1_home','avg_corners_lasts5_1_away', \n",
    "            'avg_corners_conc_lasts5_1_home','avg_corners_conc_lasts5_1_away',\n",
    "            'avg_corners_lasts5_2_home','avg_corners_lasts5_2_away', \n",
    "            'avg_corners_conc_lasts5_2_home', 'avg_corners_conc_lasts5_2_away',\n",
    "            #abaixo vai ser baseado em fouls\n",
    "            'avg_fouls_lasts5_1_home','avg_fouls_lasts5_1_away', \n",
    "            'avg_fouls_conc_lasts5_1_home', 'avg_fouls_conc_lasts5_1_away',\n",
    "            'avg_fouls_lasts5_2_home','avg_fouls_lasts5_2_away', \n",
    "            'avg_fouls_conc_lasts5_2_home', 'avg_fouls_conc_lasts5_2_away',\n",
    "            #novas colunas da v7\n",
    "            'team1_ah-2.5_wins_last5', 'team1_ah-2.5_losses_last5','team2_ah-2.5_wins_last5','team2_ah-2.5_losses_last5',\n",
    "            'team1_ah+2.5_wins_last5','team1_ah+2.5_losses_last5','team2_ah+2.5_wins_last5','team2_ah+2.5_losses_last5',\n",
    "            'team1_over3.5_last5','team1_under3.5_last5','team2_over3.5_last5','team2_under3.5_last5',\n",
    "            'team1_over4.5_last5','team1_under4.5_last5','team2_over4.5_last5','team2_under4.5_last5',\n",
    "            'team1_over6.5_last5','team1_under6.5_last5','team2_over6.5_last5','team2_under6.5_last5'\n",
    "            ]\n",
    "\n",
    "# Create a dictionary with keys as column names and values as np.nan\n",
    "new_cols_dict = {col: np.nan for col in new_cols}\n",
    "\n",
    "# Add new columns to the DataFrame\n",
    "combined_df_2023 = combined_df_2023.assign(**new_cols_dict)\n",
    "\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for i, row in combined_df_2023.iterrows():\n",
    "    # For each team, get their past home and away matches before the current date\n",
    "    team1_matches = combined_df_2023[((combined_df_2023['team1'] == row['team1']) | (combined_df_2023['team2'] == row['team1'])) & (combined_df_2023['date'] < row['date']) & (combined_df_2023['season'] == row['season'])].sort_values(by='date')\n",
    "    team2_matches = combined_df_2023[((combined_df_2023['team1'] == row['team2']) | (combined_df_2023['team2'] == row['team2'])) & (combined_df_2023['date'] < row['date']) & (combined_df_2023['season'] == row['season'])].sort_values(by='date')\n",
    "\n",
    "    # For each team, calculate stats for last 5 matches\n",
    "    if not team1_matches.empty:\n",
    "        team1_matches['big_win'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_big_win'], team1_matches['team2_big_win'])\n",
    "        team1_matches['big_loss'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_big_loss'], team1_matches['team2_big_loss'])\n",
    "        combined_df_2023.at[i, 'team1_big_wins_last5'] = team1_matches['big_win'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team1_big_losses_last5'] = team1_matches['big_loss'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para ah-2.5 para a equipe 1\n",
    "        team1_matches['ah-2.5_win'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_ah-2.5_win'], team1_matches['team2_ah-2.5_win'])\n",
    "        team1_matches['ah-2.5_loss'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_ah-2.5_loss'], team1_matches['team2_ah-2.5_loss'])\n",
    "        combined_df_2023.at[i, 'team1_ah-2.5_wins_last5'] = team1_matches['ah-2.5_win'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team1_ah-2.5_losses_last5'] = team1_matches['ah-2.5_loss'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para ah+2.5 para a equipe 1\n",
    "        team1_matches['ah+2.5_win'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_ah+2.5_win'], team1_matches['team2_ah+2.5_win'])\n",
    "        team1_matches['ah+2.5_loss'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_ah+2.5_loss'], team1_matches['team2_ah+2.5_loss'])\n",
    "        combined_df_2023.at[i, 'team1_ah+2.5_wins_last5'] = team1_matches['ah+2.5_win'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team1_ah+2.5_losses_last5'] = team1_matches['ah+2.5_loss'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para over3.5 para a equipe 1\n",
    "        team1_matches['over3.5'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_over3.5'], team1_matches['team2_over3.5'])\n",
    "        team1_matches['under3.5'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_under3.5'], team1_matches['team2_under3.5'])\n",
    "        combined_df_2023.at[i, 'team1_over3.5_last5'] = team1_matches['over3.5'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team1_under3.5_last5'] = team1_matches['under3.5'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para over4.5 para a equipe 1\n",
    "        team1_matches['over4.5'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_over4.5'], team1_matches['team2_over4.5'])\n",
    "        team1_matches['under4.5'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_under4.5'], team1_matches['team2_under4.5'])\n",
    "        combined_df_2023.at[i, 'team1_over4.5_last5'] = team1_matches['over4.5'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team1_under4.5_last5'] = team1_matches['under4.5'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para over6.5 para a equipe 1\n",
    "        team1_matches['over6.5'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_over6.5'], team1_matches['team2_over6.5'])\n",
    "        team1_matches['under6.5'] = np.where(team1_matches['team1'] == row['team1'], team1_matches['team1_under6.5'], team1_matches['team2_under6.5'])\n",
    "        combined_df_2023.at[i, 'team1_over6.5_last5'] = team1_matches['over6.5'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team1_under6.5_last5'] = team1_matches['under6.5'].rolling(5).sum().iloc[-1] if len(team1_matches) >= 2 else np.nan\n",
    "\n",
    "\n",
    "\n",
    "    if not team2_matches.empty:\n",
    "        team2_matches['big_win'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_big_win'], team2_matches['team2_big_win'])\n",
    "        team2_matches['big_loss'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_big_loss'], team2_matches['team2_big_loss'])\n",
    "        combined_df_2023.at[i, 'team2_big_wins_last5'] = team2_matches['big_win'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team2_big_losses_last5'] = team2_matches['big_loss'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para ah-2.5 para a equipe 2\n",
    "        team2_matches['ah-2.5_win'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_ah-2.5_win'], team2_matches['team2_ah-2.5_win'])\n",
    "        team2_matches['ah-2.5_loss'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_ah-2.5_loss'], team2_matches['team2_ah-2.5_loss'])\n",
    "        combined_df_2023.at[i, 'team2_ah-2.5_wins_last5'] = team2_matches['ah-2.5_win'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team2_ah-2.5_losses_last5'] = team2_matches['ah-2.5_loss'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para ah+2.5 para a equipe 2\n",
    "        team2_matches['ah+2.5_win'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_ah+2.5_win'], team2_matches['team2_ah+2.5_win'])\n",
    "        team2_matches['ah+2.5_loss'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_ah+2.5_loss'], team2_matches['team2_ah+2.5_loss'])\n",
    "        combined_df_2023.at[i, 'team2_ah+2.5_wins_last5'] = team2_matches['ah+2.5_win'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team2_ah+2.5_losses_last5'] = team2_matches['ah+2.5_loss'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para over3.5  para a equipe 2\n",
    "        team2_matches['over3.5'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_over3.5'], team2_matches['team2_over3.5'])\n",
    "        team2_matches['under3.5'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_under3.5'], team2_matches['team2_under3.5'])\n",
    "        combined_df_2023.at[i, 'team2_over3.5_last5'] = team2_matches['over3.5'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team2_under3.5_last5'] = team2_matches['under3.5'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para over4.5  para a equipe 2\n",
    "        team2_matches['over4.5'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_over4.5'], team2_matches['team2_over4.5'])\n",
    "        team2_matches['under4.5'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_under4.5'], team2_matches['team2_under4.5'])\n",
    "        combined_df_2023.at[i, 'team2_over4.5_last5'] = team2_matches['over4.5'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team2_under4.5_last5'] = team2_matches['under4.5'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "\n",
    "        # Para over6.5  para a equipe 2\n",
    "        team2_matches['over6.5'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_over6.5'], team2_matches['team2_over6.5'])\n",
    "        team2_matches['under6.5'] = np.where(team2_matches['team1'] == row['team2'], team2_matches['team1_under6.5'], team2_matches['team2_under6.5'])\n",
    "        combined_df_2023.at[i, 'team2_over6.5_last5'] = team2_matches['over6.5'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "        combined_df_2023.at[i, 'team2_under6.5_last5'] = team2_matches['under6.5'].rolling(5).sum().iloc[-1] if len(team2_matches) >= 2 else np.nan\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "for i, row in combined_df_2023.iterrows():\n",
    "    team1_home = combined_df_2023[(combined_df_2023['date'] < row['date']) & (combined_df_2023['team1'] == row['team1']) & (combined_df_2023['season'] == row['season'])]\n",
    "    team1_away = combined_df_2023[(combined_df_2023['date'] < row['date']) & (combined_df_2023['team2'] == row['team1']) & (combined_df_2023['season'] == row['season'])]\n",
    "    \n",
    "    team2_home = combined_df_2023[(combined_df_2023['date'] < row['date']) & (combined_df_2023['team1'] == row['team2']) & (combined_df_2023['season'] == row['season'])]\n",
    "    team2_away = combined_df_2023[(combined_df_2023['date'] < row['date']) & (combined_df_2023['team2'] == row['team2']) & (combined_df_2023['season'] == row['season'])]\n",
    "\n",
    "    if not team1_home.empty:\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts3_1_home'] = team1_home['team1_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team1_home['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts5_1_home'] = team1_home['team1_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts3_1_home'] = team1_home['team2_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team1_home['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts5_1_home'] = team1_home['team2_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team2_goals'].isna().any() else np.nan\n",
    "        ####################################### ABAIXO É SOBRE FINALIZAÇÕES ###########################################\n",
    "        combined_df_2023.at[i, 'avg_total_shots_lasts5_1_home'] = team1_home['team1_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_total_shots'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_total_shots_lasts5_1_home'] = team1_home['team2_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team2_total_shots'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_otarget_shots_lasts5_1_home'] = team1_home['team1_shots_on_target'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_shots_on_target'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_out_shots_lasts5_1_home'] = team1_home['team1_shots_out'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_shots_out'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE CORNERS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_corners_lasts5_1_home'] = team1_home['team1_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_corners'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_corners_conc_lasts5_1_home'] = team1_home['team2_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team2_corners'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE FOULS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_fouls_lasts5_1_home'] = team1_home['team1_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team1_fouls'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_fouls_conc_lasts5_1_home'] = team1_home['team2_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_home['team2_fouls'].isna().any() else np.nan\n",
    "\n",
    "    if not team1_away.empty:\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts3_1_away'] = team1_away['team2_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team1_away['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts5_1_away'] = team1_away['team2_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts3_1_away'] = team1_away['team1_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team1_away['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts5_1_away'] = team1_away['team1_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team1_goals'].isna().any() else np.nan\n",
    "        ####################################### ABAIXO É SOBRE FINALIZAÇÕES ###########################################\n",
    "        combined_df_2023.at[i, 'avg_total_shots_lasts5_1_away'] = team1_away['team2_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_total_shots'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_otarget_shots_lasts5_1_away'] = team1_away['team2_shots_on_target'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_shots_on_target'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_out_shots_lasts5_1_away'] = team1_away['team2_shots_out'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_shots_out'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_total_shots_lasts5_1_away'] = team1_away['team1_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team1_total_shots'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE CORNERS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_corners_lasts5_1_away'] = team1_away['team2_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_corners'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_corners_conc_lasts5_1_away'] = team1_away['team1_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team1_corners'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE FOULS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_fouls_lasts5_1_away'] = team1_away['team2_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team2_fouls'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_fouls_conc_lasts5_1_away'] = team1_away['team1_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team1_away['team1_fouls'].isna().any() else np.nan\n",
    "\n",
    "    if not team2_home.empty:\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts3_2_home'] = team2_home['team1_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team2_home['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts5_2_home'] = team2_home['team1_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts3_2_home'] = team2_home['team2_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team2_home['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts5_2_home'] = team2_home['team2_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team2_goals'].isna().any() else np.nan\n",
    "        ####################################### ABAIXO É SOBRE FINALIZAÇÕES ###########################################\n",
    "        combined_df_2023.at[i, 'avg_total_shots_lasts5_2_home'] = team2_home['team1_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_total_shots'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_otarget_shots_lasts5_2_home'] = team2_home['team1_shots_on_target'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_shots_on_target'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_out_shots_lasts5_2_home'] = team2_home['team1_shots_out'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_shots_out'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_total_shots_lasts5_2_home'] = team2_home['team2_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team2_total_shots'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE CORNERS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_corners_lasts5_2_home'] = team2_home['team1_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_corners'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_corners_conc_lasts5_2_home'] = team2_home['team2_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team2_corners'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE FOULS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_fouls_lasts5_2_home'] = team2_home['team1_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team1_fouls'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_fouls_conc_lasts5_2_home'] = team2_home['team2_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_home['team2_fouls'].isna().any() else np.nan\n",
    "\n",
    "\n",
    "    if not team2_away.empty:\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts3_2_away'] = team2_away['team2_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team2_away['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_scr_lasts5_2_away'] = team2_away['team2_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts3_2_away'] = team2_away['team1_goals'].rolling(3, min_periods=2).mean().iloc[-1] if not team2_away['team1_goals'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_lasts5_2_away'] = team2_away['team1_goals'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team1_goals'].isna().any() else np.nan\n",
    "        ####################################### ABAIXO É SOBRE FINALIZAÇÕES ###########################################\n",
    "        combined_df_2023.at[i, 'avg_total_shots_lasts5_2_away'] = team2_away['team2_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_total_shots'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_otarget_shots_lasts5_2_away'] = team2_away['team2_shots_on_target'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_shots_on_target'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_out_shots_lasts5_2_away'] = team2_away['team2_shots_out'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_shots_out'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_conc_total_shots_lasts5_2_away'] = team2_away['team1_total_shots'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team1_total_shots'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE CORNERS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_corners_lasts5_2_away'] = team2_away['team2_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_corners'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_corners_conc_lasts5_2_away'] = team2_away['team1_corners'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team1_corners'].isna().any() else np.nan\n",
    "        ########################################## ABAIXO É SOBRE FOULS ##########################################\n",
    "        combined_df_2023.at[i, 'avg_fouls_lasts5_2_away'] = team2_away['team2_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team2_fouls'].isna().any() else np.nan\n",
    "        combined_df_2023.at[i, 'avg_fouls_conc_lasts5_2_away'] = team2_away['team1_fouls'].rolling(5, min_periods=2).mean().iloc[-1] if not team2_away['team1_fouls'].isna().any() else np.nan\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "combined_df_2023.shape        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 140)"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_result(row):\n",
    "    if row['team1_goals'] > row['team2_goals']:\n",
    "        return pd.Series([3, 0])\n",
    "    elif row['team1_goals'] < row['team2_goals']:\n",
    "        return pd.Series([0, 3])\n",
    "    else:\n",
    "        return pd.Series([1, 1])\n",
    "\n",
    "combined_df_2023[['result_team1', 'result_team2']] = combined_df_2023.apply(get_result, axis=1)\n",
    "\n",
    "def get_streak(df, result_col, results):\n",
    "    result_series = df[result_col].apply(lambda x: 1 if x in results else 0)\n",
    "    result_series = result_series * (result_series.groupby((result_series != result_series.shift()).cumsum()).cumcount() + 1)\n",
    "    return result_series\n",
    "\n",
    "# Create a dictionary to hold individual team dataframes\n",
    "team_df_dict = {}\n",
    "\n",
    "def get_individual_team_df(df, team_name): #teoricamente aqui deveria ser corners, mas o erro se apresentou menor assim:\n",
    "    if team_name in team_df_dict:\n",
    "        return team_df_dict[team_name]\n",
    "        \n",
    "    team_games = df[(df['team1'] == team_name) | (df['team2'] == team_name)].copy()\n",
    "    team_games['team_is_team1'] = team_games['team1'] == team_name\n",
    "    team_games['team_result'] = np.where(team_games['team_is_team1'], team_games['result_team1'], team_games['result_team2'])\n",
    "    team_games['team_goals'] = np.where(team_games['team_is_team1'], team_games['team1_goals'], team_games['team2_goals'])\n",
    "    team_games['team_redcards'] = np.where(team_games['team_is_team1'], team_games['team1_red_cards'], team_games['team2_red_cards'])\n",
    "\n",
    "    team_games.sort_values('date', inplace=True)\n",
    "    team_games['days_since_last_game'] = team_games['date'].diff().dt.days\n",
    "\n",
    "    team_df_dict[team_name] = team_games\n",
    "    return team_games\n",
    "\n",
    "def get_team_stats(row, df):\n",
    "    team1_games = get_individual_team_df(df, row['team1'])\n",
    "    team2_games = get_individual_team_df(df, row['team2'])\n",
    "\n",
    "    # Filter to include only games that occurred before the current game\n",
    "    team1_games = team1_games[team1_games['date'] < row['date']]\n",
    "    team2_games = team2_games[team2_games['date'] < row['date']]\n",
    "\n",
    "    stats = {}\n",
    "\n",
    "    if not team1_games.empty:\n",
    "        stats['team1_winning_streak'] = get_streak(team1_games, 'team_result', [3]).iloc[-1]\n",
    "        stats['team1_undefeated_streak'] = get_streak(team1_games, 'team_result', [1, 3]).iloc[-1]\n",
    "        stats['team1_losing_streak'] = get_streak(team1_games, 'team_result', [0]).iloc[-1]\n",
    "        stats['team1_without_winning_streak'] = get_streak(team1_games, 'team_result', [0, 1]).iloc[-1]\n",
    "        stats['avg_points_lasts5_1'] = team1_games.tail(5)['team_result'].mean()\n",
    "        stats['team1_strength'] = team1_games['team_goals'].sum() / (team1_games['team1_goals'].sum() + team1_games['team2_goals'].sum() + 0.01)\n",
    "        stats['championship_points_1'] = team1_games['team_result'].sum() / len(team1_games)\n",
    "        rested_4_or_more_days_1 = team1_games.tail(1)['days_since_last_game'].values[0] >= 4\n",
    "        stats['rested_4_days_or_more_1'] = 1 if rested_4_or_more_days_1 else -1\n",
    "\n",
    "    if not team2_games.empty:\n",
    "        stats['team2_winning_streak'] = get_streak(team2_games, 'team_result', [3]).iloc[-1]\n",
    "        stats['team2_undefeated_streak'] = get_streak(team2_games, 'team_result', [1, 3]).iloc[-1]\n",
    "        stats['team2_losing_streak'] = get_streak(team2_games, 'team_result', [0]).iloc[-1]\n",
    "        stats['team2_without_winning_streak'] = get_streak(team2_games, 'team_result', [0, 1]).iloc[-1]\n",
    "        stats['avg_points_lasts5_2'] = team2_games.tail(5)['team_result'].mean()\n",
    "        stats['team2_strength'] = team2_games['team_goals'].sum() / (team2_games['team1_goals'].sum() + team2_games['team2_goals'].sum() + 0.01)\n",
    "        stats['championship_points_2'] = team2_games['team_result'].sum() / len(team2_games)\n",
    "        rested_4_or_more_days_2 = team2_games.tail(1)['days_since_last_game'].values[0] >= 4\n",
    "        stats['rested_4_days_or_more_2'] = 1 if rested_4_or_more_days_2 else -1\n",
    "\n",
    "    return pd.Series(stats)\n",
    "\n",
    "combined_df_2023 = pd.concat([combined_df_2023, combined_df_2023.apply(lambda row: get_team_stats(row, combined_df_2023), axis=1)], axis=1)\n",
    "\n",
    "# Now, calculate the number of suspended players for the next match for each team.\n",
    "for team_name in team_df_dict.keys():\n",
    "    team_df = team_df_dict[team_name].copy()\n",
    "    team_df['next_match_suspended_players'] = team_df['team_redcards'].shift()\n",
    "\n",
    "    # Assign the suspended players back to the combined_df_2023.\n",
    "    team1_mask = combined_df_2023['team1'] == team_name\n",
    "    team2_mask = combined_df_2023['team2'] == team_name\n",
    "    combined_df_2023.loc[team1_mask, 'team1_suspended_players'] = team_df.loc[team1_mask, 'next_match_suspended_players']\n",
    "    combined_df_2023.loc[team2_mask, 'team2_suspended_players'] = team_df.loc[team2_mask, 'next_match_suspended_players']\n",
    "\n",
    "combined_df_2023.shape    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['team1',\n",
       " 'team2',\n",
       " 'team1_goals',\n",
       " 'team2_goals',\n",
       " 'season',\n",
       " 'championship',\n",
       " 'team1_shots_on_target',\n",
       " 'team1_shots_out',\n",
       " 'team2_shots_on_target',\n",
       " 'team2_shots_out',\n",
       " 'team1_red_cards',\n",
       " 'team2_red_cards',\n",
       " 'team1_fouls',\n",
       " 'team2_fouls',\n",
       " 'team1_corners',\n",
       " 'team2_corners',\n",
       " 'team1_total_shots',\n",
       " 'team2_total_shots',\n",
       " 'date',\n",
       " 'is_future_match',\n",
       " 'goal_diff_team1',\n",
       " 'goal_diff_team2',\n",
       " 'corners_diff_team1',\n",
       " 'corners_diff_team2',\n",
       " 'team1_big_win',\n",
       " 'team1_big_loss',\n",
       " 'team2_big_win',\n",
       " 'team2_big_loss',\n",
       " 'team1_ah-2.5_win',\n",
       " 'team1_ah-2.5_loss',\n",
       " 'team2_ah-2.5_win',\n",
       " 'team2_ah-2.5_loss',\n",
       " 'team1_ah+2.5_win',\n",
       " 'team1_ah+2.5_loss',\n",
       " 'team2_ah+2.5_win',\n",
       " 'team2_ah+2.5_loss',\n",
       " 'team1_over4.5',\n",
       " 'team1_under4.5',\n",
       " 'team2_over4.5',\n",
       " 'team2_under4.5',\n",
       " 'team1_over3.5',\n",
       " 'team1_under3.5',\n",
       " 'team2_over3.5',\n",
       " 'team2_under3.5',\n",
       " 'team1_over6.5',\n",
       " 'team1_under6.5',\n",
       " 'team2_over6.5',\n",
       " 'team2_under6.5',\n",
       " 'team1_big_wins_last5',\n",
       " 'team1_big_losses_last5',\n",
       " 'team2_big_wins_last5',\n",
       " 'team2_big_losses_last5',\n",
       " 'team1_ah-2.5_wins_last5',\n",
       " 'team1_ah-2.5_losses_last5',\n",
       " 'team2_ah-2.5_wins_last5',\n",
       " 'team2_ah-2.5_losses_last5',\n",
       " 'team1_ah+2.5_wins_last5',\n",
       " 'team1_ah+2.5_losses_last5',\n",
       " 'team2_ah+2.5_wins_last5',\n",
       " 'team2_ah+2.5_losses_last5',\n",
       " 'team1_over3.5_last5',\n",
       " 'team1_under3.5_last5',\n",
       " 'team2_over3.5_last5',\n",
       " 'team2_under3.5_last5',\n",
       " 'team1_over4.5_last5',\n",
       " 'team1_under4.5_last5',\n",
       " 'team2_over4.5_last5',\n",
       " 'team2_under4.5_last5',\n",
       " 'team1_over6.5_last5',\n",
       " 'team1_under6.5_last5',\n",
       " 'team2_over6.5_last5',\n",
       " 'team2_under6.5_last5',\n",
       " 'avg_scr_lasts3_1_home',\n",
       " 'avg_scr_lasts5_1_home',\n",
       " 'avg_scr_lasts3_1_away',\n",
       " 'avg_scr_lasts5_1_away',\n",
       " 'avg_conc_lasts3_1_home',\n",
       " 'avg_conc_lasts5_1_home',\n",
       " 'avg_conc_lasts3_1_away',\n",
       " 'avg_conc_lasts5_1_away',\n",
       " 'avg_scr_lasts3_2_home',\n",
       " 'avg_scr_lasts5_2_home',\n",
       " 'avg_scr_lasts3_2_away',\n",
       " 'avg_scr_lasts5_2_away',\n",
       " 'avg_conc_lasts3_2_home',\n",
       " 'avg_conc_lasts5_2_home',\n",
       " 'avg_conc_lasts3_2_away',\n",
       " 'avg_conc_lasts5_2_away',\n",
       " 'avg_total_shots_lasts5_1_home',\n",
       " 'avg_total_shots_lasts5_1_away',\n",
       " 'avg_total_shots_lasts5_2_home',\n",
       " 'avg_total_shots_lasts5_2_away',\n",
       " 'avg_otarget_shots_lasts5_1_home',\n",
       " 'avg_otarget_shots_lasts5_1_away',\n",
       " 'avg_otarget_shots_lasts5_2_home',\n",
       " 'avg_otarget_shots_lasts5_2_away',\n",
       " 'avg_out_shots_lasts5_1_home',\n",
       " 'avg_out_shots_lasts5_1_away',\n",
       " 'avg_out_shots_lasts5_2_home',\n",
       " 'avg_out_shots_lasts5_2_away',\n",
       " 'avg_conc_total_shots_lasts5_1_home',\n",
       " 'avg_conc_total_shots_lasts5_1_away',\n",
       " 'avg_conc_total_shots_lasts5_2_home',\n",
       " 'avg_conc_total_shots_lasts5_2_away',\n",
       " 'avg_corners_lasts5_1_home',\n",
       " 'avg_corners_lasts5_1_away',\n",
       " 'avg_corners_conc_lasts5_1_home',\n",
       " 'avg_corners_conc_lasts5_1_away',\n",
       " 'avg_corners_lasts5_2_home',\n",
       " 'avg_corners_lasts5_2_away',\n",
       " 'avg_corners_conc_lasts5_2_home',\n",
       " 'avg_corners_conc_lasts5_2_away',\n",
       " 'avg_fouls_lasts5_1_home',\n",
       " 'avg_fouls_lasts5_1_away',\n",
       " 'avg_fouls_conc_lasts5_1_home',\n",
       " 'avg_fouls_conc_lasts5_1_away',\n",
       " 'avg_fouls_lasts5_2_home',\n",
       " 'avg_fouls_lasts5_2_away',\n",
       " 'avg_fouls_conc_lasts5_2_home',\n",
       " 'avg_fouls_conc_lasts5_2_away',\n",
       " 'result_team1',\n",
       " 'result_team2',\n",
       " 'avg_points_lasts5_1',\n",
       " 'avg_points_lasts5_2',\n",
       " 'championship_points_1',\n",
       " 'championship_points_2',\n",
       " 'rested_4_days_or_more_1',\n",
       " 'rested_4_days_or_more_2',\n",
       " 'team1_losing_streak',\n",
       " 'team1_strength',\n",
       " 'team1_undefeated_streak',\n",
       " 'team1_winning_streak',\n",
       " 'team1_without_winning_streak',\n",
       " 'team2_losing_streak',\n",
       " 'team2_strength',\n",
       " 'team2_undefeated_streak',\n",
       " 'team2_winning_streak',\n",
       " 'team2_without_winning_streak',\n",
       " 'team1_suspended_players',\n",
       " 'team2_suspended_players']"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combined_df_2023.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    " #'team1_goals',\n",
    " #'team2_goals',\n",
    " 'team1_shots_on_target',\n",
    " 'team1_shots_out',\n",
    " 'team2_shots_on_target',\n",
    " 'team2_shots_out',\n",
    " 'team1_red_cards',\n",
    " 'team2_red_cards',\n",
    " 'team1_fouls',\n",
    " 'team2_fouls',\n",
    " 'team1_corners',\n",
    " 'team2_corners',\n",
    " 'team1_total_shots',\n",
    " 'team2_total_shots',\n",
    " 'date',\n",
    " 'is_future_match',\n",
    " 'goal_diff_team1',\n",
    " 'goal_diff_team2',\n",
    " 'corners_diff_team1',\n",
    " 'corners_diff_team2',\n",
    " 'team1_big_win',\n",
    " 'team1_big_loss',\n",
    " 'team2_big_win',\n",
    " 'team2_big_loss',\n",
    " 'team1_ah-2.5_win',\n",
    " 'team1_ah-2.5_loss',\n",
    " 'team2_ah-2.5_win',\n",
    " 'team2_ah-2.5_loss',\n",
    " 'team1_ah+2.5_win',\n",
    " 'team1_ah+2.5_loss',\n",
    " 'team2_ah+2.5_win',\n",
    " 'team2_ah+2.5_loss',\n",
    " 'team1_over4.5',\n",
    " 'team1_under4.5',\n",
    " 'team2_over4.5',\n",
    " 'team2_under4.5',\n",
    " 'team1_over3.5',\n",
    " 'team1_under3.5',\n",
    " 'team2_over3.5',\n",
    " 'team2_under3.5',\n",
    " 'team1_over6.5',\n",
    " 'team1_under6.5',\n",
    " 'team2_over6.5',\n",
    " 'team2_under6.5',\n",
    " 'result_team1',\n",
    " 'result_team2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando future Match baseado na data de hoje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(261, 140)\n",
      "(18, 95)\n"
     ]
    }
   ],
   "source": [
    "dataset2 = combined_df_2023.copy()\n",
    "\n",
    "# filter the DataFrame\n",
    "future_matches = dataset2[dataset2['is_future_match'] == True].copy()\n",
    "future_matches.sort_values(by='date')\n",
    "print(future_matches.shape)\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Get yesterday's date\n",
    "yesterday = datetime.now() - timedelta(days=1)\n",
    "\n",
    "# Filter the DataFrame to include only rows with dates greater than yesterday\n",
    "#future_matches = future_matches[future_matches['date'] > yesterday]\n",
    "\n",
    "# Substituir np.nan por 0\n",
    "future_matches['team1_goals'].fillna(0, inplace=True)\n",
    "future_matches['team2_goals'].fillna(0, inplace=True)\n",
    "\n",
    "# Liste todas as colunas que você deseja verificar\n",
    "columns_to_check= [col for col in future_matches.columns if col not in columns_to_drop]\n",
    "\n",
    "# Drop as linhas com 'np.nan' nas colunas especificadas\n",
    "future_matches = future_matches.dropna(subset=columns_to_check)\n",
    "future_matches_calculado = future_matches.drop(columns_to_drop,axis=1)\n",
    "future_matches_calculado = future_matches_calculado.drop('season',axis=1)\n",
    "\n",
    "\n",
    "\"\"\"# Contando os valores NaN em cada coluna\n",
    "nan_counts = future_matches.isna().sum()\n",
    "\n",
    "# Transformando em uma lista de pares (nome da coluna, contagem de np.nan)\n",
    "nan_list = list(nan_counts.items())\n",
    "\n",
    "# Percorrendo a lista e imprimindo cada valor individualmente com o nome da coluna\n",
    "for col_name, nan_count in nan_list:\n",
    "    print(f'{col_name}: {nan_count}')\"\"\"\n",
    "    \n",
    "print(future_matches_calculado.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 140)\n",
      "A quantidade de np.nan em linhas eram 20760\n",
      "Total number of rows with 'NaN' or an empty value: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(246, 140)"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CORTAR AS LINHAS COM MATCHES FUTUROS AQUI\n",
    "\n",
    "# Replace empty strings with NaN\n",
    "print(dataset2.shape)\n",
    "dataset2.replace('', np.nan, inplace=True)\n",
    "print(f\"A quantidade de np.nan em linhas eram {dataset2.isna().sum().sum()}\")\n",
    "# Remove rows that contain any missing values\n",
    "dataset2.dropna(inplace=True)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "counter = 0  # Initialize counter\n",
    "for index, row in dataset2.iterrows():\n",
    "    if row.isnull().any() or row.eq('').any():\n",
    "        print(f\"Row {index} contains 'NaN' or an empty value.\")\n",
    "        counter += 1  # Increase counter if condition is met\n",
    "\n",
    "print(f\"Total number of rows with 'NaN' or an empty value: {counter}\")\n",
    "dataset2.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenando os 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>championship</th>\n",
       "      <th>date</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>team1_goals</th>\n",
       "      <th>team2_goals</th>\n",
       "      <th>team1_total_shots</th>\n",
       "      <th>team2_total_shots</th>\n",
       "      <th>team1_shots_on_target</th>\n",
       "      <th>team2_shots_on_target</th>\n",
       "      <th>...</th>\n",
       "      <th>team1_winning_streak</th>\n",
       "      <th>team1_without_winning_streak</th>\n",
       "      <th>team2_losing_streak</th>\n",
       "      <th>team2_strength</th>\n",
       "      <th>team2_undefeated_streak</th>\n",
       "      <th>team2_winning_streak</th>\n",
       "      <th>team2_without_winning_streak</th>\n",
       "      <th>team1_suspended_players</th>\n",
       "      <th>team2_suspended_players</th>\n",
       "      <th>is_future_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E0</td>\n",
       "      <td>2002-09-14</td>\n",
       "      <td>Charlton</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666297</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E0</td>\n",
       "      <td>2002-09-14</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.665927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E0</td>\n",
       "      <td>2002-09-14</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Man United</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.554939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E0</td>\n",
       "      <td>2002-09-14</td>\n",
       "      <td>West Brom</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332963</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E0</td>\n",
       "      <td>2002-09-15</td>\n",
       "      <td>Man City</td>\n",
       "      <td>Blackburn</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.454133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67081</th>\n",
       "      <td>BRA A</td>\n",
       "      <td>2023-08-20</td>\n",
       "      <td>bahia</td>\n",
       "      <td>red bull bragantino</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.613497</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67082</th>\n",
       "      <td>BRA A</td>\n",
       "      <td>2023-08-20</td>\n",
       "      <td>santos</td>\n",
       "      <td>grêmio</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.531802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67083</th>\n",
       "      <td>SUE A</td>\n",
       "      <td>2023-08-20</td>\n",
       "      <td>kalmar</td>\n",
       "      <td>hammarby if</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67084</th>\n",
       "      <td>SUE A</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>norrkoping</td>\n",
       "      <td>aik</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.438917</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67085</th>\n",
       "      <td>BRA A</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>goiás</td>\n",
       "      <td>athletico-pr</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555432</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67086 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      championship       date       team1                team2  team1_goals  \\\n",
       "0               E0 2002-09-14    Charlton              Arsenal          0.0   \n",
       "1               E0 2002-09-14     Everton        Middlesbrough          2.0   \n",
       "2               E0 2002-09-14       Leeds           Man United          1.0   \n",
       "3               E0 2002-09-14   West Brom          Southampton          1.0   \n",
       "4               E0 2002-09-15    Man City            Blackburn          2.0   \n",
       "...            ...        ...         ...                  ...          ...   \n",
       "67081        BRA A 2023-08-20       bahia  red bull bragantino          4.0   \n",
       "67082        BRA A 2023-08-20      santos               grêmio          2.0   \n",
       "67083        SUE A 2023-08-20      kalmar          hammarby if          0.0   \n",
       "67084        SUE A 2023-08-21  norrkoping                  aik          3.0   \n",
       "67085        BRA A 2023-08-21       goiás         athletico-pr          1.0   \n",
       "\n",
       "       team2_goals  team1_total_shots  team2_total_shots  \\\n",
       "0              3.0                9.0               10.0   \n",
       "1              1.0               13.0               10.0   \n",
       "2              0.0                8.0                6.0   \n",
       "3              0.0               11.0               10.0   \n",
       "4              2.0               15.0               12.0   \n",
       "...            ...                ...                ...   \n",
       "67081          0.0                9.0               10.0   \n",
       "67082          1.0               15.0                6.0   \n",
       "67083          0.0                2.0                4.0   \n",
       "67084          1.0               10.0               12.0   \n",
       "67085          1.0               13.0               11.0   \n",
       "\n",
       "       team1_shots_on_target  team2_shots_on_target  ...  \\\n",
       "0                        3.0                    8.0  ...   \n",
       "1                        8.0                    5.0  ...   \n",
       "2                        2.0                    5.0  ...   \n",
       "3                        7.0                    5.0  ...   \n",
       "4                        7.0                    8.0  ...   \n",
       "...                      ...                    ...  ...   \n",
       "67081                    6.0                    8.0  ...   \n",
       "67082                    8.0                    4.0  ...   \n",
       "67083                    1.0                    2.0  ...   \n",
       "67084                    5.0                    8.0  ...   \n",
       "67085                    4.0                    5.0  ...   \n",
       "\n",
       "       team1_winning_streak  team1_without_winning_streak  \\\n",
       "0                       0.0                           1.0   \n",
       "1                       0.0                           3.0   \n",
       "2                       1.0                           0.0   \n",
       "3                       2.0                           0.0   \n",
       "4                       0.0                           1.0   \n",
       "...                     ...                           ...   \n",
       "67081                   0.0                           7.0   \n",
       "67082                   0.0                           5.0   \n",
       "67083                   0.0                           3.0   \n",
       "67084                   4.0                           0.0   \n",
       "67085                   2.0                           0.0   \n",
       "\n",
       "       team2_losing_streak  team2_strength  team2_undefeated_streak  \\\n",
       "0                      0.0        0.666297                      5.0   \n",
       "1                      0.0        0.665927                      1.0   \n",
       "2                      1.0        0.554939                      0.0   \n",
       "3                      0.0        0.332963                      1.0   \n",
       "4                      2.0        0.454133                      0.0   \n",
       "...                    ...             ...                      ...   \n",
       "67081                  0.0        0.613497                      4.0   \n",
       "67082                  0.0        0.531802                      1.0   \n",
       "67083                  0.0        0.469292                      1.0   \n",
       "67084                  0.0        0.438917                      5.0   \n",
       "67085                  0.0        0.555432                      5.0   \n",
       "\n",
       "       team2_winning_streak  team2_without_winning_streak  \\\n",
       "0                       1.0                           0.0   \n",
       "1                       1.0                           0.0   \n",
       "2                       0.0                           1.0   \n",
       "3                       1.0                           0.0   \n",
       "4                       0.0                           3.0   \n",
       "...                     ...                           ...   \n",
       "67081                   0.0                           1.0   \n",
       "67082                   1.0                           0.0   \n",
       "67083                   1.0                           0.0   \n",
       "67084                   0.0                           2.0   \n",
       "67085                   1.0                           0.0   \n",
       "\n",
       "       team1_suspended_players team2_suspended_players  is_future_match  \n",
       "0                          0.0                     0.0              NaN  \n",
       "1                          0.0                     0.0              NaN  \n",
       "2                          0.0                     0.0              NaN  \n",
       "3                          0.0                     0.0              NaN  \n",
       "4                          1.0                     0.0              NaN  \n",
       "...                        ...                     ...              ...  \n",
       "67081                      0.0                     0.0            False  \n",
       "67082                      0.0                     0.0            False  \n",
       "67083                      0.0                     0.0            False  \n",
       "67084                      0.0                     0.0            False  \n",
       "67085                      0.0                     0.0            False  \n",
       "\n",
       "[67086 rows x 140 columns]"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatotal = pd.concat([dataset, dataset2], ignore_index=True)#mudei o 'dataset' por combined_df_13c_new\n",
    "\n",
    "datatotal.sort_values(by='date', inplace=True)\n",
    "\n",
    "if 'team1_yellow_cards' in datatotal.columns:\n",
    "    datatotal = datatotal.drop(['team1_yellow_cards'], axis=1)\n",
    "\n",
    "if 'team2_yellow_cards' in datatotal.columns:\n",
    "    datatotal = datatotal.drop(['team2_yellow_cards'], axis=1)\n",
    "\n",
    "# Substituir valores maiores que 15 por 15 na coluna 'team1_corners'\n",
    "datatotal.loc[datatotal['team1_corners'] > 15, 'team1_corners'] = 15\n",
    "\n",
    "# Substituir valores maiores que 15 por 15 na coluna 'team2_corners'\n",
    "datatotal.loc[datatotal['team2_corners'] > 15, 'team2_corners'] = 15    \n",
    "\n",
    "datatotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E0' 'SC0' 'E3' 'E2' 'E1' 'I1' 'SP1' 'D1' 'F1' 'D2' 'P1' 'SP2' 'T1' 'I2'\n",
      " 'N1' 'F2' 'B1' 'G1' 'SUE A' 'BRA A']\n"
     ]
    }
   ],
   "source": [
    "champ_uniques = datatotal['championship'].unique()\n",
    "print(champ_uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converta Categorias em IDs Numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Suponho que 'datatotal' e 'future_matches' já estejam definidos e tenham as mesmas colunas relevantes\n",
    "\n",
    "# Treinar o LabelEncoder com 'datatotal' e 'future_matches'\n",
    "le_teams = LabelEncoder().fit(pd.concat([datatotal['team1'], datatotal['team2'], future_matches_calculado['team1'], future_matches_calculado['team2']]).astype(str))\n",
    "le_champ = LabelEncoder().fit(pd.concat([datatotal['championship'], future_matches_calculado['championship']]).astype(str))\n",
    "\n",
    "# Aplicar o LabelEncoder a 'datatotal'\n",
    "datatotal['team1'] = le_teams.transform(datatotal['team1'].astype(str))\n",
    "datatotal['team2'] = le_teams.transform(datatotal['team2'].astype(str))\n",
    "datatotal['championship'] = le_champ.transform(datatotal['championship'].astype(str))\n",
    "\n",
    "# Agora, aplicar o mesmo LabelEncoder a 'future_matches'\n",
    "future_matches_calculado['team1'] = le_teams.transform(future_matches_calculado['team1'].astype(str))\n",
    "future_matches_calculado['team2'] = le_teams.transform(future_matches_calculado['team2'].astype(str))\n",
    "future_matches_calculado['championship'] = le_champ.transform(future_matches_calculado['championship'].astype(str))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>team1_goals</th>\n",
       "      <th>team2_goals</th>\n",
       "      <th>championship</th>\n",
       "      <th>team1_big_wins_last5</th>\n",
       "      <th>team1_big_losses_last5</th>\n",
       "      <th>team2_big_wins_last5</th>\n",
       "      <th>team2_big_losses_last5</th>\n",
       "      <th>team1_ah-2.5_wins_last5</th>\n",
       "      <th>...</th>\n",
       "      <th>team1_undefeated_streak</th>\n",
       "      <th>team1_winning_streak</th>\n",
       "      <th>team1_without_winning_streak</th>\n",
       "      <th>team2_losing_streak</th>\n",
       "      <th>team2_strength</th>\n",
       "      <th>team2_undefeated_streak</th>\n",
       "      <th>team2_winning_streak</th>\n",
       "      <th>team2_without_winning_streak</th>\n",
       "      <th>team1_suspended_players</th>\n",
       "      <th>team2_suspended_players</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>475</td>\n",
       "      <td>485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386276</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>482</td>\n",
       "      <td>492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.410151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>486</td>\n",
       "      <td>477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>498</td>\n",
       "      <td>478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.476077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>495</td>\n",
       "      <td>488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469292</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     team1  team2  team1_goals  team2_goals  championship  \\\n",
       "190    475    485          0.0          0.0             1   \n",
       "189    482    492          0.0          0.0             1   \n",
       "197    486    477          0.0          0.0             1   \n",
       "192    498    478          0.0          0.0             1   \n",
       "524    495    488          0.0          0.0            18   \n",
       "\n",
       "     team1_big_wins_last5  team1_big_losses_last5  team2_big_wins_last5  \\\n",
       "190                   2.0                     0.0                   0.0   \n",
       "189                   0.0                     1.0                   0.0   \n",
       "197                   0.0                     0.0                   0.0   \n",
       "192                   1.0                     1.0                   1.0   \n",
       "524                   1.0                     1.0                   1.0   \n",
       "\n",
       "     team2_big_losses_last5  team1_ah-2.5_wins_last5  ...  \\\n",
       "190                     0.0                      1.0  ...   \n",
       "189                     1.0                      2.0  ...   \n",
       "197                     0.0                      0.0  ...   \n",
       "192                     2.0                      3.0  ...   \n",
       "524                     0.0                      1.0  ...   \n",
       "\n",
       "     team1_undefeated_streak  team1_winning_streak  \\\n",
       "190                      6.0                   0.0   \n",
       "189                      2.0                   1.0   \n",
       "197                      0.0                   0.0   \n",
       "192                      0.0                   0.0   \n",
       "524                      0.0                   0.0   \n",
       "\n",
       "     team1_without_winning_streak  team2_losing_streak  team2_strength  \\\n",
       "190                           1.0                  0.0        0.386276   \n",
       "189                           0.0                  2.0        0.410151   \n",
       "197                           1.0                  0.0        0.483715   \n",
       "192                           2.0                  2.0        0.476077   \n",
       "524                           1.0                  0.0        0.469292   \n",
       "\n",
       "     team2_undefeated_streak  team2_winning_streak  \\\n",
       "190                      6.0                   0.0   \n",
       "189                      0.0                   0.0   \n",
       "197                      1.0                   0.0   \n",
       "192                      0.0                   0.0   \n",
       "524                      2.0                   0.0   \n",
       "\n",
       "     team2_without_winning_streak  team1_suspended_players  \\\n",
       "190                           1.0                      0.0   \n",
       "189                           8.0                      0.0   \n",
       "197                           6.0                      1.0   \n",
       "192                           2.0                      0.0   \n",
       "524                           1.0                      0.0   \n",
       "\n",
       "     team2_suspended_players  \n",
       "190                      0.0  \n",
       "189                      0.0  \n",
       "197                      0.0  \n",
       "192                      0.0  \n",
       "524                      0.0  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_matches_calculado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "n_teams = len(le_teams.classes_)\n",
    "n_champ = len(le_champ.classes_)\n",
    "print(n_teams)\n",
    "print(n_champ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatotal['season'] = datatotal['season'].astype('float64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando X e Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67086, 96)"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = datatotal.drop(columns_to_drop, axis=1)\n",
    "y1 = datatotal['team1_corners']\n",
    "y2 = datatotal['team2_corners']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dtype('int32'),\n",
       " dtype('int32'),\n",
       " dtype('int32'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64'),\n",
       " dtype('float64')]"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['championship',\n",
       " 'team1',\n",
       " 'team2',\n",
       " 'team1_goals',\n",
       " 'team2_goals',\n",
       " 'season',\n",
       " 'team1_big_wins_last5',\n",
       " 'team1_big_losses_last5',\n",
       " 'team2_big_wins_last5',\n",
       " 'team2_big_losses_last5',\n",
       " 'team1_ah-2.5_wins_last5',\n",
       " 'team1_ah-2.5_losses_last5',\n",
       " 'team2_ah-2.5_wins_last5',\n",
       " 'team2_ah-2.5_losses_last5',\n",
       " 'team1_ah+2.5_wins_last5',\n",
       " 'team1_ah+2.5_losses_last5',\n",
       " 'team2_ah+2.5_wins_last5',\n",
       " 'team2_ah+2.5_losses_last5',\n",
       " 'team1_over3.5_last5',\n",
       " 'team1_under3.5_last5',\n",
       " 'team2_over3.5_last5',\n",
       " 'team2_under3.5_last5',\n",
       " 'team1_over4.5_last5',\n",
       " 'team1_under4.5_last5',\n",
       " 'team2_over4.5_last5',\n",
       " 'team2_under4.5_last5',\n",
       " 'team1_over6.5_last5',\n",
       " 'team1_under6.5_last5',\n",
       " 'team2_over6.5_last5',\n",
       " 'team2_under6.5_last5',\n",
       " 'avg_scr_lasts3_1_home',\n",
       " 'avg_scr_lasts5_1_home',\n",
       " 'avg_scr_lasts3_1_away',\n",
       " 'avg_scr_lasts5_1_away',\n",
       " 'avg_conc_lasts3_1_home',\n",
       " 'avg_conc_lasts5_1_home',\n",
       " 'avg_conc_lasts3_1_away',\n",
       " 'avg_conc_lasts5_1_away',\n",
       " 'avg_scr_lasts3_2_home',\n",
       " 'avg_scr_lasts5_2_home',\n",
       " 'avg_scr_lasts3_2_away',\n",
       " 'avg_scr_lasts5_2_away',\n",
       " 'avg_conc_lasts3_2_home',\n",
       " 'avg_conc_lasts5_2_home',\n",
       " 'avg_conc_lasts3_2_away',\n",
       " 'avg_conc_lasts5_2_away',\n",
       " 'avg_total_shots_lasts5_1_home',\n",
       " 'avg_total_shots_lasts5_1_away',\n",
       " 'avg_total_shots_lasts5_2_home',\n",
       " 'avg_total_shots_lasts5_2_away',\n",
       " 'avg_otarget_shots_lasts5_1_home',\n",
       " 'avg_otarget_shots_lasts5_1_away',\n",
       " 'avg_otarget_shots_lasts5_2_home',\n",
       " 'avg_otarget_shots_lasts5_2_away',\n",
       " 'avg_out_shots_lasts5_1_home',\n",
       " 'avg_out_shots_lasts5_1_away',\n",
       " 'avg_out_shots_lasts5_2_home',\n",
       " 'avg_out_shots_lasts5_2_away',\n",
       " 'avg_conc_total_shots_lasts5_1_home',\n",
       " 'avg_conc_total_shots_lasts5_1_away',\n",
       " 'avg_conc_total_shots_lasts5_2_home',\n",
       " 'avg_conc_total_shots_lasts5_2_away',\n",
       " 'avg_corners_lasts5_1_home',\n",
       " 'avg_corners_lasts5_1_away',\n",
       " 'avg_corners_conc_lasts5_1_home',\n",
       " 'avg_corners_conc_lasts5_1_away',\n",
       " 'avg_corners_lasts5_2_home',\n",
       " 'avg_corners_lasts5_2_away',\n",
       " 'avg_corners_conc_lasts5_2_home',\n",
       " 'avg_corners_conc_lasts5_2_away',\n",
       " 'avg_fouls_lasts5_1_home',\n",
       " 'avg_fouls_lasts5_1_away',\n",
       " 'avg_fouls_conc_lasts5_1_home',\n",
       " 'avg_fouls_conc_lasts5_1_away',\n",
       " 'avg_fouls_lasts5_2_home',\n",
       " 'avg_fouls_lasts5_2_away',\n",
       " 'avg_fouls_conc_lasts5_2_home',\n",
       " 'avg_fouls_conc_lasts5_2_away',\n",
       " 'avg_points_lasts5_1',\n",
       " 'avg_points_lasts5_2',\n",
       " 'championship_points_1',\n",
       " 'championship_points_2',\n",
       " 'rested_4_days_or_more_1',\n",
       " 'rested_4_days_or_more_2',\n",
       " 'team1_losing_streak',\n",
       " 'team1_strength',\n",
       " 'team1_undefeated_streak',\n",
       " 'team1_winning_streak',\n",
       " 'team1_without_winning_streak',\n",
       " 'team2_losing_streak',\n",
       " 'team2_strength',\n",
       " 'team2_undefeated_streak',\n",
       " 'team2_winning_streak',\n",
       " 'team2_without_winning_streak',\n",
       " 'team1_suspended_players',\n",
       " 'team2_suspended_players']"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. 10.  4.  0. 15.  9.  8.  5.  6.  7.  3. 12. 11. 14.  2. 13.]\n"
     ]
    }
   ],
   "source": [
    "y1_uniques = datatotal['team1_corners'].unique()\n",
    "print(y1_uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem de ocorrências para y1:\n",
      "team1_corners\n",
      "0      695\n",
      "1     2435\n",
      "2     5020\n",
      "3     7572\n",
      "4     9206\n",
      "5     9501\n",
      "6     8621\n",
      "7     7231\n",
      "8     5569\n",
      "9     3947\n",
      "10    2772\n",
      "11    1817\n",
      "12    1112\n",
      "13     710\n",
      "14     416\n",
      "15     462\n",
      "16       0\n",
      "17       0\n",
      "18       0\n",
      "19       0\n",
      "20       0\n",
      "21       0\n",
      "22       0\n",
      "23       0\n",
      "24       0\n",
      "25       0\n",
      "26       0\n",
      "27       0\n",
      "28       0\n",
      "29       0\n",
      "30       0\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Contagem de ocorrências para y2:\n",
      "team2_corners\n",
      "0      1556\n",
      "1      4938\n",
      "2      8146\n",
      "3     10270\n",
      "4     10632\n",
      "5      9468\n",
      "6      7381\n",
      "7      5625\n",
      "8      3580\n",
      "9      2335\n",
      "10     1369\n",
      "11      847\n",
      "12      415\n",
      "13      283\n",
      "14      137\n",
      "15      104\n",
      "16        0\n",
      "17        0\n",
      "18        0\n",
      "19        0\n",
      "20        0\n",
      "21        0\n",
      "22        0\n",
      "23        0\n",
      "24        0\n",
      "25        0\n",
      "26        0\n",
      "27        0\n",
      "28        0\n",
      "29        0\n",
      "30        0\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contar ocorrências para 'y1'\n",
    "y1_counts = y1.value_counts().sort_index().reindex(range(0, 31), fill_value=0)\n",
    "print(\"Contagem de ocorrências para y1:\")\n",
    "print(y1_counts)\n",
    "\n",
    "# Contar ocorrências para 'y2'\n",
    "y2_counts = y2.value_counts().sort_index().reindex(range(0, 31), fill_value=0)\n",
    "print(\"\\nContagem de ocorrências para y2:\")\n",
    "print(y2_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separando o treino e o teste e a normalização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas variáveis abaixo estão sendo criadas de forma idêntica, apenas para ter significado semântico em relação "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Dividindo os dados com base na coluna 'season'\n",
    "X_train1 = X[X['season'] < 2022].drop(['team1', 'team2', 'championship', 'season'], axis=1)\n",
    "X_test1 = X[X['season'] >= 2022].drop(['team1', 'team2', 'championship', 'season'], axis=1)\n",
    "y_train1 = y1[X['season'] < 2022]\n",
    "y_test1 = y1[X['season'] >= 2022]\n",
    "\n",
    "X_train2 = X[X['season'] < 2022].drop(['team1', 'team2', 'championship', 'season'], axis=1)\n",
    "X_test2 = X[X['season'] >= 2022].drop(['team1', 'team2', 'championship', 'season'], axis=1)\n",
    "y_train2 = y2[X['season'] < 2022]\n",
    "y_test2 = y2[X['season'] >= 2022]\n",
    "\n",
    "# Escalando os dados\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustar o escalonador com base no conjunto de treinamento\n",
    "scaler.fit(X_train1)\n",
    "\n",
    "\n",
    "# Escalando apenas as colunas que você quer (ajuste isso conforme suas necessidades)\n",
    "cols_to_scale = [col for col in future_matches_calculado.columns if col not in ['team1', 'team2', 'championship']]\n",
    "scaler = StandardScaler().fit(X_train1[cols_to_scale])\n",
    "\n",
    "# Aplicar o escalonamento\n",
    "future_matches_calculado_scaled = future_matches_calculado.copy()\n",
    "future_matches_calculado_scaled[cols_to_scale] = scaler.transform(future_matches_calculado[cols_to_scale])\n",
    "\n",
    "# Agora, você pode usar future_matches_calculado_scaled para fazer previsões\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Transformar os conjuntos de treinamento e teste\n",
    "X_train1_scaled = scaler.transform(X_train1)\n",
    "X_test1_scaled = scaler.transform(X_test1)\n",
    "\n",
    "X_train2_scaled = scaler.transform(X_train2)\n",
    "X_test2_scaled = scaler.transform(X_test2)\n",
    "\n",
    "# Preparar as colunas para o embedding\n",
    "X_train1_embed = X[X['season'] < 2022][['team1', 'team2', 'championship']]\n",
    "X_test1_embed = X[X['season'] >= 2022][['team1', 'team2', 'championship']]\n",
    "\n",
    "X_train2_embed = X[X['season'] < 2022][['team1', 'team2', 'championship']]\n",
    "X_test2_embed = X[X['season'] >= 2022][['team1', 'team2', 'championship']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['team1_big_wins_last5',\n",
       " 'team1_big_losses_last5',\n",
       " 'team2_big_wins_last5',\n",
       " 'team2_big_losses_last5',\n",
       " 'team1_ah-2.5_wins_last5',\n",
       " 'team1_ah-2.5_losses_last5',\n",
       " 'team2_ah-2.5_wins_last5',\n",
       " 'team2_ah-2.5_losses_last5',\n",
       " 'team1_ah+2.5_wins_last5',\n",
       " 'team1_ah+2.5_losses_last5',\n",
       " 'team2_ah+2.5_wins_last5',\n",
       " 'team2_ah+2.5_losses_last5',\n",
       " 'team1_over3.5_last5',\n",
       " 'team1_under3.5_last5',\n",
       " 'team2_over3.5_last5',\n",
       " 'team2_under3.5_last5',\n",
       " 'team1_over4.5_last5',\n",
       " 'team1_under4.5_last5',\n",
       " 'team2_over4.5_last5',\n",
       " 'team2_under4.5_last5',\n",
       " 'team1_over6.5_last5',\n",
       " 'team1_under6.5_last5',\n",
       " 'team2_over6.5_last5',\n",
       " 'team2_under6.5_last5',\n",
       " 'avg_scr_lasts3_1_home',\n",
       " 'avg_scr_lasts5_1_home',\n",
       " 'avg_scr_lasts3_1_away',\n",
       " 'avg_scr_lasts5_1_away',\n",
       " 'avg_conc_lasts3_1_home',\n",
       " 'avg_conc_lasts5_1_home',\n",
       " 'avg_conc_lasts3_1_away',\n",
       " 'avg_conc_lasts5_1_away',\n",
       " 'avg_scr_lasts3_2_home',\n",
       " 'avg_scr_lasts5_2_home',\n",
       " 'avg_scr_lasts3_2_away',\n",
       " 'avg_scr_lasts5_2_away',\n",
       " 'avg_conc_lasts3_2_home',\n",
       " 'avg_conc_lasts5_2_home',\n",
       " 'avg_conc_lasts3_2_away',\n",
       " 'avg_conc_lasts5_2_away',\n",
       " 'avg_total_shots_lasts5_1_home',\n",
       " 'avg_total_shots_lasts5_1_away',\n",
       " 'avg_total_shots_lasts5_2_home',\n",
       " 'avg_total_shots_lasts5_2_away',\n",
       " 'avg_otarget_shots_lasts5_1_home',\n",
       " 'avg_otarget_shots_lasts5_1_away',\n",
       " 'avg_otarget_shots_lasts5_2_home',\n",
       " 'avg_otarget_shots_lasts5_2_away',\n",
       " 'avg_out_shots_lasts5_1_home',\n",
       " 'avg_out_shots_lasts5_1_away',\n",
       " 'avg_out_shots_lasts5_2_home',\n",
       " 'avg_out_shots_lasts5_2_away',\n",
       " 'avg_conc_total_shots_lasts5_1_home',\n",
       " 'avg_conc_total_shots_lasts5_1_away',\n",
       " 'avg_conc_total_shots_lasts5_2_home',\n",
       " 'avg_conc_total_shots_lasts5_2_away',\n",
       " 'avg_corners_lasts5_1_home',\n",
       " 'avg_corners_lasts5_1_away',\n",
       " 'avg_corners_conc_lasts5_1_home',\n",
       " 'avg_corners_conc_lasts5_1_away',\n",
       " 'avg_corners_lasts5_2_home',\n",
       " 'avg_corners_lasts5_2_away',\n",
       " 'avg_corners_conc_lasts5_2_home',\n",
       " 'avg_corners_conc_lasts5_2_away',\n",
       " 'avg_fouls_lasts5_1_home',\n",
       " 'avg_fouls_lasts5_1_away',\n",
       " 'avg_fouls_conc_lasts5_1_home',\n",
       " 'avg_fouls_conc_lasts5_1_away',\n",
       " 'avg_fouls_lasts5_2_home',\n",
       " 'avg_fouls_lasts5_2_away',\n",
       " 'avg_fouls_conc_lasts5_2_home',\n",
       " 'avg_fouls_conc_lasts5_2_away',\n",
       " 'avg_points_lasts5_1',\n",
       " 'avg_points_lasts5_2',\n",
       " 'championship_points_1',\n",
       " 'championship_points_2',\n",
       " 'rested_4_days_or_more_1',\n",
       " 'rested_4_days_or_more_2',\n",
       " 'team1_losing_streak',\n",
       " 'team1_strength',\n",
       " 'team1_undefeated_streak',\n",
       " 'team1_winning_streak',\n",
       " 'team1_without_winning_streak',\n",
       " 'team2_losing_streak',\n",
       " 'team2_strength',\n",
       " 'team2_undefeated_streak',\n",
       " 'team2_winning_streak',\n",
       " 'team2_without_winning_streak',\n",
       " 'team1_suspended_players',\n",
       " 'team2_suspended_players']"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_train1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61353, 92)\n",
      "(5733, 92)\n",
      "(61353,)\n",
      "(5733,)\n",
      "(61353, 92)\n",
      "(5733, 92)\n",
      "(61353,)\n",
      "(5733,)\n",
      "(61353, 3)\n",
      "(5733, 3)\n",
      "(61353, 3)\n",
      "(5733, 3)\n",
      "(18, 95)\n"
     ]
    }
   ],
   "source": [
    "print(X_train1_scaled.shape)\n",
    "print(X_test1_scaled.shape)\n",
    "print(y_train1.shape)\n",
    "print(y_test1.shape)\n",
    "print(X_train2_scaled.shape)\n",
    "print(X_test2_scaled.shape)\n",
    "print(y_train2.shape)\n",
    "print(y_test2.shape)\n",
    "print(X_train1_embed.shape)\n",
    "print(X_test1_embed.shape)\n",
    "print(X_train2_embed.shape)\n",
    "print(X_test2_embed.shape)\n",
    "print(future_matches_calculado_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função de perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, [-1])\n",
    "    y_pred = tf.reshape(y_pred, [-1])\n",
    "\n",
    "    avg = tf.reduce_mean(y_true)\n",
    "    abs_error = tf.abs(y_true - y_pred)\n",
    "    distance_to_avg = tf.abs(y_pred - avg)\n",
    "    reward = tf.math.log(distance_to_avg + 3)\n",
    "    penalty = 2 * abs_error / (distance_to_avg + 3)\n",
    "    \n",
    "    # Aplicando a função tanh ao resultado de (penalty - reward)\n",
    "    normalized_diff = tf.math.tanh(penalty - reward)\n",
    "    \n",
    "    # Somando com abs_error\n",
    "    custom_loss_value = abs_error + normalized_diff\n",
    "    \n",
    "    # Garantindo que o valor mínimo da perda seja 0.0001\n",
    "    custom_loss_value = tf.maximum(custom_loss_value, 0.0001)\n",
    "    \n",
    "    return tf.reduce_mean(custom_loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def custom_unified_loss(y_true, y_pred):\n",
    "    # Separar y_true e y_pred para cada time\n",
    "    y_true_team1, y_true_team2 = y_true[:, 0], y_true[:, 1]\n",
    "    y_pred_team1, y_pred_team2 = y_pred[:, 0], y_pred[:, 1]\n",
    "    \n",
    "    # Calcular a média para cada time\n",
    "    avg1 = tf.reduce_mean(y_true_team1)\n",
    "    avg2 = tf.reduce_mean(y_true_team2)\n",
    "\n",
    "    # Calcular o erro absoluto relativo para cada time\n",
    "    normalized_error_team1 = tf.abs(y_true[:, 0] - y_pred[:, 0]) \n",
    "    normalized_error_team2 = tf.abs(y_true[:, 1] - y_pred[:, 1]) *(avg1/avg2)\n",
    "    abs_error = (normalized_error_team1 + normalized_error_team2) / 2\n",
    "\n",
    "    #_val_mae_diff = np.mean(np.abs((val_predict[:, 0] - val_predict[:, 1]) - (val_targ[:, 0] - val_targ[:, 1])))\n",
    "       # ...\n",
    "    dif_prev = (y_pred_team1 - y_pred_team2)\n",
    "    dif_true = (y_true_team1 - y_true_team2)\n",
    "    \n",
    "    # Calcula a diferença absoluta entre as diferenças previstas e verdadeiras\n",
    "    abs_diff = tf.abs(dif_prev - dif_true)\n",
    "    \n",
    "    # Calcula um termo de bônus usando a função sigmoidal\n",
    "    bonus_term = tf.math.tanh(10 * (1 - abs_diff))\n",
    "    \n",
    "    # Se a diferença é maior ou igual a 4 (ou menor ou igual a -4), aplica um fator negativo\n",
    "    condition1 = tf.logical_and(dif_true >= 4, dif_prev >= 4)\n",
    "    condition2 = tf.logical_and(dif_true <= -4, dif_prev <= -4)\n",
    "    condition3 = abs_diff <= 1.5\n",
    "\n",
    "    final_condition = tf.logical_or(tf.logical_or(condition1, condition2), condition3)\n",
    "\n",
    "    abs_diff_acc = tf.where(final_condition, -1 * (abs_diff + bonus_term), abs_diff + bonus_term)\n",
    "\n",
    "\n",
    "    # Calcular a diferença entre as previsões para as médias\n",
    "    distance_to_avg1 = tf.abs(y_pred_team1 - avg1)\n",
    "    distance_to_avg2 = tf.abs(y_pred_team2 - avg2)\n",
    "    \n",
    "    # Calcular os rewards\n",
    "    reward1 = tf.math.log(distance_to_avg1 + 1)\n",
    "    reward2 = tf.math.log(distance_to_avg2 + 1)\n",
    "\n",
    "    # Calcular as penalties\n",
    "    penalty1 = 1 * normalized_error_team1 / (distance_to_avg1 + 1)\n",
    "    penalty2 = 1 * normalized_error_team2 / (distance_to_avg2 + 1)    \n",
    "\n",
    "    # Aplicando a função tanh ao resultado de (penalty - reward)\n",
    "    normalized_diff1 = tf.math.tanh(penalty1 - reward1)\n",
    "    normalized_diff2 = tf.math.tanh(penalty2 - reward2)\n",
    "    normalized_diff = tf.math.tanh((normalized_diff1 + normalized_diff2)/2)\n",
    "\n",
    "    # combined_error\n",
    "    combined_error = abs_error + abs_diff_acc + normalized_diff\n",
    "    \n",
    "    # Garantindo que o valor mínimo da perda seja 0.0001\n",
    "    combined_error_value = tf.maximum(combined_error, 0.0001)\n",
    "\n",
    "    return tf.reduce_mean(combined_error_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testes de funções de perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward1: [2.1282318], penalty1: [1.3095238], normalized_diff1: [-0.67436606]\n",
      "reward2: [0.9555114], penalty2: [2.207358], normalized_diff2: [0.8488007]\n",
      "bonus_term [-1.]--> abs_diff_acc: [14.], abs_error: [8.369565], normalized_diff: [0.08699685]\n",
      "y_true_team1: 3, y_pred_team1: 14, y_true_team2: 7, y_pred_team2: 3, Loss: 22.4566\n",
      "\n",
      "reward1: [0.8754688], penalty1: [1.6666666], normalized_diff1: [0.6590871]\n",
      "reward2: [2.1282318], penalty2: [1.0248448], normalized_diff2: [-0.80171233]\n",
      "bonus_term [-1.]--> abs_diff_acc: [1.], abs_error: [6.304348], normalized_diff: [-0.07119196]\n",
      "y_true_team1: 4, y_pred_team1: 8, y_true_team2: 6, y_pred_team2: 12, Loss: 7.2332\n",
      "\n",
      "reward1: [2.2407095], penalty1: [1.1702129], normalized_diff1: [-0.7896483]\n",
      "reward2: [2.3418057], penalty2: [1.2416389], normalized_diff2: [-0.800559]\n",
      "bonus_term [-1.]--> abs_diff_acc: [1.], abs_error: [11.956522], normalized_diff: [-0.6612906]\n",
      "y_true_team1: 4, y_pred_team1: 15, y_true_team2: 5, y_pred_team2: 14, Loss: 12.2952\n",
      "\n",
      "reward1: [1.2237755], penalty1: [1.7647058], normalized_diff1: [0.49369183]\n",
      "reward2: [1.856298], penalty2: [1.1209239], normalized_diff2: [-0.62634224]\n",
      "bonus_term [0.]--> abs_diff_acc: [-1.], abs_error: [6.5869565], normalized_diff: [-0.06622811]\n",
      "y_true_team1: 3, y_pred_team1: 9, y_true_team2: 5, y_pred_team2: 10, Loss: 5.5207\n",
      "\n",
      "reward1: [1.2237755], penalty1: [0.8823529], normalized_diff1: [-0.32874686]\n",
      "reward2: [1.5260563], penalty2: [3.4310021], normalized_diff2: [0.95665884]\n",
      "bonus_term [-1.]--> abs_diff_acc: [7.], abs_error: [9.391304], normalized_diff: [0.30403173]\n",
      "y_true_team1: 12, y_pred_team1: 9, y_true_team2: 12, y_pred_team2: 1, Loss: 16.6953\n",
      "\n",
      "reward1: [2.2407095], penalty1: [1.2765958], normalized_diff1: [-0.74610627]\n",
      "reward2: [0.3364723], penalty2: [2.0496893], normalized_diff2: [0.93704104]\n",
      "bonus_term [-1.]--> abs_diff_acc: [9.], abs_error: [7.4347825], normalized_diff: [0.0951784]\n",
      "y_true_team1: 3, y_pred_team1: 15, y_true_team2: 3, y_pred_team2: 5, Loss: 16.5300\n",
      "\n",
      "reward1: [1.4816046], penalty1: [1.8181818], normalized_diff1: [0.32441822]\n",
      "reward2: [0.9555114], penalty2: [1.6555185], normalized_diff2: [0.6043723]\n",
      "bonus_term [-1.]--> abs_diff_acc: [4.], abs_error: [6.152174], normalized_diff: [0.43365973]\n",
      "y_true_team1: 2, y_pred_team1: 10, y_true_team2: 0, y_pred_team2: 3, Loss: 10.5858\n",
      "\n",
      "reward1: [2.00148], penalty1: [1.2162162], normalized_diff1: [-0.6557177]\n",
      "reward2: [2.2407095], penalty2: [1.8316375], normalized_diff2: [-0.38768443]\n",
      "bonus_term [-1.]--> abs_diff_acc: [2.], abs_error: [13.108696], normalized_diff: [-0.47901183]\n",
      "y_true_team1: 4, y_pred_team1: 13, y_true_team2: 1, y_pred_team2: 13, Loss: 14.6297\n",
      "\n",
      "reward1: [1.4816046], penalty1: [0.], normalized_diff1: [-0.9017682]\n",
      "reward2: [0.9555114], penalty2: [1.6555185], normalized_diff2: [0.6043723]\n",
      "bonus_term [-1.]--> abs_diff_acc: [-2.], abs_error: [2.152174], normalized_diff: [-0.14761157]\n",
      "y_true_team1: 10, y_pred_team1: 10, y_true_team2: 6, y_pred_team2: 3, Loss: 0.0046\n",
      "\n",
      "reward1: [1.686399], penalty1: [2.037037], normalized_diff1: [0.33694115]\n",
      "reward2: [1.856298], penalty2: [2.2418478], normalized_diff2: [0.36751738]\n",
      "bonus_term [0.]--> abs_diff_acc: [-1.], abs_error: [12.673913], normalized_diff: [0.33835107]\n",
      "y_true_team1: 0, y_pred_team1: 11, y_true_team2: 0, y_pred_team2: 10, Loss: 12.0123\n",
      "\n",
      "reward1: [0.3364723], penalty1: [4.285714], normalized_diff1: [0.9992576]\n",
      "reward2: [1.7227666], penalty2: [2.8183231], normalized_diff2: [0.79889727]\n",
      "bonus_term [-1.]--> abs_diff_acc: [4.], abs_error: [10.891304], normalized_diff: [0.71584845]\n",
      "y_true_team1: 13, y_pred_team1: 7, y_true_team2: 11, y_pred_team2: 0, Loss: 15.6072\n",
      "\n",
      "reward1: [1.2809339], penalty1: [0.5555556], normalized_diff1: [-0.62022966]\n",
      "reward2: [0.3364723], penalty2: [2.0496893], normalized_diff2: [0.93704104]\n",
      "bonus_term [-1.]--> abs_diff_acc: [3.], abs_error: [2.4347825], normalized_diff: [0.15709391]\n",
      "y_true_team1: 6, y_pred_team1: 4, y_true_team2: 3, y_pred_team2: 5, Loss: 5.5919\n",
      "\n",
      "reward1: [2.0281482], penalty1: [0.65789473], normalized_diff1: [-0.8787499]\n",
      "reward2: [0.9555114], penalty2: [5.518395], normalized_diff2: [0.9997823]\n",
      "bonus_term [-1.]--> abs_diff_acc: [4.], abs_error: [9.673913], normalized_diff: [0.06044243]\n",
      "y_true_team1: 5, y_pred_team1: 0, y_true_team2: 13, y_pred_team2: 3, Loss: 13.7344\n",
      "\n",
      "reward1: [1.7227666], penalty1: [0.35714287], normalized_diff1: [-0.87769103]\n",
      "reward2: [2.00148], penalty2: [0.19388954], normalized_diff2: [-0.94758636]\n",
      "bonus_term [-1.]--> abs_diff_acc: [-2.], abs_error: [1.7173913], normalized_diff: [-0.7223964]\n",
      "y_true_team1: 0, y_pred_team1: 2, y_true_team2: 12, y_pred_team2: 11, Loss: 0.0001\n",
      "\n",
      "reward1: [1.7227666], penalty1: [1.6071429], normalized_diff1: [-0.11511119]\n",
      "reward2: [0.8754688], penalty2: [4.1847825], normalized_diff2: [0.99733305]\n",
      "bonus_term [-1.]--> abs_diff_acc: [1.], abs_error: [9.521739], normalized_diff: [0.41456488]\n",
      "y_true_team1: 11, y_pred_team1: 2, y_true_team2: 13, y_pred_team2: 6, Loss: 10.9363\n",
      "\n",
      "reward1: [1.2809339], penalty1: [0.], normalized_diff1: [-0.85673356]\n",
      "reward2: [1.2809339], penalty2: [0.7971015], normalized_diff2: [-0.44930756]\n",
      "bonus_term [-1.]--> abs_diff_acc: [1.], abs_error: [1.4347826], normalized_diff: [-0.5736999]\n",
      "y_true_team1: 4, y_pred_team1: 4, y_true_team2: 0, y_pred_team2: 2, Loss: 1.8611\n",
      "\n",
      "reward1: [0.3364723], penalty1: [0.], normalized_diff1: [-0.32432437]\n",
      "reward2: [1.856298], penalty2: [2.2418478], normalized_diff2: [0.36751738]\n",
      "bonus_term [-1.]--> abs_diff_acc: [9.], abs_error: [7.173913], normalized_diff: [0.02159315]\n",
      "y_true_team1: 7, y_pred_team1: 7, y_true_team2: 0, y_pred_team2: 10, Loss: 16.1955\n",
      "\n",
      "reward1: [1.8870696], penalty1: [1.0606061], normalized_diff1: [-0.67857254]\n",
      "reward2: [1.7227666], penalty2: [0.5124224], normalized_diff2: [-0.8367828]\n",
      "bonus_term [-1.]--> abs_diff_acc: [4.], abs_error: [4.9347825], normalized_diff: [-0.6397071]\n",
      "y_true_team1: 8, y_pred_team1: 1, y_true_team2: 2, y_pred_team2: 0, Loss: 8.2951\n",
      "\n",
      "reward1: [1.2237755], penalty1: [0.8823529], normalized_diff1: [-0.32874686]\n",
      "reward2: [0.3364723], penalty2: [2.0496893], normalized_diff2: [0.93704104]\n",
      "bonus_term [0.]--> abs_diff_acc: [-1.], abs_error: [2.9347825], normalized_diff: [0.29510316]\n",
      "y_true_team1: 6, y_pred_team1: 9, y_true_team2: 3, y_pred_team2: 5, Loss: 2.2299\n",
      "\n",
      "reward1: [0.47000358], penalty1: [0.], normalized_diff1: [-0.4382022]\n",
      "reward2: [1.5260563], penalty2: [0.31190926], normalized_diff2: [-0.8379192]\n",
      "bonus_term [0.]--> abs_diff_acc: [-1.], abs_error: [0.7173913], normalized_diff: [-0.56357765]\n",
      "y_true_team1: 6, y_pred_team1: 6, y_true_team2: 2, y_pred_team2: 1, Loss: 0.0001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def custom_unified_loss2(y_true, y_pred):\n",
    "    # Separar y_true e y_pred para cada time\n",
    "    y_true_team1, y_true_team2 = y_true[:, 0], y_true[:, 1]\n",
    "    y_pred_team1, y_pred_team2 = y_pred[:, 0], y_pred[:, 1]\n",
    "    \n",
    "    # Calcular a média para cada time\n",
    "    avg1 = 6.6\n",
    "    avg2 = 4.6\n",
    "\n",
    "    # Calcular o erro absoluto relativo para cada time\n",
    "    normalized_error_team1 = tf.abs(y_true[:, 0] - y_pred[:, 0]) \n",
    "    normalized_error_team2 = tf.abs(y_true[:, 1] - y_pred[:, 1]) *(avg1/avg2)\n",
    "    abs_error = (normalized_error_team1 + normalized_error_team2) / 2\n",
    "\n",
    "    #_val_mae_diff = np.mean(np.abs((val_predict[:, 0] - val_predict[:, 1]) - (val_targ[:, 0] - val_targ[:, 1])))\n",
    "       # ...\n",
    "    dif_prev = (y_pred_team1 - y_pred_team2)\n",
    "    dif_true = (y_true_team1 - y_true_team2)\n",
    "    \n",
    "    # Calcula a diferença absoluta entre as diferenças previstas e verdadeiras\n",
    "    abs_diff = tf.abs(dif_prev - dif_true)\n",
    "    \n",
    "    # Calcula um termo de bônus usando a função sigmoidal\n",
    "    bonus_term = tf.math.tanh(10 * (1 - abs_diff))\n",
    "    \n",
    "    # Se a diferença é maior ou igual a 4 (ou menor ou igual a -4), aplica um fator negativo\n",
    "    if (dif_true >= 4 and dif_prev >= 4) or (dif_true <= -4 and dif_prev <= -4) or (abs_diff <= 1.5):\n",
    "        abs_diff_acc = -1 * (abs_diff + bonus_term)\n",
    "    else:\n",
    "        abs_diff_acc = abs_diff + bonus_term\n",
    "\n",
    "\n",
    "    # Calcular a diferença entre as previsões para as médias\n",
    "    distance_to_avg1 = tf.abs(y_pred_team1 - avg1)\n",
    "    distance_to_avg2 = tf.abs(y_pred_team2 - avg2)\n",
    "    \n",
    "    # Calcular os rewards\n",
    "    reward1 = tf.math.log(distance_to_avg1 + 1)\n",
    "    reward2 = tf.math.log(distance_to_avg2 + 1)\n",
    "\n",
    "    # Calcular as penalties\n",
    "    penalty1 = 1 * normalized_error_team1 / (distance_to_avg1 + 1)\n",
    "    penalty2 = 1 * normalized_error_team2 / (distance_to_avg2 + 1)    \n",
    "\n",
    "    # Aplicando a função tanh ao resultado de (penalty - reward)\n",
    "    normalized_diff1 = tf.math.tanh(penalty1 - reward1)\n",
    "    normalized_diff2 = tf.math.tanh(penalty2 - reward2)\n",
    "    normalized_diff = tf.math.tanh((normalized_diff1 + normalized_diff2)/2)\n",
    "\n",
    "    # Print rewards, penalties, and normalized_diff\n",
    "    print(f\"reward1: {reward1.numpy()}, penalty1: {penalty1.numpy()}, normalized_diff1: {normalized_diff1.numpy()}\")\n",
    "    print(f\"reward2: {reward2.numpy()}, penalty2: {penalty2.numpy()}, normalized_diff2: {normalized_diff2.numpy()}\")\n",
    "    print(f\"bonus_term {bonus_term.numpy()}--> abs_diff_acc: {abs_diff_acc.numpy()}, abs_error: {abs_error.numpy()}, normalized_diff: {normalized_diff.numpy()}\")  # Novo valor impresso\n",
    "\n",
    "\n",
    "    # combined_error\n",
    "    combined_error = abs_error + abs_diff_acc + normalized_diff\n",
    "    \n",
    "    # Garantindo que o valor mínimo da perda seja 0.0001\n",
    "    combined_error_value = tf.maximum(combined_error, 0.0001)\n",
    "\n",
    "    return tf.reduce_mean(combined_error_value)\n",
    "\n",
    "# Loop para gerar valores aleatórios e calcular a perda\n",
    "for _ in range(20):\n",
    "    # Gerando valores aleatórios para y_true e y_pred\n",
    "    y_true_sample = np.random.randint(0, 16, size=(1, 2))\n",
    "    y_pred_sample = np.random.randint(0, 16, size=(1, 2))\n",
    "    \n",
    "    # Convertendo para tensores do TensorFlow\n",
    "    y_true_tensor = tf.convert_to_tensor(y_true_sample, dtype=tf.float32)\n",
    "    y_pred_tensor = tf.convert_to_tensor(y_pred_sample, dtype=tf.float32)\n",
    "    \n",
    "    # Calculando a perda\n",
    "    loss_value = custom_unified_loss2(y_true_tensor, y_pred_tensor).numpy()\n",
    "    \n",
    "    # Imprimindo os resultados\n",
    "    print(f\"y_true_team1: {y_true_sample[0][0]}, y_pred_team1: {y_pred_sample[0][0]}, y_true_team2: {y_true_sample[0][1]}, y_pred_team2: {y_pred_sample[0][1]}, Loss: {loss_value:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenando ambos Ys em um único tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61353, 3)\n",
      "(5733, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Suponha que y_train1 e y_train2 são seus vetores de saída originais\n",
    "# Eles têm o shape (comprimento,)\n",
    "\n",
    "# Calcular a diferença entre y_train1 e y_train2\n",
    "y_train_diff = y_train1 - y_train2\n",
    "y_test_diff = y_test1 - y_test2\n",
    "# Concatenar ao longo de uma nova dimensão para criar um tensor de saída com shape (comprimento, 3)\n",
    "y_train_combined = np.stack((y_train1, y_train2, y_train_diff), axis=-1)\n",
    "y_test_combined = np.stack((y_test1, y_test2, y_test_diff), axis=-1)\n",
    "\n",
    "\n",
    "print(y_train_combined.shape)\n",
    "print(y_test_combined.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arquitetura da NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ==== Parte 1: Definindo os Inputs para o Embedding ====\n",
    "# Estes são os inputs que vão alimentar os embeddings. \n",
    "# Cada input tem a dimensão de (1,) porque cada jogo tem exatamente um 'team1', um 'team2', e um 'championship'.\n",
    "team1_input = Input(shape=(1,), name='Team1-Input')\n",
    "team2_input = Input(shape=(1,), name='Team2-Input')\n",
    "champ_input = Input(shape=(1,), name='Championship-Input')\n",
    "\n",
    "# ==== Parte 2: Criando os Embeddings ====\n",
    "# n_teams e n_champ são o número de times e campeonatos únicos, respectivamente.\n",
    "# O output_dim é um hiperparâmetro para você ajustar. Ele define o tamanho do espaço de embedding.\n",
    "\n",
    "# Embedding para o time 1\n",
    "team1_embedding = Embedding(input_dim=n_teams, output_dim=50, name='Team1-Embedding')(team1_input)  # output_dim ajustável\n",
    "\n",
    "# Embedding para o time 2\n",
    "team2_embedding = Embedding(input_dim=n_teams, output_dim=50, name='Team2-Embedding')(team2_input)  # output_dim ajustável\n",
    "\n",
    "# Embedding para o campeonato\n",
    "champ_embedding = Embedding(input_dim=n_champ, output_dim=5, name='Championship-Embedding')(champ_input)  # output_dim ajustável\n",
    "\n",
    "# ==== Parte 3: Achatando os Embeddings ====\n",
    "# Cada embedding precisa ser achatado para ser concatenado posteriormente\n",
    "team1_embedding = Flatten()(team1_embedding)\n",
    "team2_embedding = Flatten()(team2_embedding)\n",
    "champ_embedding = Flatten()(champ_embedding)\n",
    "\n",
    "# ==== Parte 4: Outras Características ====\n",
    "# Este é o input para as outras características (já escaladas) do seu conjunto de dados.\n",
    "other_features_input = Input(shape=(X_train1_scaled.shape[1],), name='Other-Features-Input')\n",
    "\n",
    "# ==== Parte 5: Concatenando Tudo ====\n",
    "# Aqui, todos os embeddings e as outras características são concatenados em um único vetor\n",
    "merged = Concatenate()([team1_embedding, team2_embedding, champ_embedding, other_features_input])\n",
    "\n",
    "# ==== Parte 6: Camadas Ocultas ====\n",
    "# Estes são os neurônios e camadas totalmente conectadas (Dense) onde a \"aprendizagem\" real acontece.\n",
    "# Você pode ajustar o número de neurônios, a função de ativação, e outros hiperparâmetros aqui.\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "hidden_layer = Dense(1024, activation='relu', kernel_regularizer=l2(0.0001))(merged)\n",
    "hidden_layer = Dropout(0.2)(hidden_layer)\n",
    "\n",
    "hidden_layer = Dense(512, activation='tanh')(hidden_layer)\n",
    "hidden_layer = Dropout(0.2)(hidden_layer)\n",
    "\n",
    "hidden_layer = Dense(256, activation='tanh')(hidden_layer)\n",
    "hidden_layer = Dropout(0.2)(hidden_layer)\n",
    "\n",
    "hidden_layer = Dense(128, activation='tanh')(hidden_layer)\n",
    "hidden_layer = Dropout(0.2)(hidden_layer)\n",
    "\n",
    "hidden_layer = Dense(64, activation='tanh')(hidden_layer)\n",
    "hidden_layer = Dropout(0.2)(hidden_layer)\n",
    "\n",
    "hidden_layer = Dense(32, activation='tanh')(hidden_layer)\n",
    "hidden_layer = Dropout(0.2)(hidden_layer)\n",
    "\n",
    "#hidden_layer = Dense(8, activation='tanh')(hidden_layer)\n",
    "#hidden_layer = Dropout(0.2)(hidden_layer)\n",
    "\n",
    "# ==== Parte 7: Camada de Saída ====\n",
    "# Esta é a camada de saída. A função de ativação 'linear' é usada para regressão.\n",
    "output = Dense(3, activation='linear', name='Output-Layer')(hidden_layer)\n",
    "\n",
    "# ==== Parte 8: Compilando o Modelo ====\n",
    "# Finalmente, o modelo é compilado. O otimizador Adam é usado, com uma taxa de aprendizagem de 0.001.\n",
    "# A perda é definida como 'mean_squared_error', que é comum para problemas de regressão.\n",
    "model = Model(\n",
    "    inputs=[team1_input, team2_input, champ_input, other_features_input], \n",
    "    outputs=[output]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "480/480 [==============================] - 15s 28ms/step - loss: 4.9330 - mean_absolute_error: 2.7715 - val_loss: 4.6751 - val_mean_absolute_error: 2.5863\n",
      "180/180 [==============================] - 1s 6ms/step\n",
      " - val_mae_team1: 2.2590 - val_mae_team2: 2.0115 - val_mae_diff: 3.2161 - val_mae_diff_output: 3.4883\n",
      "Epoch 2/100\n",
      "480/480 [==============================] - 12s 26ms/step - loss: 4.7897 - mean_absolute_error: 2.6832 - val_loss: 4.7139 - val_mean_absolute_error: 2.5792\n",
      "180/180 [==============================] - 1s 5ms/step\n",
      " - val_mae_team1: 2.2547 - val_mae_team2: 1.9749 - val_mae_diff: 3.2368 - val_mae_diff_output: 3.5081\n",
      "Epoch 3/100\n",
      "480/480 [==============================] - 12s 25ms/step - loss: 4.7190 - mean_absolute_error: 2.6438 - val_loss: 4.6811 - val_mean_absolute_error: 2.5537\n",
      "180/180 [==============================] - 1s 5ms/step\n",
      " - val_mae_team1: 2.2515 - val_mae_team2: 1.9791 - val_mae_diff: 3.2417 - val_mae_diff_output: 3.4303\n",
      "Epoch 4/100\n",
      "480/480 [==============================] - 12s 25ms/step - loss: 4.7058 - mean_absolute_error: 2.6269 - val_loss: 4.6846 - val_mean_absolute_error: 2.5485\n",
      "180/180 [==============================] - 1s 5ms/step\n",
      " - val_mae_team1: 2.2652 - val_mae_team2: 1.9849 - val_mae_diff: 3.2664 - val_mae_diff_output: 3.3954\n",
      "Epoch 5/100\n",
      "480/480 [==============================] - 12s 25ms/step - loss: 4.6780 - mean_absolute_error: 2.6166 - val_loss: 4.6640 - val_mean_absolute_error: 2.5544\n",
      "180/180 [==============================] - 1s 5ms/step\n",
      " - val_mae_team1: 2.2867 - val_mae_team2: 1.9914 - val_mae_diff: 3.2407 - val_mae_diff_output: 3.3852\n",
      "Epoch 6/100\n",
      "480/480 [==============================] - 12s 25ms/step - loss: 4.6545 - mean_absolute_error: 2.6131 - val_loss: 4.6454 - val_mean_absolute_error: 2.5529\n",
      "180/180 [==============================] - 1s 5ms/step\n",
      " - val_mae_team1: 2.2353 - val_mae_team2: 2.0130 - val_mae_diff: 3.2340 - val_mae_diff_output: 3.4103\n",
      "Epoch 7/100\n",
      "480/480 [==============================] - 12s 24ms/step - loss: 4.6432 - mean_absolute_error: 2.6104 - val_loss: 4.6633 - val_mean_absolute_error: 2.5640\n",
      "180/180 [==============================] - 1s 5ms/step\n",
      " - val_mae_team1: 2.2712 - val_mae_team2: 1.9916 - val_mae_diff: 3.2579 - val_mae_diff_output: 3.4291\n",
      "Epoch 8/100\n",
      "480/480 [==============================] - 12s 24ms/step - loss: 4.6399 - mean_absolute_error: 2.6130 - val_loss: 4.6628 - val_mean_absolute_error: 2.5555\n",
      "180/180 [==============================] - 1s 5ms/step\n",
      " - val_mae_team1: 2.2446 - val_mae_team2: 2.0105 - val_mae_diff: 3.2325 - val_mae_diff_output: 3.4115\n",
      "Epoch 9/100\n",
      "480/480 [==============================] - 11s 24ms/step - loss: 4.6184 - mean_absolute_error: 2.6082 - val_loss: 4.6828 - val_mean_absolute_error: 2.5623\n",
      "180/180 [==============================] - 1s 5ms/step\n",
      " - val_mae_team1: 2.2465 - val_mae_team2: 2.0405 - val_mae_diff: 3.2458 - val_mae_diff_output: 3.3998\n",
      "Epoch 10/100\n",
      "480/480 [==============================] - 12s 24ms/step - loss: 4.6101 - mean_absolute_error: 2.6058 - val_loss: 4.6578 - val_mean_absolute_error: 2.5579\n",
      "180/180 [==============================] - 1s 5ms/step\n",
      " - val_mae_team1: 2.2376 - val_mae_team2: 2.0298 - val_mae_diff: 3.2380 - val_mae_diff_output: 3.4062\n",
      "Epoch 11/100\n",
      "480/480 [==============================] - 12s 24ms/step - loss: 4.6152 - mean_absolute_error: 2.6071 - val_loss: 4.6700 - val_mean_absolute_error: 2.5519\n",
      "180/180 [==============================] - 1s 5ms/step\n",
      " - val_mae_team1: 2.2465 - val_mae_team2: 2.0161 - val_mae_diff: 3.2498 - val_mae_diff_output: 3.3930\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "# Parâmetros para Early Stopping\n",
    "patience = 10\n",
    "best_val_mae_diff = np.inf\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "# Número de épocas\n",
    "n_epochs = 100\n",
    "\n",
    "# Compilando o modelo unificado\n",
    "model.compile(optimizer=Adam(0.001), loss=custom_unified_loss, metrics=['mean_absolute_error'])\n",
    "\n",
    "# Loop de treinamento\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "    \n",
    "    # Treinamento para uma época\n",
    "    history = model.fit(\n",
    "        [X_train1_embed['team1'], X_train1_embed['team2'], X_train1_embed['championship'], X_train1_scaled], \n",
    "        y_train_combined, \n",
    "        epochs=1,\n",
    "        batch_size=128,\n",
    "        verbose=1,\n",
    "        validation_data=([X_test1_embed['team1'], X_test1_embed['team2'], X_test1_embed['championship'], X_test1_scaled], y_test_combined)\n",
    "    )\n",
    "    \n",
    "    # Calculando métricas adicionais\n",
    "    val_predict = model.predict([X_test1_embed['team1'], X_test1_embed['team2'], X_test1_embed['championship'], X_test1_scaled])\n",
    "    val_targ = y_test_combined\n",
    "\n",
    "    _val_mae_team1 = np.mean(np.abs(val_predict[:, 0] - val_targ[:, 0]))\n",
    "    _val_mae_team2 = np.mean(np.abs(val_predict[:, 1] - val_targ[:, 1]))\n",
    "    _val_mae_diff = np.mean(np.abs((val_predict[:, 0] - val_predict[:, 1]) - (val_targ[:, 0] - val_targ[:, 1])))\n",
    "    _val_mae_diff_output = np.mean(np.abs(val_predict[:, 2] - val_targ[:, 2]))  # Nova métrica para a terceira saída\n",
    "\n",
    "    print(f\" - val_mae_team1: {_val_mae_team1:.4f} - val_mae_team2: {_val_mae_team2:.4f} - val_mae_diff: {_val_mae_diff:.4f} - val_mae_diff_output: {_val_mae_diff_output:.4f}\")\n",
    "\n",
    "    # Lógica de Early Stopping\n",
    "    if _val_mae_diff < best_val_mae_diff:\n",
    "        best_val_mae_diff = _val_mae_diff\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1901447772979736\n",
    "#1.996545672416687"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 95)"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_matches_calculado_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>team1_goals</th>\n",
       "      <th>team2_goals</th>\n",
       "      <th>championship</th>\n",
       "      <th>team1_big_wins_last5</th>\n",
       "      <th>team1_big_losses_last5</th>\n",
       "      <th>team2_big_wins_last5</th>\n",
       "      <th>team2_big_losses_last5</th>\n",
       "      <th>team1_ah-2.5_wins_last5</th>\n",
       "      <th>...</th>\n",
       "      <th>team1_undefeated_streak</th>\n",
       "      <th>team1_winning_streak</th>\n",
       "      <th>team1_without_winning_streak</th>\n",
       "      <th>team2_losing_streak</th>\n",
       "      <th>team2_strength</th>\n",
       "      <th>team2_undefeated_streak</th>\n",
       "      <th>team2_winning_streak</th>\n",
       "      <th>team2_without_winning_streak</th>\n",
       "      <th>team1_suspended_players</th>\n",
       "      <th>team2_suspended_players</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>475</td>\n",
       "      <td>485</td>\n",
       "      <td>-1.192433</td>\n",
       "      <td>-1.036144</td>\n",
       "      <td>1</td>\n",
       "      <td>1.257310</td>\n",
       "      <td>-0.986648</td>\n",
       "      <td>-0.939662</td>\n",
       "      <td>-0.950273</td>\n",
       "      <td>-0.333442</td>\n",
       "      <td>...</td>\n",
       "      <td>1.228464</td>\n",
       "      <td>-0.478941</td>\n",
       "      <td>-0.389724</td>\n",
       "      <td>-0.525751</td>\n",
       "      <td>-1.372864</td>\n",
       "      <td>1.143038</td>\n",
       "      <td>-0.569612</td>\n",
       "      <td>-0.314683</td>\n",
       "      <td>-0.334677</td>\n",
       "      <td>-0.305174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>482</td>\n",
       "      <td>492</td>\n",
       "      <td>-1.192433</td>\n",
       "      <td>-1.036144</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.907378</td>\n",
       "      <td>0.123596</td>\n",
       "      <td>-0.939662</td>\n",
       "      <td>0.184672</td>\n",
       "      <td>0.596325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006032</td>\n",
       "      <td>0.327638</td>\n",
       "      <td>-0.759254</td>\n",
       "      <td>1.364236</td>\n",
       "      <td>-1.075121</td>\n",
       "      <td>-0.661135</td>\n",
       "      <td>-0.569612</td>\n",
       "      <td>2.313513</td>\n",
       "      <td>-0.334677</td>\n",
       "      <td>-0.305174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>486</td>\n",
       "      <td>477</td>\n",
       "      <td>-1.192433</td>\n",
       "      <td>-1.036144</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.907378</td>\n",
       "      <td>-0.986648</td>\n",
       "      <td>-0.939662</td>\n",
       "      <td>-0.950273</td>\n",
       "      <td>-1.263209</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.605184</td>\n",
       "      <td>-0.478941</td>\n",
       "      <td>-0.389724</td>\n",
       "      <td>-0.525751</td>\n",
       "      <td>-0.157732</td>\n",
       "      <td>-0.360440</td>\n",
       "      <td>-0.569612</td>\n",
       "      <td>1.562600</td>\n",
       "      <td>2.587813</td>\n",
       "      <td>-0.305174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>498</td>\n",
       "      <td>478</td>\n",
       "      <td>-1.192433</td>\n",
       "      <td>-1.036144</td>\n",
       "      <td>1</td>\n",
       "      <td>0.174966</td>\n",
       "      <td>0.123596</td>\n",
       "      <td>0.117516</td>\n",
       "      <td>1.319616</td>\n",
       "      <td>1.526092</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.605184</td>\n",
       "      <td>-0.478941</td>\n",
       "      <td>-0.020195</td>\n",
       "      <td>1.364236</td>\n",
       "      <td>-0.252980</td>\n",
       "      <td>-0.661135</td>\n",
       "      <td>-0.569612</td>\n",
       "      <td>0.060774</td>\n",
       "      <td>-0.334677</td>\n",
       "      <td>-0.305174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>495</td>\n",
       "      <td>488</td>\n",
       "      <td>-1.192433</td>\n",
       "      <td>-1.036144</td>\n",
       "      <td>18</td>\n",
       "      <td>0.174966</td>\n",
       "      <td>0.123596</td>\n",
       "      <td>0.117516</td>\n",
       "      <td>-0.950273</td>\n",
       "      <td>-0.333442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.605184</td>\n",
       "      <td>-0.478941</td>\n",
       "      <td>-0.389724</td>\n",
       "      <td>-0.525751</td>\n",
       "      <td>-0.337596</td>\n",
       "      <td>-0.059744</td>\n",
       "      <td>-0.569612</td>\n",
       "      <td>-0.314683</td>\n",
       "      <td>-0.334677</td>\n",
       "      <td>-0.305174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     team1  team2  team1_goals  team2_goals  championship  \\\n",
       "190    475    485    -1.192433    -1.036144             1   \n",
       "189    482    492    -1.192433    -1.036144             1   \n",
       "197    486    477    -1.192433    -1.036144             1   \n",
       "192    498    478    -1.192433    -1.036144             1   \n",
       "524    495    488    -1.192433    -1.036144            18   \n",
       "\n",
       "     team1_big_wins_last5  team1_big_losses_last5  team2_big_wins_last5  \\\n",
       "190              1.257310               -0.986648             -0.939662   \n",
       "189             -0.907378                0.123596             -0.939662   \n",
       "197             -0.907378               -0.986648             -0.939662   \n",
       "192              0.174966                0.123596              0.117516   \n",
       "524              0.174966                0.123596              0.117516   \n",
       "\n",
       "     team2_big_losses_last5  team1_ah-2.5_wins_last5  ...  \\\n",
       "190               -0.950273                -0.333442  ...   \n",
       "189                0.184672                 0.596325  ...   \n",
       "197               -0.950273                -1.263209  ...   \n",
       "192                1.319616                 1.526092  ...   \n",
       "524               -0.950273                -0.333442  ...   \n",
       "\n",
       "     team1_undefeated_streak  team1_winning_streak  \\\n",
       "190                 1.228464             -0.478941   \n",
       "189                 0.006032              0.327638   \n",
       "197                -0.605184             -0.478941   \n",
       "192                -0.605184             -0.478941   \n",
       "524                -0.605184             -0.478941   \n",
       "\n",
       "     team1_without_winning_streak  team2_losing_streak  team2_strength  \\\n",
       "190                     -0.389724            -0.525751       -1.372864   \n",
       "189                     -0.759254             1.364236       -1.075121   \n",
       "197                     -0.389724            -0.525751       -0.157732   \n",
       "192                     -0.020195             1.364236       -0.252980   \n",
       "524                     -0.389724            -0.525751       -0.337596   \n",
       "\n",
       "     team2_undefeated_streak  team2_winning_streak  \\\n",
       "190                 1.143038             -0.569612   \n",
       "189                -0.661135             -0.569612   \n",
       "197                -0.360440             -0.569612   \n",
       "192                -0.661135             -0.569612   \n",
       "524                -0.059744             -0.569612   \n",
       "\n",
       "     team2_without_winning_streak  team1_suspended_players  \\\n",
       "190                     -0.314683                -0.334677   \n",
       "189                      2.313513                -0.334677   \n",
       "197                      1.562600                 2.587813   \n",
       "192                      0.060774                -0.334677   \n",
       "524                     -0.314683                -0.334677   \n",
       "\n",
       "     team2_suspended_players  \n",
       "190                -0.305174  \n",
       "189                -0.305174  \n",
       "197                -0.305174  \n",
       "192                -0.305174  \n",
       "524                -0.305174  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_matches_calculado_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 126ms/step\n",
      "Prediction for corinthians: 4.090848922729492 corners\n",
      "Prediction for goiás: 3.4415998458862305 corners\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prediction for flamengo: 6.877560138702393 corners\n",
      "Prediction for internacional: 3.2001960277557373 corners\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Prediction for grêmio: 4.088830471038818 corners\n",
      "Prediction for cruzeiro: 3.534945487976074 corners\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Prediction for red bull bragantino: 6.877573490142822 corners\n",
      "Prediction for cuiabá: 3.200420618057251 corners\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prediction for mjallby: 4.062017440795898 corners\n",
      "Prediction for hammarby if: 5.899352550506592 corners\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prediction for atlético mineiro: 6.877467155456543 corners\n",
      "Prediction for santos: 3.2008495330810547 corners\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prediction for ifk gotemburgo: 4.152868747711182 corners\n",
      "Prediction for bk hacken: 3.849923610687256 corners\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Prediction for djurgardens if: 6.871236324310303 corners\n",
      "Prediction for degerfors if: 3.2050588130950928 corners\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prediction for fortaleza: 5.021853446960449 corners\n",
      "Prediction for coritiba: 2.7347092628479004 corners\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Prediction for ifk varnamo: 4.203769207000732 corners\n",
      "Prediction for halmstad: 3.289109706878662 corners\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prediction for athletico-pr: 4.1214985847473145 corners\n",
      "Prediction for fluminense: 3.437407970428467 corners\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prediction for palmeiras: 6.87525749206543 corners\n",
      "Prediction for vasco da gama: 3.20210862159729 corners\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Prediction for américa-mg: 4.015212059020996 corners\n",
      "Prediction for são paulo: 5.95165491104126 corners\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Prediction for botafogo: 6.876049995422363 corners\n",
      "Prediction for bahia: 3.203187942504883 corners\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prediction for brommapojkarna: 5.606142520904541 corners\n",
      "Prediction for kalmar: 3.2565348148345947 corners\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prediction for ik sirius: 3.9699723720550537 corners\n",
      "Prediction for malmo: 5.989296913146973 corners\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Prediction for elfsborg: 6.877551555633545 corners\n",
      "Prediction for norrkoping: 3.2002737522125244 corners\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Prediction for aik: 5.901612281799316 corners\n",
      "Prediction for varbergs bois fc: 3.4404537677764893 corners\n",
      "Corner Predictions: {'corinthians': 4.090849, 'goiás': 3.4415998, 'flamengo': 6.87756, 'internacional': 3.200196, 'grêmio': 4.0888305, 'cruzeiro': 3.5349455, 'red bull bragantino': 6.8775735, 'cuiabá': 3.2004206, 'mjallby': 4.0620174, 'hammarby if': 5.8993526, 'atlético mineiro': 6.877467, 'santos': 3.2008495, 'ifk gotemburgo': 4.1528687, 'bk hacken': 3.8499236, 'djurgardens if': 6.8712363, 'degerfors if': 3.2050588, 'fortaleza': 5.0218534, 'coritiba': 2.7347093, 'ifk varnamo': 4.203769, 'halmstad': 3.2891097, 'athletico-pr': 4.1214986, 'fluminense': 3.437408, 'palmeiras': 6.8752575, 'vasco da gama': 3.2021086, 'américa-mg': 4.015212, 'são paulo': 5.951655, 'botafogo': 6.87605, 'bahia': 3.203188, 'brommapojkarna': 5.6061425, 'kalmar': 3.2565348, 'ik sirius': 3.9699724, 'malmo': 5.989297, 'elfsborg': 6.8775516, 'norrkoping': 3.2002738, 'aik': 5.9016123, 'varbergs bois fc': 3.4404538}\n"
     ]
    }
   ],
   "source": [
    "# Inicializando um dicionário vazio para armazenar as previsões\n",
    "corner_predictions = {}\n",
    "\n",
    "# Iterar sobre cada linha em 'future_matches' e 'future_matches_calculado_scaled'\n",
    "for (index1, row1), (index2, row2) in zip(future_matches.iterrows(), future_matches_calculado_scaled.iterrows()):\n",
    "    # Prepare os dados de entrada para a previsão\n",
    "    team1_input_data = np.array([[row2['team1']]], dtype=np.float32)\n",
    "    team2_input_data = np.array([[row2['team2']]], dtype=np.float32)\n",
    "    champ_input_data = np.array([[row2['championship']]], dtype=np.float32)\n",
    "    \n",
    "    # Certifique-se de que 'other_features_data' contém todas as outras características na mesma ordem que foram usadas para treinar o modelo\n",
    "    other_features_data = np.array([row2.drop(['team1', 'team2', 'championship']).astype(np.float32)])\n",
    "    \n",
    "    # Faça a previsão usando o modelo unificado\n",
    "    pred = model.predict([team1_input_data, team2_input_data, champ_input_data, other_features_data])\n",
    "    \n",
    "    # As previsões para ambos os times estão na mesma saída, então vamos separá-las\n",
    "    pred_team1, pred_team2 = pred[0][0], pred[0][1]\n",
    "    \n",
    "    # Armazenar as previsões no dicionário\n",
    "    corner_predictions[row1['team1']] = pred_team1\n",
    "    corner_predictions[row1['team2']] = pred_team2\n",
    "    \n",
    "    # Imprimir as previsões\n",
    "    print(f\"Prediction for {row1['team1']}: {pred_team1} corners\")\n",
    "    print(f\"Prediction for {row1['team2']}: {pred_team2} corners\")\n",
    "\n",
    "# Exibindo o dicionário de previsões\n",
    "print(\"Corner Predictions:\", corner_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team1_name</th>\n",
       "      <th>Team1_prediction</th>\n",
       "      <th>Team2_name</th>\n",
       "      <th>Team2_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>corinthians</td>\n",
       "      <td>4.090849</td>\n",
       "      <td>goiás</td>\n",
       "      <td>3.441600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flamengo</td>\n",
       "      <td>6.877560</td>\n",
       "      <td>internacional</td>\n",
       "      <td>3.200196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>grêmio</td>\n",
       "      <td>4.088830</td>\n",
       "      <td>cruzeiro</td>\n",
       "      <td>3.534945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>red bull bragantino</td>\n",
       "      <td>6.877573</td>\n",
       "      <td>cuiabá</td>\n",
       "      <td>3.200421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mjallby</td>\n",
       "      <td>4.062017</td>\n",
       "      <td>hammarby if</td>\n",
       "      <td>5.899353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>atlético mineiro</td>\n",
       "      <td>6.877467</td>\n",
       "      <td>santos</td>\n",
       "      <td>3.200850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ifk gotemburgo</td>\n",
       "      <td>4.152869</td>\n",
       "      <td>bk hacken</td>\n",
       "      <td>3.849924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>djurgardens if</td>\n",
       "      <td>6.871236</td>\n",
       "      <td>degerfors if</td>\n",
       "      <td>3.205059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fortaleza</td>\n",
       "      <td>5.021853</td>\n",
       "      <td>coritiba</td>\n",
       "      <td>2.734709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ifk varnamo</td>\n",
       "      <td>4.203769</td>\n",
       "      <td>halmstad</td>\n",
       "      <td>3.289110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>athletico-pr</td>\n",
       "      <td>4.121499</td>\n",
       "      <td>fluminense</td>\n",
       "      <td>3.437408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>palmeiras</td>\n",
       "      <td>6.875257</td>\n",
       "      <td>vasco da gama</td>\n",
       "      <td>3.202109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>américa-mg</td>\n",
       "      <td>4.015212</td>\n",
       "      <td>são paulo</td>\n",
       "      <td>5.951655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>botafogo</td>\n",
       "      <td>6.876050</td>\n",
       "      <td>bahia</td>\n",
       "      <td>3.203188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>brommapojkarna</td>\n",
       "      <td>5.606143</td>\n",
       "      <td>kalmar</td>\n",
       "      <td>3.256535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ik sirius</td>\n",
       "      <td>3.969972</td>\n",
       "      <td>malmo</td>\n",
       "      <td>5.989297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>elfsborg</td>\n",
       "      <td>6.877552</td>\n",
       "      <td>norrkoping</td>\n",
       "      <td>3.200274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aik</td>\n",
       "      <td>5.901612</td>\n",
       "      <td>varbergs bois fc</td>\n",
       "      <td>3.440454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Team1_name  Team1_prediction        Team2_name  Team2_prediction\n",
       "0           corinthians          4.090849             goiás          3.441600\n",
       "1              flamengo          6.877560     internacional          3.200196\n",
       "2                grêmio          4.088830          cruzeiro          3.534945\n",
       "3   red bull bragantino          6.877573            cuiabá          3.200421\n",
       "4               mjallby          4.062017       hammarby if          5.899353\n",
       "5      atlético mineiro          6.877467            santos          3.200850\n",
       "6        ifk gotemburgo          4.152869         bk hacken          3.849924\n",
       "7        djurgardens if          6.871236      degerfors if          3.205059\n",
       "8             fortaleza          5.021853          coritiba          2.734709\n",
       "9           ifk varnamo          4.203769          halmstad          3.289110\n",
       "10         athletico-pr          4.121499        fluminense          3.437408\n",
       "11            palmeiras          6.875257     vasco da gama          3.202109\n",
       "12           américa-mg          4.015212         são paulo          5.951655\n",
       "13             botafogo          6.876050             bahia          3.203188\n",
       "14       brommapojkarna          5.606143            kalmar          3.256535\n",
       "15            ik sirius          3.969972             malmo          5.989297\n",
       "16             elfsborg          6.877552        norrkoping          3.200274\n",
       "17                  aik          5.901612  varbergs bois fc          3.440454"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformar o dicionário em uma lista de listas, quebrando a cada 2 itens\n",
    "items = list(corner_predictions.items())\n",
    "rows = [items[i:i + 2] for i in range(0, len(items), 2)]\n",
    "\n",
    "# Criar um DataFrame a partir da lista de listas\n",
    "df = pd.DataFrame(rows, columns=['Team1', 'Team2'])\n",
    "\n",
    "# Separar as tuplas em duas colunas separadas para os nomes das equipes e as previsões\n",
    "df[['Team1_name', 'Team1_prediction']] = pd.DataFrame(df['Team1'].tolist(), index=df.index)\n",
    "df[['Team2_name', 'Team2_prediction']] = pd.DataFrame(df['Team2'].tolist(), index=df.index)\n",
    "\n",
    "# Descartar as colunas originais e reordenar\n",
    "df = df[['Team1_name', 'Team1_prediction', 'Team2_name', 'Team2_prediction']]\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 4)"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 2\n",
    "\n",
    "from scipy.stats import poisson\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def poisson_probabilities(lam, max_corners=15):\n",
    "    probs = [poisson.pmf(k, lam) for k in range(max_corners + 1)]\n",
    "    probs.append(1 - sum(probs))\n",
    "    return probs\n",
    "\n",
    "def calculate_probabilities(team1_corners_prediction, team2_corners_prediction):\n",
    "    team1_corners_probabilities = poisson_probabilities(team1_corners_prediction)\n",
    "    team2_corners_probabilities = poisson_probabilities(team2_corners_prediction)\n",
    "\n",
    "    joint_prob_matrix = np.outer(team1_corners_probabilities, team2_corners_probabilities)\n",
    "\n",
    "    team1_win_prob = np.sum(np.tril(joint_prob_matrix, -1))\n",
    "    draw_prob = np.sum(np.diag(joint_prob_matrix))\n",
    "    team2_win_prob = np.sum(np.triu(joint_prob_matrix, 1))\n",
    "\n",
    "    team1_minus35_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if i-j>=4])\n",
    "    team1_plus35_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if i-j>=-3])\n",
    "    team2_minus35_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if j-i>=4])\n",
    "    team2_plus35_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if j-i>=-3])\n",
    "\n",
    "    team1_minus25_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if i-j>=3])\n",
    "    team1_plus25_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if i-j>=-2])\n",
    "    team2_minus25_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if j-i>=3])\n",
    "    team2_plus25_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if j-i>=-2])\n",
    "\n",
    "    team1_minus15_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if i-j>=2])\n",
    "    team1_plus15_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if i-j>=-1])\n",
    "    team2_minus15_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if j-i>=2])\n",
    "    team2_plus15_prob = np.sum([joint_prob_matrix[i,j] for i in range(joint_prob_matrix.shape[0]) for j in range(joint_prob_matrix.shape[1]) if j-i>=-1])\n",
    "\n",
    "    team1_over45_prob = 1 - sum(team1_corners_probabilities[:5])\n",
    "    team1_under45_prob = sum(team1_corners_probabilities[:5])\n",
    "    team2_over45_prob = 1 - sum(team2_corners_probabilities[:5])\n",
    "    team2_under45_prob = sum(team2_corners_probabilities[:5])\n",
    "\n",
    "    team1_over55_prob = 1 - sum(team1_corners_probabilities[:6])\n",
    "    team1_under55_prob = sum(team1_corners_probabilities[:6])\n",
    "    team2_over55_prob = 1 - sum(team2_corners_probabilities[:6])\n",
    "    team2_under55_prob = sum(team2_corners_probabilities[:6])\n",
    "\n",
    "    team1_over65_prob = 1 - sum(team1_corners_probabilities[:7])\n",
    "    team1_under65_prob = sum(team1_corners_probabilities[:7])\n",
    "    team2_over65_prob = 1 - sum(team2_corners_probabilities[:7])\n",
    "    team2_under65_prob = sum(team2_corners_probabilities[:7])\n",
    "    \n",
    "    return (team1_win_prob, draw_prob, team2_win_prob,\n",
    "        team1_minus15_prob, team1_plus15_prob, team2_minus15_prob, team2_plus15_prob,\n",
    "        team1_minus25_prob, team1_plus25_prob, team2_minus25_prob, team2_plus25_prob,\n",
    "        team1_minus35_prob, team1_plus35_prob, team2_minus35_prob, team2_plus35_prob,\n",
    "        team1_over45_prob, team1_under45_prob, team2_over45_prob, team2_under45_prob,\n",
    "        team1_over55_prob, team1_under55_prob, team2_over55_prob, team2_under55_prob,\n",
    "        team1_over65_prob, team1_under65_prob, team2_over65_prob, team2_under65_prob)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 31)\n"
     ]
    }
   ],
   "source": [
    "# Inicializando o DataFrame para armazenar as odds\n",
    "odds_df = pd.DataFrame(columns=['Team 1', 'Team 2', 'Team 1 Win Odd', 'Draw Odd', 'Team 2 Win Odd',\n",
    "                                'Team 1 -1.5 Odd', 'Team 1 +1.5 Odd', 'Team 2 -1.5 Odd', 'Team 2 +1.5 Odd',\n",
    "                                'Team 1 -2.5 Odd', 'Team 1 +2.5 Odd', 'Team 2 -2.5 Odd', 'Team 2 +2.5 Odd',\n",
    "                                'Team 1 -3.5 Odd', 'Team 1 +3.5 Odd', 'Team 2 -3.5 Odd', 'Team 2 +3.5 Odd',\n",
    "                                'Team 1 Over 4.5', 'Team 1 Under 4.5', 'Team 2 Over 4.5', 'Team 2 Under 4.5',\n",
    "                                'Team 1 Over 5.5', 'Team 1 Under 5.5', 'Team 2 Over 5.5', 'Team 2 Under 5.5',\n",
    "                                'Team 1 Over 6.5', 'Team 1 Under 6.5', 'Team 2 Over 6.5', 'Team 2 Under 6.5'])\n",
    "\n",
    "# Iterar sobre cada linha no DataFrame 'df'\n",
    "for index, row in df.iterrows():\n",
    "    team1_name = row['Team1_name']\n",
    "    team1_prediction = row['Team1_prediction']\n",
    "    team2_name = row['Team2_name']\n",
    "    team2_prediction = row['Team2_prediction']\n",
    "    \n",
    "    # Calculando as probabilidades usando a função do STEP 2\n",
    "    probabilities = calculate_probabilities(team1_prediction, team2_prediction)\n",
    "    \n",
    "    # Calculando as odds\n",
    "    odds = [1 / prob for prob in probabilities]\n",
    "    \n",
    "    # Adicionando as odds ao DataFrame\n",
    "    odds_df.loc[len(odds_df)] = [team1_name, team2_name] + odds\n",
    "\n",
    "    # Inicializando as novas colunas\n",
    "odds_df['date'] = None\n",
    "odds_df['championship'] = None\n",
    "\n",
    "# Preenchendo as novas colunas\n",
    "for index, row in odds_df.iterrows():\n",
    "    team1 = row['Team 1']\n",
    "    team2 = row['Team 2']\n",
    "    \n",
    "    # Encontrando a linha correspondente em 'future_matches'\n",
    "    match_row = future_matches[(future_matches['team1'] == team1) & (future_matches['team2'] == team2)]\n",
    "    \n",
    "    if not match_row.empty:\n",
    "        # Se encontrarmos uma linha correspondente, atualizamos 'odds_df'\n",
    "        odds_df.at[index, 'date'] = match_row.iloc[0]['date']\n",
    "        odds_df.at[index, 'championship'] = match_row.iloc[0]['championship']\n",
    "\n",
    "# Converte a coluna 'date' para o tipo de data do pandas\n",
    "odds_df['date'] = pd.to_datetime(odds_df['date'])\n",
    "\n",
    "# Formata a coluna 'date' para o formato de data brasileiro (dd/mm/yyyy)\n",
    "odds_df['date'] = odds_df['date'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "odds_df = odds_df.sort_values(['championship', 'date'])\n",
    "\n",
    "# Lista das colunas atuais\n",
    "cols = odds_df.columns.tolist()\n",
    "\n",
    "# Removendo 'date' e 'championship' da lista\n",
    "cols.remove('date')\n",
    "cols.remove('championship')\n",
    "\n",
    "# Reordenando as colunas\n",
    "new_cols = ['date', 'championship'] + cols\n",
    "\n",
    "# Atualizando o DataFrame com a nova ordem de colunas\n",
    "odds_df = odds_df[new_cols]\n",
    "\n",
    "odds_df.to_excel(\"output_corners_NNNN_AH.xlsx\", index=False)\n",
    "\n",
    "# Exibindo o DataFrame de odds\n",
    "print(odds_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
